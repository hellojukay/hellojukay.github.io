<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>润物细无声</title>
    <link>http://localhost:1313/</link>
    <description>Recent content on 润物细无声</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 11 Nov 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>在 docker build 的时候使用 pip 安装依赖报错，但是换个机器就没问题</title>
      <link>http://localhost:1313/posts/2024/2024-11-11/</link>
      <pubDate>Mon, 11 Nov 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2024/2024-11-11/</guid>
      <description>研发反馈，在 CI 流程中，打包镜像的时候，使用 pip 安装依赖报错，但是在自己的服务器就没问题，报错信息如下：&#xA;2024-11-11 16:43:31 [91mERROR: Exception: 2024-11-11 16:43:31 Traceback (most recent call last): 2024-11-11 16:43:31 File &amp;#34;/opt/conda/lib/python3.10/site-packages/pip/_internal/cli/base_command.py&amp;#34;, line 180, in exc_logging_wrapper 2024-11-11 16:43:31 status = run_func(*args) 2024-11-11 16:43:31 File &amp;#34;/opt/conda/lib/python3.10/site-packages/pip/_internal/cli/req_command.py&amp;#34;, line 245, in wrapper 2024-11-11 16:43:31 return func(self, options, args) 2024-11-11 16:43:31 File &amp;#34;/opt/conda/lib/python3.10/site-packages/pip/_internal/commands/install.py&amp;#34;, line 377, in run 2024-11-11 16:43:31 requirement_set = resolver.resolve( 2024-11-11 16:43:31 File &amp;#34;/opt/conda/lib/python3.10/site-packages/pip/_internal/resolution/resolvelib/resolver.py&amp;#34;, line 95, in resolve 2024-11-11 16:43:31 result = self._result = resolver.</description>
    </item>
    <item>
      <title>【翻译】golang 1.22 版本 http 路由的路径参数</title>
      <link>http://localhost:1313/posts/2024/2024-11-01/</link>
      <pubDate>Fri, 01 Nov 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2024/2024-11-01/</guid>
      <description>原文地址: https://www.willem.dev/articles/url-path-parameters-in-routes/&#xA;我在处理基于 http 的 API 的时候，通常使用 URL 路径按时(也叫路径变量)来传递数据，这些参数是 URL 的一部分。&#xA;几乎所有的 Web 服务器，都会通过路径模式来匹配处理逻辑。 我们希望能在路由中定义参数变量&#xA;/products/{slug} /users/{id}/profile /{page} 在上面的路由总， {slug} 和 {id} 都是路径参数，{page} 都是命名的路由参数。我们的想法是，我们可以在 http 处理逻辑中获取这些参数。&#xA;func handler(w http.ResponseWriter, r *http.Request) { // Get slug, id or page from in here. } 在 golang 1.22 版本之前，标准库的 http 路由参数是不支持的, 处理路由参数有些麻烦，或需要使用第三方库。随着 1.22 版本的发布，标准库开始支持 http 路由参数, 我们来按下如何使用这个新特性。&#xA;定义路由参数 在 http.ServeMux 类上，我们有2种定义路由的方法，分别是 Handle 和 HandleFunc。它们唯一不同指出在参数，一直接受一个 http.Handler 类型，另一个接受个 http.HandlerFunc 类型的函数。&#xA;func(w http.ResponseWriter, r *http.Request) 这篇文章中我们都使用 HandleFunc 方法，因为它更简单。</description>
    </item>
    <item>
      <title>快速停止Jenkins某个任务的所有构建</title>
      <link>http://localhost:1313/posts/2024/2024-11-01-1/</link>
      <pubDate>Fri, 01 Nov 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2024/2024-11-01-1/</guid>
      <description>背景 某个 Job 是定义启动的，因为某些资源原因，这些启动这的任务都卡住了，Jenkins 上某个节点的所有执行器都被消耗完毕了，无法执行新的任务，如果手动一个一个的关闭这些卡主的任务，太麻烦了，有没有什么办法可以快速停止某个 Job 的所有构建呢？&#xA;解决方案 进入管理页面，选择脚本控制台 如数如下脚本，修改脚本中的 jobName 为你的任务名称,然后执行即可。&#xA;import hudson.model.* def jobName = &amp;#34;你的任务名称&amp;#34; def job = Jenkins.instance.getItem(jobName) if (job) { def builds = job.getBuilds() for (build in builds) { build.doStop() } println(&amp;#34;已停止任务 $jobName 的所有构建。&amp;#34;) } else { println(&amp;#34;未找到名为 $jobName 的任务。&amp;#34;) } </description>
    </item>
    <item>
      <title>Jenkins 选择指定镜像部署</title>
      <link>http://localhost:1313/posts/2024/2024-10-24/</link>
      <pubDate>Thu, 24 Oct 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2024/2024-10-24/</guid>
      <description>背景需求： 项目的编译和部署是分离的，每次编译完成以后把镜像推送到镜像仓库，然后由部署人员拉取镜像进行部署。部署人员需要再 Jenkins 上选择需要部署的版本，然后点击确认进行部署。难点是，在 Jenkins 上如何获取指定镜像的所有版本，然后样用户选择？&#xA;解决方案： 每次编译完成以后把镜像推送到镜像仓库以后，同步触发一个 webhook 事件，将镜像的版本信息推送到一个第三方系统，让后下次部署的时候，从第三方系统的接口查询镜像的版本信息，然后用户选择。&#xA;这里的第三方系统代码我已经实现好了，代码在 github 上 aq，每次 webhook 发送 POST 请求&#xA;curl -X POST http://localhost:9090/image/{name}:{tag} 服务器会记录版本信息，然后下次部署的时候查询接口&#xA;curl -X GET http://localhost:9090/image/{name} 就能返回一个版本列表&#xA;[{ &amp;#34;name&amp;#34;: &amp;#34;xxx&amp;#34;, &amp;#34;tag&amp;#34;:&amp;#34;xxx&amp;#34;&amp;#34; }] 创建自由风格软件项目 我们在添加参数，选择 choice 类型 然后写 groovy 脚本获取镜像的版本信息, 下面的脚本就会动态获取版本列表了(Jenkins 上注意开放一下执行权限)，这个脚本还能优化一下，传递一个 limit 参数，限制返回的版本数量，这样下拉框的选项会少很多。 代码如下：&#xA;import groovy.json.JsonSlurper try { List&amp;lt;String&amp;gt; artifacts = new ArrayList&amp;lt;String&amp;gt;() def artifactsUrl = &amp;#34;http://localhost:9999/image/{name}&amp;#34; def artifactsObjectRaw = [&amp;#34;curl&amp;#34;, &amp;#34;-s&amp;#34;,&amp;#39;-X&amp;#39;,&amp;#39;GET&amp;#39;, &amp;#34;-H&amp;#34;, &amp;#34;accept: application/json&amp;#34;, &amp;#34;-k&amp;#34;, &amp;#34;--url&amp;#34;, &amp;#34;${artifactsUrl}&amp;#34;].execute().text def jsonSlurper = new JsonSlurper() def artifactsJsonObject = jsonSlurper.</description>
    </item>
    <item>
      <title>Jenkins Pipeline 判断 slave 上是否存在文件，注意避坑！</title>
      <link>http://localhost:1313/posts/2024/2024-09-12/</link>
      <pubDate>Thu, 12 Sep 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2024/2024-09-12/</guid>
      <description>今天某个网友遇到了一个古怪的问题，在 Jenkins Pipeline 中判断 slave 上是否存在文件，但是无论怎么判断都是返回 false。下面是他的核心代码:&#xA;def fh = new File(filePath) if(fh.exists()){ echo &amp;#34;文件存在&amp;#34; } else { echo &amp;#34;文件不存在&amp;#34; } 最后不管他怎么调试，上面的脚本总是输出“文件不存在”。&#xA;后来经过一番研究，终于找到了原因。在 pipeline 中， java 代码的 context 是运行在 master 节点上的，所以上面的代码中的 filePath 是 master 节点的路径。而 master 节点上没有这个文件，所以返回 false。正确的判断文件是否存在，应该使用 pipeline utils 库中的 fileExists 方法，代码如下：&#xA;def filePath = &amp;#34;xxx&amp;#34; if(fileExists(filePath)){ echo &amp;#34;文件存在&amp;#34; } else { echo &amp;#34;文件不存在&amp;#34; } 读取文件也是同样的问题，需要使用 readFile 方法。不要 new File 对象来读取文件。</description>
    </item>
    <item>
      <title>我的工单已经申请通过了，但是还是没有权限</title>
      <link>http://localhost:1313/posts/2024/2024-08-15/</link>
      <pubDate>Thu, 15 Aug 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2024/2024-08-15/</guid>
      <description>最近总是有人象我反馈，他申请权限的工单已经走完了流程，但是还是没有权限。我看了一下，他的工单确实通过了，但是看到走后的自动化任务执行情况，只执行了部分任务，没有执行全部的。我怀疑是我们的内部工单系统，没有调用我们的 Jenkins 任务，导致没有部分添加权限的任务没有被执行，但是实际看工单系统的日志，发现是请求了 Jenkins 的，所以不存在没有调用的情况。&#xA;我们的工单流程是：工单系统-&amp;gt;审批流程-&amp;gt;webhook-&amp;gt;Jenkins任务。 在 Jenkins 上通过 Ansbile 实现自动化任务。&#xA;今天我无意中发现，如果同时间多次触发 Jenkins 任务，只会执行一次任务，并不会每次触发都执行。从下面的截图可以看出来，我触发了 3 次，但是只执行了一次。 这种场景一般是多个工单同时间通过，在短时间内都执行 Webhok，导致 Jenkins 的任务被合并到只执行一次，就会导致部分权限没有添加。&#xA;解决方案可以参考: https://www.cnblogs.com/bolingcavalry/p/13800722.html&#xA;大概原理就是显示的告诉 Jenkins , 我的任务是有参数的任务，不好合并执行，强制设置 Jenkins 任务为带参数的任务。&#xA;#!/usr/bin/env groovy pipeline { agent { label &amp;#34;devops&amp;#34; } triggers { GenericTrigger( genericVariables: [ [key: &amp;#39;group&amp;#39;, value: &amp;#39;$.group&amp;#39;], [key: &amp;#39;user&amp;#39;, value: &amp;#39;$.apply_user&amp;#39;] ], causeString: &amp;#39;add $user to group $group&amp;#39;, token: &amp;#39;docker&amp;#39;, printContributedVariables: true, printPostContent: true, silentResponse: false, shouldNotFlattern: false ) } stages { stage(&amp;#39;申请 jfrog 权限&amp;#39;) { steps { script { currentBuild.</description>
    </item>
    <item>
      <title>未锁定依赖引发的故障</title>
      <link>http://localhost:1313/posts/2024/2024-07-18/</link>
      <pubDate>Thu, 18 Jul 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2024/2024-07-18/</guid>
      <description>前端研发突然找我，说他们的代码什么都没有改，重新编译上线，结果就页面白屏了，看浏览器的请求都是 404 , 因为他确信自己没有改动过代码，而且之前也编译过了。所以只能把问题怀疑到我们的我们的编译系统上。&#xA;听到研发的反馈，我们也很无奈，因为这段时间我们也没有改过代码，而且之前编译也没出问题，说明系统都是正常的，但是现在线上的资源访问 404 了。肯定是哪里出现问题，我们开始排查。&#xA;首先看编译日志，编译日志里面就有猫腻&#xA;这里报错 NoSuchBucket 看起来是找不到 s3 的 bucket , 说明他们在编译过程中使用到了 bucket , 然我就将代码下载下来，搜索关键字 bucket , 我运气好，给我找到了一个 upload.js 文件, 我看了这个文件的内容，就是往百度云的 bos 上传部分文件，然后我看到代码在编译期间被调用了，比较确信就是这里出了问题。&#xA;但是研发确实也没有改动过代码，我就比较怀疑是不是依赖没有锁死，我在代码里面发现是有 lock 文件的，于是我去查看编译日志，发现 lock 文件无效，被忽略了&#xA;这里我就怀疑是上游发布了新的包，我看了引用的 @baiducloud/sdk 这个包， https://www.npmjs.com/package/@baiducloud/sdk?activeTab=versions ，然后我到 npm 上查看这个包的发布历史，好家伙，昨天才发布的版本，因为依赖没有锁定，安装依赖的时候自动升级到了最新的 1.0.1 版本&#xA;说明这个版本是有 bug , 然后我们强制修改 package.json 文件，锁定版本到 1.0.0-rc.34 , 然后重新编译，上线，问题解决。&#xA;不管是做什么语言的开发，都需要把依赖锁定，避免出现代码再次编译后，依赖版本升级，导致代码不可用的情况，有的时候尽管代码仓库中有依赖的 lock 文件，但是也要确认在 CI 环境的下，这个 lock 文件是否有效。因为 CI 环境的编译工具可能和本地版本不一致，导致 lock 文件无效。</description>
    </item>
    <item>
      <title>快速删除 artifactory 删的过期文件</title>
      <link>http://localhost:1313/posts/2024/2024-07-10/</link>
      <pubDate>Wed, 10 Jul 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2024/2024-07-10/</guid>
      <description>首先我们需要安装安装 artifactory 的命令行工具， jfrog cli , 网址是 https://github.com/jfrog/jfrog-cli 。&#xA;我们需要写一个 artifactory 的查询脚本， 查询出所有的过期文件, 下面这个脚本是查询出 2016-10-18T21:26:52.000Z 之前的文件。&#xA;{ &amp;#34;files&amp;#34;: [ { &amp;#34;aql&amp;#34;: { &amp;#34;items.find&amp;#34;: { &amp;#34;repo&amp;#34;: &amp;#34;foobar&amp;#34;, &amp;#34;$or&amp;#34;: [ { &amp;#34;$and&amp;#34;: [ { &amp;#34;modified&amp;#34;: { &amp;#34;$lt&amp;#34;: &amp;#34;2016-10-18T21:26:52.000Z&amp;#34;} } ] } ] } } } ] } 我们也可以使用相对日期&#xA;&amp;#34;modified&amp;#34;: { &amp;#34;$before&amp;#34;:&amp;#34;6mo&amp;#34; } 然后我们使用 jfrog cli 命令行工具， 执行删除命令&#xA;jf rt del --spec /tmp/foo.spec --dry-run 加上 &amp;ndash;dry-run 参数， 执行删除命令的时候，不会真的删除文件。&#xA;jf rt del --spec /tmp/foo.spec 还可以设置一下并发的线程数量，这样删除会快一点</description>
    </item>
    <item>
      <title>给 apt 配置上网络代理</title>
      <link>http://localhost:1313/posts/2024/2024-06-25/</link>
      <pubDate>Tue, 25 Jun 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2024/2024-06-25/</guid>
      <description>ubuntu 或者 debian 安装软件的时候，apt 会从软件源下载软件。有时候网络可能比较慢，导致下载软件很慢。我们可以通过配置 apt 的代理来解决这个问题。编辑文件 /etc/apt/apt.conf （默认情况这个文件不存在，需要手动创建，或者内容为空），添加如下内容：&#xA;Acquire::http::Proxy &amp;#34;http://{ip}:{port}&amp;#34;; # 给 http 配置代理 Acquire::https::Proxy &amp;#34;http://{ip}:{port}&amp;#34;; # 给 https 配置代理 Acquire::http::Proxy::{no proxy domain} DIRECT; # 配置不需要代理的域名 </description>
    </item>
    <item>
      <title>苹果 M1 指纹解锁失效解决方案</title>
      <link>http://localhost:1313/posts/2024/2024-03-21/</link>
      <pubDate>Thu, 21 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2024/2024-03-21/</guid>
      <description>最近发现在 MacBook Pro 上使用 M1 芯片的 MacBook Pro 无法使用指纹解锁（之前是可以的），只能使用密码解锁。问了一圈周围的同事，发现很多人也遇到了这个问题。我们下意识的以为是公司把指纹解锁这个功能给禁止了，但经过排查，发现并不是，IT 人员表示他们没有禁用指纹解锁功能。我尝试删除现有的指纹，重新录入指纹，发现系统很难识别指纹，废了很大的功夫才录入成功。于是我怀疑这个会不是是 M1 的通病，开始在网上搜索相关信息，最后排查了一圈发现这样一篇文章 MacBook pro M1 版指纹解锁故障及解决办法 。&#xA;发现在B站上有一个视频，里面介绍了了这个问题。 Macbook Pro M1 这是啥问题 插上电源指纹解锁失灵 。&#xA;最终摸索出解决方案：&#xA;在使用指纹解锁时候，我们的手掌需要放在电脑上键盘下方的金属面板，就能成功解锁电脑，否则指纹识别不出来。不要尝试手掌悬空的状态下要手指解锁，这样是识别不出来指纹的。</description>
    </item>
    <item>
      <title>为什么博客更新越来也少</title>
      <link>http://localhost:1313/posts/2024/2024-03-08/</link>
      <pubDate>Fri, 08 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2024/2024-03-08/</guid>
      <description>今天是三八妇女节，祝福老婆节日快乐。&#xA;为什么写博客越来越少？我想了一下可能有几个原因：&#xA;写博客需要时间，需要思考，需要整理，结婚有孩子以后时间少了。 没什么值得写的，刚开始工作的时候是萌新一个，每天感觉学到好多东西，都想把它记录下来，有一些学习感悟，工作时间久了就发现我那些所谓学到的本领其实都是信息的堆叠，通过谷歌都能搜索到，所以现在我遇到了新的东西，我都不会去记录，因为我觉得没什么必要。随时都能搜到到。 没有原创的内容，写了那么多的文章，无非是读了别人的文章，让后自己理解一下重写一遍。我不太想重复了。 </description>
    </item>
    <item>
      <title>禁止 chrome 插件在某些网站上运行</title>
      <link>http://localhost:1313/posts/2023/2023-05-06_11/</link>
      <pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2023/2023-05-06_11/</guid>
      <description>Vimium 是我在 chrome 上经常使用的一个浏览器插件，这个插件能让我在 chrome 上使用 vim 的快捷键，但是我们再 jump server 上使用 vim 的时候， Vimium 插件会捕获我 的按键消息，导致我无法在跳板机上正常使用 vim 命令，所以我需要访问跳板网站的时候禁止 Vimium 插件运行。 操作方式如下:&#xA;1. 就进入插件插件里面chrome://extensions/ 2. 找到 `Vimium`, 点击 详情=&amp;gt;扩展程序选项=&amp;gt;Excluded URLs and keys 3. 添加一条网站的正则表达式 完毕.</description>
    </item>
    <item>
      <title>python 使用 urllib2 发送 PUT 请求</title>
      <link>http://localhost:1313/posts/2022/20222-07-15_17/</link>
      <pubDate>Fri, 15 Jul 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2022/20222-07-15_17/</guid>
      <description>默认是没法直接设置请求方法为 PUT 的，需要重写请求对象得 get_method 方法，让这个方法返回 PUT&#xA;import urllib2 def put_request(url, data): opener = urllib2.build_opener(urllib2.HTTPHandler) request = urllib2.Request(url, data=data) request.get_method = lambda: &amp;#39;PUT&amp;#39; response = opener.open(request) return response.read() # 示例用法 url = &amp;#39;http://example.com/api&amp;#39; data = &amp;#39;{&amp;#34;key&amp;#34;: &amp;#34;value&amp;#34;}&amp;#39; result = put_request(url, data) print(result) </description>
    </item>
    <item>
      <title>archlinux 链接wifi</title>
      <link>http://localhost:1313/posts/2022/2022-06-17_21/</link>
      <pubDate>Fri, 17 Jun 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2022/2022-06-17_21/</guid>
      <description>主要是使用 nmcli 这个工具&#xA;nmcli dev wifi connect {wifi name} password {wifi password} </description>
    </item>
    <item>
      <title>tmux 相关命令</title>
      <link>http://localhost:1313/posts/2022/2022-03-04_14/</link>
      <pubDate>Fri, 04 Mar 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2022/2022-03-04_14/</guid>
      <description>默认情况下， tmux 的前缀是 ctrl + b， 下面是一些常用的命令：&#xA;tmux new -s 启动 tmux 并且创建一个会话 tmux ls 列出 tmux 的所有会话 tmux send-keys -t 向 tmux 会发发从按键 prefix + d detach 当前会话 prefix + attach -t attach 到一个会话中 prefix + &amp;quot; 上下分割窗口右 prefix + % 左右分割窗口 prefix + c 再当前会话创建新的窗口 prefix + x 关闭当窗口 prefix + s 列出所有的会话 prefix + w 列出所有的窗口 prefix + , 重新命名当前窗口 prefix + n 切换到下一个窗口 prefix + p 切换到上一个窗口 </description>
    </item>
    <item>
      <title>Go程序编译注入版本信息</title>
      <link>http://localhost:1313/posts/2022/2022-02-09_14/</link>
      <pubDate>Wed, 09 Feb 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2022/2022-02-09_14/</guid>
      <description>编译注入全局变量 flags=&amp;#34;-X &amp;#39;main.goversion=$(go version)&amp;#39;&amp;#34; go build -ldflags &amp;#34;$flags&amp;#34; -x -o build-version main.go Go的debug包可以自动注入版本信息 if version { info, ok := debug.ReadBuildInfo() if ok { println(info.Main.Version, info.Main.Sum) } os.Exit(0) } 这种方式有一定的局限性，本地编译的时候版本永远都是 (devel), 只有通过 go install 命令才能展示编译时候的 git tag 版本。</description>
    </item>
    <item>
      <title>git 配置多个用户的方法</title>
      <link>http://localhost:1313/posts/2021/2021-12-28_11/</link>
      <pubDate>Tue, 28 Dec 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2021/2021-12-28_11/</guid>
      <description>git 经常会搞乱配置 将公司用户邮箱推送到 github 将私人邮箱推送到 gitlab 有必要将2套环境的配置分开，在 git 的 2.13 版本加入了 includeIf 功能：在不同的目录导入不同的配置。 见: https://stackoverflow.com/questions/8801729/is-it-possible-to-have-different-git-configuration-for-different-projects&#xA;[user] name = xiaowang email = xiaowang@qianxin.com [includeIf &amp;#34;gitdir:~/github/&amp;#34;] path = ~/.githubconfig [pull] rebase = false [init] defaultBranch = main 这里定义了默认用户名和邮箱，但是如果项目目录在 ~/github/ 目录则会使用 .githubconfig 中的配置，在 .githubconfig 中可以配置一个新的 用户和邮箱。&#xA;参考:&#xA;https://git-scm.com/docs/git-config#_includes </description>
    </item>
    <item>
      <title>【转载】 nginx 的 https 相关知识</title>
      <link>http://localhost:1313/posts/2021/2021-12-10_14/</link>
      <pubDate>Fri, 10 Dec 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2021/2021-12-10_14/</guid>
      <description>原文地址 https://tengine.taobao.org/nginx_docs/cn/docs/http/configuring_https_servers.html&#xA;配置HTTPS主机，必须在server配置块中打开SSL协议，还需要指定服务器端证书和密钥文件的位置：&#xA;server { listen 443; server_name www.example.com; ssl on; ssl_certificate www.example.com.crt; ssl_certificate_key www.example.com.key; ssl_protocols SSLv3 TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers HIGH:!aNULL:!MD5; ... } 服务器证书是公开的，会被传送到每一个连接到服务器的客户端。而私钥不是公开的，需要存放在访问受限的文件中，当然，nginx主进程必须有读取密钥的权限。私钥和证书可以存放在同一个文件中：&#xA;ssl_certificate www.example.com.cert; ssl_certificate_key www.example.com.cert; 这种情况下，证书文件同样得设置访问限制。当然，虽然证书和密钥存放在同一个文件，只有证书会发送给客户端，密钥不会发送。&#xA;ssl_protocols和ssl_ciphers指令可以用来强制用户连接只能引入SSL/TLS那些强壮的协议版本和强大的加密算法。从1.0.5版本开始，nginx默认使用“ssl_protocols SSLv3 TLSv1”和“ssl_ciphers HIGH:!aNULL:!MD5”，所以只有在之前的版本，明确地配置它们才是有意义的。从1.1.13和1.0.12版本开始，nginx默认使用“ssl_protocols SSLv3 TLSv1 TLSv1.1 TLSv1.2”。&#xA;CBC模式的加密算法容易受到一些攻击，尤其是BEAST攻击（参见CVE-2011-3389）。可以通过下面配置调整为优先使用RC4-SHA加密算法：&#xA;ssl_ciphers RC4:HIGH:!aNULL:!MD5; ssl_prefer_server_ciphers on; HTTPS服务器优化 SSL操作需要消耗CPU资源，所以在多处理器的系统，需要启动多个工作进程，而且数量需要不少于可用CPU的个数。最消耗CPU资源的SSL操作是SSL握手，有两种方法可以将每个客户端的握手操作数量降到最低：第一种是保持客户端长连接，在一个SSL连接发送多个请求，第二种是在并发的连接或者后续的连接中重用SSL会话参数，这样可以避免SSL握手的操作。会话缓存用于保存SSL会话，这些缓存在工作进程间共享，可以使用ssl_session_cache指令进行配置。1M缓存可以存放大约4000个会话。默认的缓存超时是5分钟，可以使用ssl_session_timeout加大它。下面是一个针对4核系统的配置优化的例子，使用10M的共享会话缓存：&#xA;worker_processes 4; http { ssl_session_cache shared:SSL:10m; ssl_session_timeout 10m; server { listen 443; server_name www.example.com; keepalive_timeout 70; ssl on; ssl_certificate www.example.com.crt; ssl_certificate_key www.example.com.key; ssl_protocols SSLv3 TLSv1 TLSv1.</description>
    </item>
    <item>
      <title>内存分析工具 smem</title>
      <link>http://localhost:1313/posts/2021/2021-12-06_11/</link>
      <pubDate>Mon, 06 Dec 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2021/2021-12-06_11/</guid>
      <description>下载地址: https://www.selenic.com/smem/download/&#xA;#!/usr/bin/env python2 # # smem - a tool for meaningful memory reporting # # Copyright 2008-2009 Matt Mackall &amp;lt;mpm@selenic.com&amp;gt; # # This software may be used and distributed according to the terms of # the GNU General Public License version 2 or later, incorporated # herein by reference. import re, os, sys, pwd, optparse, errno, tarfile warned = False class procdata(object): def __init__(self, source): self._ucache = {} self._gcache = {} self.</description>
    </item>
    <item>
      <title>archlinux 安装中文输入法</title>
      <link>http://localhost:1313/posts/2021/2021-11-21_16/</link>
      <pubDate>Sun, 21 Nov 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2021/2021-11-21_16/</guid>
      <description>转载: https://zhuanlan.zhihu.com/p/393746270&#xA;Arch Linux可以安装安装fcitx5 实现输入中文，具体步骤如下 sudo pacman -S fcitx5-im # 默认所有都装 sudo pacman -S fcitx5-chinese-addons fcitx5-rime 其中 fcitx5-chinese-addons 包含了大量中文输入方式：拼音、双拼、五笔拼音、自然码、仓颉、冰蟾全息、二笔等 fcitx5-rime 对经典的 Rime IME 输入法的包装，内置了繁体中文和简体中文的支持。 然后在环境变量配置文件/etc/environment中添加如下内容 # /etc/environment GTK_IM_MODULE=fcitx QT_IM_MODULE=fcitx XMODIFIERS=@im=fcitx SDL_IM_MODULE=fcitx 然后配置自动启动，提供以下3种方法，第一个不行，试第2个，然后第3个 如果，支持XDG桌面环境，例如KDE,GNOME, Xfce,默认重启后即可 在~/.config/autostart目录下添加fcitx-autostart.desktop文件，可以从目录etc/xdg/autostart中复制 对于i3-wm,可以在配置文件~/.config/i3/config中添加如下代码 # fcitx5 exec_always --no-startup-id fcitx5 </description>
    </item>
    <item>
      <title>windows 更新本地证书列表</title>
      <link>http://localhost:1313/posts/2021/2021-11-17_11/</link>
      <pubDate>Wed, 17 Nov 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2021/2021-11-17_11/</guid>
      <description>转载: https://www.sohu.com/a/483126111_121200070&#xA;certutil.exe -generateSSTFromWU roots.sst $sstStore = ( Get-ChildItem -Path &amp;#34;$pwd\roots.sst&amp;#34; ) $sstStore | Import-Certificate -CertStoreLocation Cert:\LocalMachine\Root 如果是 linux 系统，可以使用 update-ca-certificates 命令更新证书。</description>
    </item>
    <item>
      <title>解决 centos7 上 perl 找不到 JSON::PP 包的问题</title>
      <link>http://localhost:1313/posts/2021/2021-11-10_17/</link>
      <pubDate>Wed, 10 Nov 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2021/2021-11-10_17/</guid>
      <description>perl 没有内置这个包，需要单独安装，方法如下：&#xA;wget http://mirror.centos.org/centos/7/os/x86_64/Packages/perl-JSON-PP-2.27202-2.el7.noarch.rpm rpm -i perl-JSON-PP-2.27202-2.el7.noarch.rpm </description>
    </item>
    <item>
      <title>vim 使用技巧</title>
      <link>http://localhost:1313/posts/2021/2021-10-20_11/</link>
      <pubDate>Wed, 20 Oct 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2021/2021-10-20_11/</guid>
      <description>bi : 在单词前面插入 ea : 在单词后面插入 cib : 修改 () 内的内容 ciB : 修改在{} 内的内容 dj : 删除下面2行 dk : 删除上面2行 ctrl+w c : 关闭但前分屏 ctrl+w q : 关闭但前分屏,如果是最后一屏，则退出 vim </description>
    </item>
    <item>
      <title>jenkins 小技巧</title>
      <link>http://localhost:1313/posts/2021/2021-10-15_17/</link>
      <pubDate>Fri, 15 Oct 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2021/2021-10-15_17/</guid>
      <description>设置项目构建的描述信息,pipline 的情况下这样设置&#xA;stage(&amp;#39;xxx&amp;#39;){ steps{ script { currentBuild.name =&amp;#34;MY_VERSION_NUMBER&amp;#34; currentBuild.description =&amp;#34;MY_PROJECT MY_VERSION_NUMBER&amp;#34; } } } 在自由风格的情况下，需要安装 &amp;lsquo;description setter plugin&amp;rsquo;, 然后在项目的时候下面添加一个编译后的步骤，选择 &amp;lsquo;Set build description&amp;rsquo;, 然后 填写上正则表达式，捕获日志中的字符串，在 &amp;lsquo;Description&amp;rsquo; 中可以用 \number 的方式引用正则的捕获。</description>
    </item>
    <item>
      <title>perl 小技巧</title>
      <link>http://localhost:1313/posts/2021/2021-10-15_11/</link>
      <pubDate>Fri, 15 Oct 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2021/2021-10-15_11/</guid>
      <description>实用函数 # 删除字符串左右空格 sub trim ($) { my $s = shift; $s =~ s/^\s+|\s+$//g; return $s } perl 多线程消费 参考文档: https://metacpan.org/pod/Thread::Queue use threads; use Thread::Queue; my $q = Thread::Queue-&amp;gt;new(); sub work ($) { while(my $task = $q-&amp;gt;dequeue()){ # if $task is undef, it means the queue end last unless($task); # do somthing } } # enqueue async { foreach(0..10) { $q-&amp;gt;enqueue($_) } # Signal that there is no more work to be sent $q-&amp;gt;end(); } # create threads foreach(0.</description>
    </item>
    <item>
      <title>webpack 学习</title>
      <link>http://localhost:1313/posts/2021/2021-09-13_14/</link>
      <pubDate>Mon, 13 Sep 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2021/2021-09-13_14/</guid>
      <description>webpack 是什么？ webpack 是一个打包工具(不是编译工具),他负责将从一个入口文件开始，递归的打包这个入口文件所依赖的所有资源&#xA;默认的配置文件是什么 webpack.config.js&#xA;打包命令 webpack 或者 webpack &amp;ndash;config webpack.config.js&#xA;loader 是什么？ webpack 本身只能打包 javascript 代码，实际需求我们也需要打包 css 和 html 代码，但是直接在 javascript 中 import 这些文件显然是报错的，因为它们都不是合法的 javascript 文件，所以我们需要有其他的 loader 来加载识别不同的文件，将他们转化成 合法的 javascript 语法文件。比如 style-loader , css-loader.入门可以写一个规则列表，对于不同的文件，使用不同的 loader 来处理&#xA;在开发中，如果需要实时的自动编译，预览文件，我们需要给 webpack 配置 devServer , 它底层是一个 express 服务，我们在启动的 时候加上 &amp;ndash;static-watch 就能自动实时编译刷新了</description>
    </item>
    <item>
      <title>Go编写命令行添加alias的方法</title>
      <link>http://localhost:1313/posts/2021/2021-09-01_14/</link>
      <pubDate>Wed, 01 Sep 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2021/2021-09-01_14/</guid>
      <description>参考 https://github.com/golang/go/issues/35761#issuecomment-559207341 , 代码如下&#xA;package main import &amp;#34;flag&amp;#34; func main() { name := flag.String(&amp;#34;name&amp;#34;, &amp;#34;&amp;#34;, &amp;#34;your name&amp;#34;) flag.StringVar(name, &amp;#34;n&amp;#34;, *name, &amp;#34;alais for --name&amp;#34;) flag.Parse() println(*name) } 编译&#xA;hellojukay@local test $ go build hellojukay@local test $ ./test -h Usage of ./test: -n string alais for --name -name string your name </description>
    </item>
    <item>
      <title>几个终端代码演示图片工具</title>
      <link>http://localhost:1313/posts/2021/2021-07-27_12/</link>
      <pubDate>Tue, 27 Jul 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2021/2021-07-27_12/</guid>
      <description> t-rec 是一个 rust 编写的终端录屏工具 https://github.com/sassman/t-rec-rs 推荐命令&#xA;t-rec -d none -b black silicon 是一个可以给代码生成图片的工具 https://github.com/Aloxaf/silicon 推荐命令行,设置背景为白色&#xA;silicon -b=\#FFFFFF </description>
    </item>
    <item>
      <title>Ocaml 技巧</title>
      <link>http://localhost:1313/posts/2021/2021-06-24_14/</link>
      <pubDate>Thu, 24 Jun 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2021/2021-06-24_14/</guid>
      <description>静态编译一个 Ocaml 脚本文件 ocamlopt -ccopt -static -o hello hello.ml dune 项目静态编译可以参考 https://www.ocamlpro.com/2021/09/02/generating-static-and-portable-executables-with-ocaml/&#xA;(executable (flags (:standard -cclib -static)) (name main)) 相同目录下的文件直接当成模块使用 hello.ml 在本目录的其他文件中，可以直接 Open hello&#xA;Ocaml 发送 post 请求，并且设置 header 和 body&#xA;open Lwt let body = let buffer = Cohttp_lwt.Body.of_string &amp;#34;body string&amp;#34; in let headers = Cohttp.Header.init () in Cohttp_lwt_unix.Client.post ~body:buffer ~headers:(Cohttp.Header.add headers &amp;#34;Content-type&amp;#34; &amp;#34;application/json&amp;#34;) (Uri.of_string &amp;#34;http://.........&amp;#34;) &amp;gt;&amp;gt;= fun (_, body) -&amp;gt; Cohttp_lwt.Body.to_string body let () = let body = Lwt_main.</description>
    </item>
    <item>
      <title>envsubst 在 perl 的实现</title>
      <link>http://localhost:1313/posts/2021/2021-06-07_11/</link>
      <pubDate>Mon, 07 Jun 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2021/2021-06-07_11/</guid>
      <description>代码来源: https://metacpan.org/source/PEVANS/String-Expand-0.04/lib/String/Expand.pm&#xA;#!/usr/bin/env perl my $VARNAME_MATCH = qr/\$([A-Z_][A-Z0-9_]*|\{.*?\})/; sub expand_one_var($$) { my ( $var, $vars ) = @_; # Chop off delimiting {braces} if present $var =~ s/^\{(.*)\}$/$1/; unless( defined $vars-&amp;gt;{$var} ) { die &amp;#34;Unknown variable &amp;#39;$var&amp;#39;&amp;#34;; } return $vars-&amp;gt;{$var}; } sub expand_string($$) { my ( $str, $vars ) = @_; $str =~ s{\\([\\\$])|$VARNAME_MATCH} { $1 or expand_one_var( $2, $vars )}eg; return $str; } sub expand_strings_inner($$$$); sub expand_strings_one_var($$$$) { my ( $var, $strs, $overlay, $done ) = @_; # Chop off delimiting {braces} if present $var =~ s/^\{(.</description>
    </item>
    <item>
      <title>man 手册的用法</title>
      <link>http://localhost:1313/posts/2021/2021-06-04_15/</link>
      <pubDate>Fri, 04 Jun 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2021/2021-06-04_15/</guid>
      <description>带选项的用法 man [keyword] man ls man -f 查找文档所在的章节 hellojukay@local ~ $ man -f syscalls syscalls (2) - Linux system calls man [number] [keyword] 查看指定章节的文档 man 2 syscalls man -k [keyword] 使用正则表达式搜索所有的章节 hellojukay@local ~ $ man -k cd cdt (3) - container data types BN_gcd (3ssl) - arithmetic operations on BIGNUMs cd (1p) - change the working directory cd (n) - Change working directory cd-create-profile (1) - Color Manager Profile Creation Tool cd-drive (1) - show CD-ROM drive characteristics cd-fix-profile (1) - Color Manager Testing Tool cd-info (1) - shows Information about a CD or CD-image cd-it8 (1) - Color Manager Testing Tool man -I [keyword] 严格区分大小写 hellojukay@local ~ $ man -I BAsh 没有 BAsh 的手册页条目 2024年04月25日更新: tldr 这个项目已经可以很好替代 man 手册了</description>
    </item>
    <item>
      <title>列出 kubernetes 上 deployment apps 的镜像</title>
      <link>http://localhost:1313/posts/2021/2021-05-26_15/</link>
      <pubDate>Wed, 26 May 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2021/2021-05-26_15/</guid>
      <description>今天盼哥问我说怎么看每个服务的版本，我说可以通过 kubectl describe pod 看，盼哥表示太麻烦了，于是我用 perl 写 了一个脚本，如下:&#xA;#!/bin/perl use strict; use warnings; use Getopt::Long qw( GetOptions :config no_ignore_case); sub usage ($); GetOptions(&amp;#34;n|namnespace=s&amp;#34;, \(my $namespace), &amp;#34;h|help&amp;#34;, \(my $help)) or usage(1); if($help){ usage(0); } if(not $namespace) { $namespace = &amp;#34;default&amp;#34;; } sub get_deployment(@){ my $namespace = $_[0]; my @deployments = `kubectl get deployments -n $namespace | grep -v NAME | awk &amp;#39;{print \$1}&amp;#39;`; return @deployments; } sub print_version(@){ my $namespace = $_[0]; my $deployment = $_[1]; $deployment =~ s/^\s+|\s+$//g; my @image = `kubectl describe deploy $deployment -n $namespace | grep Image | awk &amp;#39;{print \$2}&amp;#39;`; my $image_str = join &amp;#34;, &amp;#34;, @image; $image_str =~ s/^\s+|\n+?</description>
    </item>
    <item>
      <title>python 终端简单输出颜色</title>
      <link>http://localhost:1313/posts/2021/2021-05-07_18/</link>
      <pubDate>Fri, 07 May 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2021/2021-05-07_18/</guid>
      <description>在 https://stackoverflow.com/questions/287871/how-to-print-colored-text-to-the-terminal 上看到的代码&#xA;class bcolors: HEADER = &amp;#39;\033[95m&amp;#39; OKBLUE = &amp;#39;\033[94m&amp;#39; OKCYAN = &amp;#39;\033[96m&amp;#39; OKGREEN = &amp;#39;\033[92m&amp;#39; WARNING = &amp;#39;\033[93m&amp;#39; FAIL = &amp;#39;\033[91m&amp;#39; ENDC = &amp;#39;\033[0m&amp;#39; BOLD = &amp;#39;\033[1m&amp;#39; UNDERLINE = &amp;#39;\033[4m&amp;#39; print(bcolors.WARNING + &amp;#34;Warning: No active frommets remain. Continue?&amp;#34; + bcolors.ENDC) python 3.6+ 如下： print(f&amp;#34;{bcolors.WARNING}Warning: No active frommets remain. Continue?{bcolors.ENDC}&amp;#34;) 也有更加高级一点的，能够设置字体颜色&#xA;class colors: &amp;#39;&amp;#39;&amp;#39;Colors class: Reset all colors with colors.reset Two subclasses fg for foreground and bg for background. Use as colors.</description>
    </item>
    <item>
      <title>解决 YCM 安装 cmake 报错的问题</title>
      <link>http://localhost:1313/posts/2021/2021-04-26_22/</link>
      <pubDate>Mon, 26 Apr 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2021/2021-04-26_22/</guid>
      <description>报错信息： ERROR: Unable to find cmake executable in any of [&amp;#39;cmake3&amp;#39;, &amp;#39;cmake&amp;#39;]. CMake is required to build ycmd 等待我们安装好了 cmake 以后还是继续报错&#xA;sudo pacman -S cmake 错误如下：&#xA;Searching Python 3.9 libraries... Found Python library: /usr/lib64/libpython3.9.so Found Python headers folder: /usr/include/python3.9 CMake Error: CMake was unable to find a build program corresponding to &amp;#34;Unix Makefiles&amp;#34;. CMAKE_MAKE_PROGRAM is not set. You probably need to select a different build tool. CMake Error: CMAKE_C_COMPILER not set, after EnableLanguage CMake Error: CMAKE_CXX_COMPILER not set, after EnableLanguage -- Configuring incomplete, errors occurred!</description>
    </item>
    <item>
      <title>coredns 创建泛域名解析</title>
      <link>http://localhost:1313/posts/2021/2021-04-22_16/</link>
      <pubDate>Thu, 22 Apr 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2021/2021-04-22_16/</guid>
      <description>例子如下: .:53 { errors health { lameduck 5s } ready template IN A test.cn { match .*\.test\.cn answer &amp;#34;{{ .Name }} 60 IN A 192.168.1.1&amp;#34; fallthrough } forward . /etc/resolv.conf cache 30 reload loadbalance } 这里创建了一个 &amp;#34;*.test.cn&amp;#34; 的泛域名解析，所有的解析都被指向了地址 &amp;#34;192.168.1.1&amp;#34; 文本参考: 1. https://www.1nth.com/post/coredns_diy/ </description>
    </item>
    <item>
      <title>发布 cargo 包到 crates 官方仓库的方法</title>
      <link>http://localhost:1313/posts/2021/2021-04-16_11/</link>
      <pubDate>Fri, 16 Apr 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2021/2021-04-16_11/</guid>
      <description> 登录 https://crates.io ，完成 github.com 的登录授权，然后在个人 主页面中进入 Account Settingss 完成如下工作:&#xA;填写个人邮箱地址（并且完成认证) 创建 token, 记录 token 后面会用到 终端认证&#xA;cargo login &amp;lt;token here&amp;gt; 发布到 crates 中 cargo publish 这样会自动编译包，并且完成发布&#xA;相关问题:&#xA;Q: 设置了 mirror 无法发布 A: 删除 mirror 相关的配置 Q: 网络有问题，链接超时 A: 添加终端带来，并且在 ~/.cargo/conf 中配置好 net.git-fetch-with-cli export https_proxy=http://127.0.0.1:7890 Q: warning: manifest has no description, license, license-file, documentation, homepage or repository. A: 务必在项目的 Cargo.toml 文件中配置好 license, document, homepage , description 字段 </description>
    </item>
    <item>
      <title>windows 搭建 rust 开发环境【免安装 VS Studio】</title>
      <link>http://localhost:1313/posts/2021/2021-04-09_23/</link>
      <pubDate>Fri, 09 Apr 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2021/2021-04-09_23/</guid>
      <description>本文介绍使用 MYSYS2 在 windows 上安装 rust 开发环境，首先我们需要安装 rustup,这个可以参见官网：https://www.rust-lang.org/&#xA;然后安装号 MYSYS2 ，直接双击 exe 文件安装即可，安装好了以后在 MYSYS2 中安装好 gcc 环境:&#xA;pacman -S mingw-w64-x86_64-gcc 安装好了之后配置好 cargo 的配置文件 C:\Users\Administrator.cargo ， 配置内容如下:&#xA;[source.crates-io] registry = &amp;#34;https://github.com/rust-lang/crates.io-index&amp;#34; replace-with = &amp;#39;ustc&amp;#39; [source.ustc] registry = &amp;#34;git://http://mirrors.ustc.edu.cn/crates.io-index&amp;#34; [target.x86_64-pc-windows-gnu] linker = &amp;#34;E:/msys64/mingw64/bin/gcc.exe&amp;#34; ar = &amp;#34;E:/msys64/mingw64/bin/ar.exe&amp;#34; 然后执行如下命令：&#xA;rustup toolchain install stable-x86_64-pc-windows-gnu rustup default stable-x86_64-pc-windows-gnu 执行完毕以后就能编译 rust 代码了&#xA;PS E:\code&amp;gt; cargo new aaa --bin Created binary (application) `aaa` package PS E:\code&amp;gt; cd aaa PS E:\code\aaa&amp;gt; cargo run Compiling aaa v0.</description>
    </item>
    <item>
      <title>安装 ceph-common 14.2.10 版本</title>
      <link>http://localhost:1313/posts/2021/2021-04-07_18/</link>
      <pubDate>Wed, 07 Apr 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2021/2021-04-07_18/</guid>
      <description>在 k8s 中使用 ceph 当作存储，需要在每一个节点上都安装 ceph-common 包，我们这里安装的是 14.2.10 版本&#xA;首先添加 /etc/yum.repos.d/repo&#xA;[ceph] name=cenh baseurl=https://download.ceph.com/rpm-nautilus/el7/$basearch enabled=1 gpgcheck=0 然后就能安装了&#xA;yum makecache yum install ceph-common </description>
    </item>
    <item>
      <title>那些常用的linux小技巧</title>
      <link>http://localhost:1313/posts/2020/20201229/</link>
      <pubDate>Tue, 29 Dec 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2020/20201229/</guid>
      <description>既然是常用的技巧，肯定是随时都能用，在各个 linux 发行版上都能用,都是最纯粹，最简单有效的技能。&#xA;网络 检查网络端口是否网络联通 curl {ip}:{port} -v 比如:&#xA;vagrant@archlinux _posts (master) $ curl 127.0.0.1:22 -v * Trying 127.0.0.1:22... * Connected to 127.0.0.1 (127.0.0.1) port 22 (#0) &amp;gt; GET / HTTP/1.1 &amp;gt; Host: 127.0.0.1:22 &amp;gt; User-Agent: curl/7.74.0 &amp;gt; Accept: */* &amp;gt; * Received HTTP/0.9 when not allowed * Closing connection 0 curl: (1) Received HTTP/0.9 when not allowed 从输出日志可以看到 Connected 字样，说明端口是通的，类似的方式还有,netcat,telnet，不过这2个工具经常在服务器上没有。&#xA;获取 DNS 解析结果 通常我们使用 dig 或者 nslookup 命令来查看解析域名，但是这2个工具在很多场合下都没有，所以我们可以使用其它的工具来代替，比如: curl , ping</description>
    </item>
    <item>
      <title>Ansible 主机多网卡情况下获取IP地址</title>
      <link>http://localhost:1313/posts/2020/20201226/</link>
      <pubDate>Sat, 26 Dec 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2020/20201226/</guid>
      <description>这里有一个错误用法是获取受控机器的网卡的信息，但是有多个网卡的情况下就会获取到其它的网卡地址，正确的做法如下：&#xA;vagrant@archlinux k8s-install $ ansible -i inventory -m debug -a &amp;#34;var=ansible_ssh_host&amp;#34; all -u vagrant -k SSH password: [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details 127.0.0.1 | SUCCESS =&amp;gt; { &amp;#34;ansible_ssh_host&amp;#34;: &amp;#34;127.0.0.1&amp;#34; } 192.168.0.10 | SUCCESS =&amp;gt; { &amp;#34;ansible_ssh_host&amp;#34;: &amp;#34;192.168.0.10&amp;#34; } 192.168.0.11 | SUCCESS =&amp;gt; { &amp;#34;ansible_ssh_host&amp;#34;: &amp;#34;192.168.0.11&amp;#34; } 192.168.0.12 | SUCCESS =&amp;gt; { &amp;#34;ansible_ssh_host&amp;#34;: &amp;#34;192.168.0.12&amp;#34; } 使用 ansible_ssh_host 这个内置变量.</description>
    </item>
    <item>
      <title>k8s 获取集群的健康信息的几条命令</title>
      <link>http://localhost:1313/posts/2020/20201217/</link>
      <pubDate>Thu, 17 Dec 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2020/20201217/</guid>
      <description>一个被过期的命令是:&#xA;kubectl get componentstatus 他的简写是&#xA;kubectl get cs 一个最新的写法是&#xA;kubectl cluster-info 要获取更多的 debug 信息可以&#xA;kubectl cluster-info dump </description>
    </item>
    <item>
      <title>使用 CoreDNS 搭建内部 DNS 解析服务器</title>
      <link>http://localhost:1313/posts/2020/20201214/</link>
      <pubDate>Mon, 14 Dec 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2020/20201214/</guid>
      <description>下载二进制文件 ghget --proxy --url &amp;#34;https://github.com/coredns/coredns/releases/download/v1.8.0/coredns_1.8.0_linux_amd64.tgz&amp;#34; 配置 service 在 /usr/lib/systemd/system/coredns.service 配置好 service 文件&#xA;[Unit] Description=Coredns server Documentation=https://coredns.io/ After=network-online.target firewalld.service Wants=network-online.target [Service] Type=simple ExecStart=/bin/coredns -conf /opt/coredns/Corefile -dns.port=53 TimeoutSec=0 RestartSec=2 Restart=always [Install] WantedBy=multi-user.targe 配置好配置文件 配置文件 /opt/coredns/Corefile 内容如下&#xA;. { hosts { 192.168.0.100 www.aaa.com 192.168.0.101 www.bbb.com reload 10s ttl 50 fallthrough } forward . /etc/resolv.conf cache 120 reload 10s log errors } 配置好了以后就能启动服务了&#xA;systemctl start coredns 然后就能使用 dig 命令解析服务了&#xA;dig @127.0.0.1 www.aaa.com </description>
    </item>
    <item>
      <title>k8s 无法创建 Statefulset</title>
      <link>http://localhost:1313/posts/2020/20201210/</link>
      <pubDate>Thu, 10 Dec 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2020/20201210/</guid>
      <description>错误信息如下&#xA;The StatefulSet &amp;#34;nacos&amp;#34; is invalid: spec: Forbidden: updates to statefulset spec for fields other than &amp;#39;replicas&amp;#39;, &amp;#39;template&amp;#39;, and &amp;#39;updateStrategy&amp;#39; are forbidden 原因： statefulset 已经存在了，当前 yml 文件的配置和已经存在的文件的配置又冲突，删除再次创建就没有问题.</description>
    </item>
    <item>
      <title>maven 生成 swagger.json</title>
      <link>http://localhost:1313/posts/2020/20201206/</link>
      <pubDate>Sun, 06 Dec 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2020/20201206/</guid>
      <description>参考 demo : https://github.com/leanix/swagger-demo.git&#xA;执行编译命令，生成 wagger.json&#xA;mvn compile 执行上面命令后会在 target/classes/api-docs/ 目录生成 swagger.json 文件.</description>
    </item>
    <item>
      <title>failed to create rbd image: execut able file not found in $PATH, command output</title>
      <link>http://localhost:1313/posts/2020/20201130/</link>
      <pubDate>Mon, 30 Nov 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2020/20201130/</guid>
      <description>k8s 在使用 Ceph 当作存储的时候无法根据 ClassStorage 分配PV,提示错误:&#xA;failed to create rbd image: execut able file not found in $PATH, command output: 关于社区对此问题的讨论见：https://github.com/kubernetes/kubernetes/issues/85454</description>
    </item>
    <item>
      <title>记一次 docker 路由冲突</title>
      <link>http://localhost:1313/posts/2020/20201124/</link>
      <pubDate>Tue, 24 Nov 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2020/20201124/</guid>
      <description>有两位研发告诉我，他们无法访开发服务器了，过了一会儿我被拉到一个群聊中，群里都是在吐槽无法访问开发服务器的问题，我被有要求来排查这个问题。群里也有 OPS 的同学，他们发现 iptables 中有很多 docker 注入的策略。docker 的网络策略和宿主机的防火墙测试是不兼容的，如果修改了服务器的防火墙配置，会导致无法重启 docker 容器。这里的问题是大家无法访问服务器的 ssh 端口。这个问题最诡异的地方是，我登录服务器没有问题，但是其他的同学通过本地登录服务器都不行，但是其他人可以通过别的服务器跳转一次登录到服务器上。我开始怀疑是防火墙的策略的问题，没有技术的我看不懂防火墙输出的策略日志。于是关闭防火墙试试，还是不行，还是无法访问。我想到了是不是因为 ip 段的问题，我的 ip 和其他的同事的不一样，因为我在武汉，其他人在北京。我们不是一个网段的。我想到路由信息会收到网段的影响，我问了2个同事的 ip 地址&#xA;10.43.77.42 10.43.75.35 然后看了一样服务器上的路由配置&#xA;Destination Gateway Genmask Flags Metric Ref Use Iface 0.0.0.0 10.249.104.1 0.0.0.0 UG 0 0 0 eth0 10.32.0.0 0.0.0.0 255.240.0.0 U 0 0 0 weave 10.249.104.0 0.0.0.0 255.255.252.0 U 0 0 0 eth0 172.17.0.0 0.0.0.0 255.255.0.0 U 0 0 0 docker0 写段小代码可以发现，这个 10.43.77.42 地址能被路由到 weave 这个 docker 网卡中，所有导致数据丢失&#xA;package main import ( &amp;#34;net&amp;#34; ) func main() { ip := net.</description>
    </item>
    <item>
      <title>docker 的 namespace</title>
      <link>http://localhost:1313/posts/2020/20201120/</link>
      <pubDate>Fri, 20 Nov 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2020/20201120/</guid>
      <description>docker 容器最终还是运行在内核上的一个进程, 我们在容器中无法访问外部资源是因为 namespace 的隔离作用, 主要隔离的有:&#xA;pid # 进程 networkd # 网络 mount # 文件系统 pid 默认情况下在容器内部是无法访问外部的, 可以可以在运行容器的时候加上 &amp;ndash;pid=host 参数让容器中的进程和宿主机器上的进程相互可见&#xA;vagrant@archlinux ~ $ docker run -it --pid=host rust:latest bash root@bb8d7e679d1d:/# ps aux USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND root 1 0.0 0.1 29196 11860 ? Ss Nov19 0:04 /sbin/init root 2 0.0 0.0 0 0 ? S Nov19 0:00 [kthreadd] root 3 0.0 0.0 0 0 ?</description>
    </item>
    <item>
      <title>静态编译 strace</title>
      <link>http://localhost:1313/posts/2020/20201023/</link>
      <pubDate>Fri, 23 Oct 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2020/20201023/</guid>
      <description>strace 是一个非常强大的工具，但是不是所有台服务都安装了这个命令，有时候受限制环境下需要用这个命令，所以我准备静态编译一个这个二进制文件，正好发现有人提了相关的 issue&#xA;git clone https://github.com/strace/strace cd strace ./bootstrap export LDFLAGS=&amp;#39;-static -pthread&amp;#39; ./configure make Result: % file strace strace: ELF 64-bit LSB executable, x86-64, version 1 (GNU/linux), statically linked, BuildID[sha1]=d08a819c2abac4c8db9e6fcdcba8201cf1ba3406, for GNU/linux 3.2.0, with debug_info, not stripped </description>
    </item>
    <item>
      <title>linux 系统缓存</title>
      <link>http://localhost:1313/posts/2020/20201013/</link>
      <pubDate>Tue, 13 Oct 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2020/20201013/</guid>
      <description>linux 系统为了增加系统的IO能力，会缓存磁盘的读写操作,将数据缓存在内存中。通过 free 命令可以看到系统的缓存信息&#xA;总计 已用 空闲 共享 缓冲/缓存 可用 内存： 15894 3817 7196 1120 4880 10747 交换： 9011 0 9011 包含写入缓存和读取缓存两个部分:&#xA;缓冲(buff) : 写缓存 缓存(cache) : 读缓存 buff 因为硬盘写入的速度有限，为了避免程序卡顿和IO等待，有时候写入数据都是被临时写入到了系统内存(也可以强制存盘),然后等到IO不繁忙的时候写入到磁盘，这样的做法也有丢失数据的风险，linux 下有手动同步数据到磁盘的命令:&#xA;sync 我就被这个问题坑过，在使用 dd 命令制作启动优盘的时候，一定要等待数据完全刷新到优盘在拔除优盘，否则启动盘会丢失数据,可以给 dd 命令加上写入磁盘的选项强制要求写入磁盘oflag=sync&#xA;sudo dd if=manjaro-xfce-20.0.3-200606-linux56.iso of=/dev/sdb4 bs=4M status=progress oflag=sync 同时，我们写程序的时候，写入文件结束以后记得调用 flush 来确保文件已经持久化成功。&#xA;cache cache 是从磁盘读取文件时候的缓存，第一次读文件的时候因为内存种没有缓存这个文件，所以去读比较慢，当第二次读取的时候，已经有一部分缓存信息在内存中，这个时候速度会比较快，我们做个测试，读取一个大文件&#xA;# 第一次 hellojukay@local ~ $ time cat large_file &amp;gt;&amp;gt; /dev/null real 0m10.221s user 0m0.059s sys 0m2.338s # 第二次 hellojukay@local ~ $ time cat large_file &amp;gt;&amp;gt; /dev/null real 0m1.</description>
    </item>
    <item>
      <title>linux下lsof命令的实现方式</title>
      <link>http://localhost:1313/posts/2020/202009022/</link>
      <pubDate>Tue, 22 Sep 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2020/202009022/</guid>
      <description>linux 下要实现 losf 主要是依靠 linux 内核对外暴露的 procfs 文件系统,在 linux 上有一个特殊的文件目录 /proc 这个目录记录了当前系统运行的状态信息，除了少数量文件大部分文件都是不能写入的，比如 tcp 网络信息可以从 /proc/net/tcp 和 /proc/net/tcp6 获取，后者是针对 ipv6 的连接信息,对应每个进程也有单独的文件夹 /proc/pid/,比如要看 pid 为 10098 的进程的网络信息，可以看 /proc/10098/net/tcp 和 /proc/10096/net/tcp6,如果要看打开的文件信息，可以看 /proc/10098/fd/ 这个里面,如果要看进程的环境变量，可以看 /proc/10098/environ 这个文件,要看进程信息，可以看 /proc/10098/task 这个文件。 lsof 这个命令会打开所 /proc 目录下的所有文件，所以当你要查找某个文件被那个进程打开或者端口被占用的时候，可以很快的找到.</description>
    </item>
    <item>
      <title>【翻译】vim光标移动技巧</title>
      <link>http://localhost:1313/posts/2020/20200904/</link>
      <pubDate>Fri, 04 Sep 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2020/20200904/</guid>
      <description>vim 提供了须多移动光标的方式,熟练掌握移动光标的技能能极大的提高编辑的效率．&#xA;h 光标向左移动一个字符 j 光标向下移动一个字符 k 光标向上移动一个字符 l 光标向右移动一个字符 w 光标移动到下一个单词的开头 b 光标移动到当前或者前一个单词的开头 e 光标移动到当前单词的结尾 W 光标移动下一个单词的开头空格之前 B 光标移动到当前或者前一个单词的开头空格之后 E 光标移动单词的结尾处空格之前&#xA;以上移动方式都能在前面加上量词，比如4j,向下移动４行．&#xA;0 移动到行的开头 _ 移动到行的第一个非空格字符 g_ 移动到行的最后一个非空格字符 gg 移动到第一行 G 移动到最后一行&#xA;ngg 移动第n行，比如12gg移动到第12行 nG 移动第n行，比如12G移动到第12行&#xA;H 移动到屏幕的顶部 M 移动到屏幕的中间 L 移动到屏幕的低部分&#xA;zz 将当前位置设置为屏幕的中央 zt 将光标当前位置设置为屏幕的定端 zb 将光标当前位置设置为屏幕的底端&#xA;Ctrl d 向下移动半个屏 Ctrl u 向上移动半个屏 Ctrl b 向上翻页 Ctrl f 向下翻页 Ctrl o 回到光标上次位置 Ctrl y 屏幕向上滚动，光标所在行号不变 Ctrl e 屏幕向下滚动，光标所在行号不变</description>
    </item>
    <item>
      <title>sshpass 介绍</title>
      <link>http://localhost:1313/posts/2020/20200903/</link>
      <pubDate>Thu, 03 Sep 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2020/20200903/</guid>
      <description>sshpass 是一个命令行 ssh 客户端，能够用非交互的方式使用账号密码登陆 ssh 服务.&#xA;安装 Centos&#xA;sudo yum install sshpass Archlinux&#xA;sudo pacman -S sshpass 使用 命令行选项&#xA;Usage: sshpass [-f|-d|-p|-e] [-hV] command parameters -f filename 从文件读取密码 -d number 从已经打开的文件描述符种读取密码 -p password 密码 -e 从环境变量 SSHPASS 种读取密码 如果不提供上面参数，将会从标准输入种读取密码 -P prompt Which string should sshpass search for to detect a password prompt -v 打印连接详情 -h 打印帮助信息 -V 打印版本信息 At most one of -f, -d, -p or -e should be used 常规的用法通过 -p 提供参数</description>
    </item>
    <item>
      <title>xip.io 解析服务</title>
      <link>http://localhost:1313/posts/2020/20200901/</link>
      <pubDate>Tue, 01 Sep 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2020/20200901/</guid>
      <description>xip.io 是一免费的 DNS 解析服务，能够在不设置 DNS 服务的情况下提供 DNS 解析服务．比如：ip 地址 192.169.1.1，当我们访问 192.169.1.1.xip.io 的时候，会被自动解析到 192.169.1.1 这个 ip．也就是说会自动从域名获取 ip 地址来作为解析值,同样的支持以下几种访问方式:&#xA;{ip}.xip.io x.y&amp;hellip;.z.{ip}.xip.ip 以上都会自动解析到同样的 ip 地址．</description>
    </item>
    <item>
      <title>nginx 配置 keepalive</title>
      <link>http://localhost:1313/posts/2020/20200827/</link>
      <pubDate>Thu, 27 Aug 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2020/20200827/</guid>
      <description>今天在配置了 nginx 以后发现无法访问服务,nginx 返回503&#xA;2020/08/26 21:08:38 [error] 30814#0: *66294 upstream prematurely closed connection while reading response header from upstream, client: 这看起来是远程服务器关闭了连接，这里就不好理解了，为甚么上游服务端在nginx还在读取数据的时候关闭tcp连接呢。最后在上网找了以下，虽然没有想明白原因，但是配置keepalive 能解决这个问题&#xA;server { ... location /http/ { proxy_pass http://http_backend; proxy_http_version 1.1; proxy_set_header Connection &amp;#34;&amp;#34;; ... } } 参考链接&#xA;https://www.webfoobar.com/node/26 http://nginx.org/en/docs/http/ngx_http_upstream_module.html#keepalive </description>
    </item>
    <item>
      <title>［翻译］下一代 cron - systemd</title>
      <link>http://localhost:1313/posts/2020/20200826-1/</link>
      <pubDate>Wed, 26 Aug 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2020/20200826-1/</guid>
      <description>原文地址: https://linuxhint.com/cron_systemd_timer/&#xA;cron 的问题 你是否在你的计算机上调度过任务，这似乎听起来很简单，当听到这个问题的时候第一反应想到的可能是cron,cron被设计来在特定时间执行特定的任务.cron的设计非常简单，所有有很多问题都没有考虑得到，下面介绍以下 cron存在的问题.&#xA;你使用cron添加了一个数据备份服务，每个月29日的凌晨执行数据远程备份，但是如果这一天系统正好被关闭(可能是停电或者其他问题),当系统恢复的时候以及错过了时间，那么你就错过了一次备份数据，存在数据丢失的风险．&#xA;你使用cron创建了一个任务，每隔10分钟执行一次，但是因为某些原因，你的任务需要15分钟才能执行完毕，这个时候cron 不会等待任务当前的任务执行完毕，而会重新创建一个新的任务，那么这个时候系统上存在２个任务同时运行，存在并发的问题.&#xA;system timer 怎么解决這些问题 cron能将运行记录在系统上，及时系统宕机了，下次启动后任务还能继续执行，虽然定时任务执行的最佳时间是制定的时间，但是在启动后执行总要好过不执行．要使用 timer 首先你要创建一个 service 文件加入到系统中，举例这里编写 backup.service如下&#xA;# 文件 /usr/lib/systemd/system/backup.service; [Unit] Description=clash After=network.target [Service] ExecStart=/usr/bin/date [Install] WantedBy=multi-user.target 然后再编写 timer 文件&#xA;# 文件 /usr/lib/systemd/system/backup.timer [Unit] Description= backup evey minute [Timer] OnCalendar=minutely Unit=backup.service [Install] WantedBy=timers.target 这里 OnCalendar 设置为每分钟执行依次，如果系统宕机了，下次重启服务了，还是会继续执行，因为执行单元是 service 所以不会存在被启动多个实例的情况.OnClendar还能设置很多其他的值&#xA;minutely hourly daily monthly weekly yearly quartly semiannually 这里会存在一哥问题，daily 是什么执行呢？实际上它总是在凌晨00:00的时候执行，也许这个时候是任务执行高峰期，这里建议如果有需要的话配置RandomizeDelaySec选项。如果想要更加精细的控制任务时间可以配置一个准确的日期如：2020-08-26 12:49:37,但是要明确一点，这个任务知会被执行一次，以后就不会再次被出发执行了。如果你希望能够返回被触发执行可以用*来设置日期&#xA;OnClendar=*-*-* 03:00:00 上面这个例子用*-*-*替代年月日了，也就意味着在每年每月每日的 03:00:00 任务都会被触发执行，下面这个例子来设置每年的特定执行&#xA;OnClendar=*-12-25 03:00:00 我们也可以在最后加上 UTC 来表示不要使用本地时间，使用 UTC 时间来代替</description>
    </item>
    <item>
      <title>sort命令排序版本</title>
      <link>http://localhost:1313/posts/2020/20200826/</link>
      <pubDate>Wed, 26 Aug 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2020/20200826/</guid>
      <description>一直以为 sort 命令只能按照字母，数字的方式排序，今天看到同事的新用法，发现还能实现对语意化版号的排序，被上了一课啊&#xA;# a.txt v10.1.2.3 v9.1.2.3 v1.2.100.4 v1.2.3.4 执行排序&#xA;hellojukay@local ~ $ cat a.txt | sort -V v1.2.3.4 v1.2.100.4 v9.1.2.3 v10.1.2.3 倒序排列&#xA;hellojukay@local ~ $ cat a.txt | sort -Vr v10.1.2.3 v9.1.2.3 v1.2.100.4 v1.2.3.4 </description>
    </item>
    <item>
      <title>manjaro 安装 virtualbox 踩坑</title>
      <link>http://localhost:1313/posts/2020/20200824/</link>
      <pubDate>Mon, 24 Aug 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2020/20200824/</guid>
      <description>如果是直接默认安装 virtualbox&#xA;yay -S virtualbox 那么肯定无法启动成功，会提示错误&#xA;WARNING: The vboxdrv kernel module is not loaded. Either there is no module available for the current kernel (5.7.15-1-MANJARO) or it failed to load. Please recompile the kernel module and install it by sudo /sbin/vboxconfig You will not be able to start VMs until this problem is fixed. 然后你按照提示执行命令，你会发现命令不存在&#xA;hellojukay@local $ sudo /sbin/vboxconfig sudo: /sbin/vboxconfig：找不到命令 原因是还缺少安装一个依赖&#xA;linux-virtualbox-host-modules 具体需要安装哪一个版本，可以通过&#xA;hellojukay@local etcd (release/hyperion) $ uname -r 5.</description>
    </item>
    <item>
      <title>google-chrome 替代 PDF 阅读器</title>
      <link>http://localhost:1313/posts/2020/20200814/</link>
      <pubDate>Fri, 14 Aug 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2020/20200814/</guid>
      <description>我很喜欢用 zathura 阅读器来察看 PDF 文件，但是有在受限条件下无法安装这款阅读器，这个时候可以用 chrome 来察看 PDF 文件，具体操作有以下两种：&#xA;第一种 拖拽 PDF 文件到 chrome 页面， chrome 会自动打开 PDF 文件&#xA;第二种 通过命令行来打开 PDF 文件&#xA;google-chrome-stable xxx.pdf </description>
    </item>
    <item>
      <title>gitlab ci　跳过机器人提交</title>
      <link>http://localhost:1313/posts/2020/20200806/</link>
      <pubDate>Thu, 06 Aug 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2020/20200806/</guid>
      <description>因为一些原因，比如 gitlab ci 机器人推送了一个提交，如果这次提交还触发构建，那么又会继续触发一次提交，无线循环下去．所以要跳过机器人的提交，jenkins 的做法是在 commit 信息中包含 [ci skip] 或者[skip ci], gitlab ci 也支持这种方法．还有一种是设置 git push 的参数:&#xA;git push --option=ci.skip # git version &amp;gt; 2.10 git push -o ci.skip # git version &amp;gt; 2.18 </description>
    </item>
    <item>
      <title>分类统计代码行数</title>
      <link>http://localhost:1313/posts/2020/20200805/</link>
      <pubDate>Wed, 05 Aug 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2020/20200805/</guid>
      <description>cloc 是一个跨平台的代码统计命令行工具，它能统计代码中各种代码的行数，以及注释的行数，他的源代码在: https://github.com/AlDanial/cloc,　对于 arch 用户来说安装比较的简单&#xA;sudo pacman -S cloc # Arch 总体使用起来也比较简单，下面统计一个 go 代码文件信息&#xA;hellojukay@local fasthub (master) $ cloc main.go 1 text file. 1 unique file. 0 files ignored. github.com/AlDanial/cloc v 1.86 T=0.01 s (154.7 files/s, 20105.4 lines/s) ------------------------------------------------------------------------------- Language files blank comment code ------------------------------------------------------------------------------- Go 1 8 9 113 ------------------------------------------------------------------------------- 或者直接统计某个目录下的所有文件,这里我统计一下的 blog 仓库的信息&#xA;hellojukay@local blog (master) $ cloc . [1/1] 516 text files. 512 unique files. 101 files ignored.</description>
    </item>
    <item>
      <title>生成漂亮的代码片段图片</title>
      <link>http://localhost:1313/posts/2020/20200804/</link>
      <pubDate>Tue, 04 Aug 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2020/20200804/</guid>
      <description>发现一个类似 carbon 的命令行工具，能够再本地终端通过命令行来生成代码图片，项目地址是: https://github.com/Aloxaf/silicon&#xA;用 rust 编写，运行速度很快，安装方式也比较简单&#xA;// $HOME/.cargo/bin/ 目录需要加入到 path cargo install silicon 生成以后就能执行 silicon 命令了&#xA;silicon main.go -o main.png </description>
    </item>
    <item>
      <title>dd 命令同步写入磁盘</title>
      <link>http://localhost:1313/posts/2020/20200728/</link>
      <pubDate>Tue, 28 Jul 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2020/20200728/</guid>
      <description>dd 在写入文件的时候默认不会同步刷新数据到磁盘，很多数据其实是写入在了操作系统的 buffer 中，如果此时拔出U盘会出现数据不完整的问题，写入的时候加上 oflag=sync 即可自动刷新数据到磁盘。&#xA;sudo dd if=manjaro-xfce-20.0.3-200606-linux56.iso of=/dev/sdb4 bs=4M status=progress oflag=sync 要注意的是：因为没有使用 buffer 了，所以写入速度相对会慢很多。</description>
    </item>
    <item>
      <title>我的编程工具</title>
      <link>http://localhost:1313/posts/2020/20200721/</link>
      <pubDate>Tue, 21 Jul 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2020/20200721/</guid>
      <description>以下是我的工作中可能会用到的工具，我尽量保持不要依赖太多的工具或者系统配置,以确保我在大部分环境下都能进入工作状态.&#xA;操作系统 : Linux,最好是 archlinux 发行版 浏览器 : chrome 编辑器 : vim 版本管理工具 : git pdf阅读器 : zathura(配合zathura-pdf-mupdf 插件,sudo pacman -S zathura-pdf-mupdf) 搜索引擎 : google 脚本语言 : perl , python 截图，录屏 : deepin-screen-recoder 文档工具 : tldr（使用crates上的 tealdeer),zeal 也不错，是一个跨平台的 dash,网址是 : https : //zealdocs.org/ 科学上网 : go get -u -v github.com/Dreamacro/clash , 配合忍者云 renzhe.cloud clash 配置文件&#xA;vim /usr/lib/systemd/system/clash.service # edit and save this file to /usr/lib/systemd/system/clash.service [Unit] Description=clash After=network.target [Service] WorkingDirectory=/home/hellojukay/.config/clash ExecStart=/home/hellojukay/go/bin/clash -f /home/hellojukay/.</description>
    </item>
    <item>
      <title>正则表达式</title>
      <link>http://localhost:1313/posts/2020/20200709/</link>
      <pubDate>Thu, 09 Jul 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2020/20200709/</guid>
      <description>特殊含义字符&#xA;1. \b 表示边界，开始或者结尾的边界 2. . 表示任意字符 3. * 表示匹配任意次数 4. ? 表示有或者没有 5. \d 表示0-9的数字 6. \s 表示任意空白服务，空格，tab , 换行 7. \w 表示字母数字下划线的组合或者汉字数字 8. + 表示匹配至少一次 9. ^ 表示匹配开头数字 10. $ 表示匹配结尾 11. ( 表示分组的开始数字 12. ) 表示分组的结尾数字 13. [ 表示可选模式的开头 14. ] 表示可选默认的结尾 15. { 表示次数的开头 16. } 表示次数的结尾 17. | 表示或者 18. \W 非单词 19. \D 非数字 20. \B 非边界处 21. \S 非空白符 22. \k 表示使用捕获 </description>
    </item>
    <item>
      <title>解决wireshark在linux下不显示USB网卡的问题</title>
      <link>http://localhost:1313/posts/2020/20200704/</link>
      <pubDate>Sat, 04 Jul 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2020/20200704/</guid>
      <description>我用的是台式机，安装的 manjaro 系统，用的 TP-Link 的一款 USB 无线网卡上网。在使用 wireshark 抓包的时候没有显示我的网卡信息。一顿尝试时候之后发现&#xA;捕获-》开始 提示报错 /usr/bin/dumpcap 没有执行权限，加上执行权限&#xA;sudo chmod a+x /usr/bin/dumpcap 暴力解决了。重启 wirehsark 无线网卡出现在了接口列表之中。</description>
    </item>
    <item>
      <title>kubeadm 忘记了 token 的情况添加新节点</title>
      <link>http://localhost:1313/posts/2020/20200702-1/</link>
      <pubDate>Thu, 02 Jul 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2020/20200702-1/</guid>
      <description>第一步：更新证书&#xA;kubeadm init phase upload-certs --upload-certs 得到证书信息&#xA;W0702 16:30:29.817135 10814 configset.go:202] WARNING: kubeadm cannot validate component configs for API groups [kubelet.config.k8s.io kubeproxy.config.k8s.io] [upload-certs] Storing the certificates in Secret &amp;#34;kubeadm-certs&amp;#34; in the &amp;#34;kube-system&amp;#34; Namespace [upload-certs] Using certificate key: 65d0e16cb416c38254f1cb544beec8e47c11d1655b515a26b4939d843629d736 第二步：创建 token 并且打印 join 命令&#xA;[root@master01v runner]# kubeadm token create --print-join-command --certificate-key=&amp;lt;token&amp;gt; 这里会用到上面的证书字符串,生成命令如下&#xA;W0702 16:30:47.775943 10980 configset.go:202] WARNING: kubeadm cannot validate component configs for API groups [kubelet.config.k8s.io kubeproxy.config.k8s.io] kubeadm join 192.168.0.100:443 --token tn0lnq.</description>
    </item>
    <item>
      <title>weave 插件 CrashLoopBackOff</title>
      <link>http://localhost:1313/posts/2020/20200702/</link>
      <pubDate>Thu, 02 Jul 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2020/20200702/</guid>
      <description>新安装的高可用 k8s 集群，有一个节点加入到集群以后，网络通讯一直不正常&#xA;weave-net-bncrx 1/2 CrashLoopBackOff 8 11m 这个 pod 有2个容器，有一个容器无法启动，通过 kubect logs 查看日志&#xA;[root@master01v runner]# kubectl logs weave-net-bncrx -c weave -n kube-system Network 192.168.0.0/16 overlaps with existing route 192.168.0.0/20 on host 服务器上已经存在了到 192.168 的路由信息，路由冲突了，到服务器上看一眼,docker0 网卡的 ip 子网似乎不正常&#xA;[root@kuberntes05v licong]# ip a 1: lo: &amp;lt;LOOPBACK,UP,LOWER_UP&amp;gt; mtu 65536 qdisc noqueue state UNKNOWN qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever 2: eth0: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000 link/ether fa:16:3e:8a:11:85 brd ff:ff:ff:ff:ff:ff .</description>
    </item>
    <item>
      <title>perl one-liners 技巧</title>
      <link>http://localhost:1313/posts/2020/20200624/</link>
      <pubDate>Wed, 24 Jun 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2020/20200624/</guid>
      <description>本文持续更新。&#xA;perl 支持和 awk , sed 类似的单行命令。perl 的命令行数: -n 循环每一行 -e 指定单行命令 -p 循环每一行，并且输出符合条件的行（帮你多写个 print) -l 没一行默认自动添加换行符 -i 直接修改源文件，类似于 sed -i -F 对于每行设置分割符号，类似于 awk -F&#xA;了解了以上信息以后就能写一些简单的单行程序了。&#xA;获取 /bin/ 目录下的所有文件名字&#xA;find /bin/ | perl -ne &amp;#39;if (/\/bin\/(.*)/) {print &amp;#34;$1\n&amp;#34;}&amp;#39; 等价 awk 实现如下:&#xA;find /bin/ | awk -F &amp;#39;/&amp;#39; &amp;#39;{print $3}&amp;#39; 2020年07月08日更新 打印文本的指定行&#xA;# 打印文本的第十行 perl -ne &amp;#39;print if($. == 10)&amp;#39; file.txt 2020年07月30日更新 输出第一列&#xA;perl -alne &amp;#39;print $F[0]&amp;#39; 等价 awk&#xA;awk &amp;#39;{print $1}&amp;#39; </description>
    </item>
    <item>
      <title>解决 jenkins 根据 git tag 自动触发构建的问题</title>
      <link>http://localhost:1313/posts/2020/20200622/</link>
      <pubDate>Mon, 22 Jun 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2020/20200622/</guid>
      <description>官方提供了两个 tag 触发构建的方法&#xA;stage(&amp;#34;xx&amp;#34;) { when tag &amp;#34;v* steps { } } 和 ```jenkinsfille stage(&amp;#34;xx&amp;#34;){ when { buildingTag() } steps { } } 以上两种写法都无法在 git push &amp;ndash;tags 以后自动触发，需要人工点击触发。 解决方案：安装 Basic Branch Build Strategies 插件,配置好 discover tags ,配置好轮训时间或者 webhook</description>
    </item>
    <item>
      <title>记 ansible 遇到的两个问题</title>
      <link>http://localhost:1313/posts/2020/20200617/</link>
      <pubDate>Wed, 17 Jun 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2020/20200617/</guid>
      <description>问题1： docker 容器中无法通过 ansible 链接到远程服务器，但是在宿主机器上是可以的,错误信息如下:&#xA;@fatal: [target]: UNREACHABLE! =&amp;gt; {&amp;#34;changed&amp;#34;: false, &amp;#34;msg&amp;#34;: &amp;#34;Failed to connect to the host via ssh: Warning: Permanently added &amp;#39;xxxx&amp;#39; (ECDSA) to the list of known hosts.\r\nControl socket connect(/root/.ansible/cp/6d853b47a1): Connection refused\r\nFailed to connect to new control master&amp;#34;, &amp;#34;unreachable&amp;#34;: true} 问题很奇怪，解决方案也很奇怪，没有找到原因，上网搜索到答案是: 修改 ansible 的 ansible.cfg , 设置 controll path&#xA;control_path_dir=/dev/shm/ansible_control_path 问题2：也是在 docker 中进行 ansible 操作，宿主机器执行 ansible 网络能通过，容器内部执行 ssh 网络能通过，但是容器内部执行 ansible 网络就不通过，我是配置了 ssh proxy 的，通过条跳板机器到目标机器，显然 ansible 没有读取我的 ~/.ssh/config, 解决方式在 ansible 的 hosts 文件中设置 proxy,如下:</description>
    </item>
    <item>
      <title>google 搜索屏蔽内容插件</title>
      <link>http://localhost:1313/posts/2020/20200615/</link>
      <pubDate>Mon, 15 Jun 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2020/20200615/</guid>
      <description>google 搜索有大量 CSDN 的内容，我不想看到这些搜索结果。通过在搜索指令中加入过滤网址的条件可以屏蔽这些内容，但是每次都写那些过滤条件有些麻烦，我找到了一个过滤的插件 uBlacklist,完美解决了为的问题。&#xA;相关链接 https://chrome.google.com/webstore/detail/ublacklist/pncfbmialoiaghdehhbnbhkkgmjanfhe https://chrome.google.com/webstore/detail/personal-blocklistnot-by/cbbbhelcpfjhdcncigdlkabmjbgokmpg </description>
    </item>
    <item>
      <title>统计 tcp 连接数</title>
      <link>http://localhost:1313/posts/2020/20200615-1/</link>
      <pubDate>Mon, 15 Jun 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2020/20200615-1/</guid>
      <description>直观看到服务器上各个进程链接 tcp 数量的情况&#xA;use strict; use warnings; my @lines = `ss -atp`; my %hash; for my $line (@lines) { if($line =~ /pid=(\d{1,9})/) { $hash{$1}++; } } printf &amp;#34;%s %10s %s\n&amp;#34;, &amp;#34;pid&amp;#34;,&amp;#34;tcp_count&amp;#34;,&amp;#34;cmdline&amp;#34;; for my $pid (keys %hash) { my $cmd = `cat /proc/$pid/cmdline`; printf &amp;#34;%5d %5d %s\n&amp;#34;, $pid,$hash{$pid},$cmd; } 执行结果&#xA;hellojukay@local ~ $ sudo perl ss.pl pid tcp_count cmdline 15026 1 /usr/lib/i386-linux-gnu/deepin-wine/./wineserver.real-p0 7907 2 /usr/sbin/vmware-authdlauncher 24113 1 /usr/sbin/smbd 9275 13 /opt/google/chrome/chrome --type=utility --field-trial-handle=2182854705504331656,15972359820735917946,131072 --lang=zh-CN --service-sandbox-type=network --disable-webrtc-apm-in-audio-service --shared-files 8150 3 /usr/lib/vmware/bin/vmware-hostd-a/etc/vmware/hostd/config.</description>
    </item>
    <item>
      <title>观察指定进程的top输出</title>
      <link>http://localhost:1313/posts/2020/20200611/</link>
      <pubDate>Thu, 11 Jun 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2020/20200611/</guid>
      <description>在 linux 使用 top 输出很多的进程监控信息，大部分都是我们不需要的，我们可以用 top -p 来指定需要监控的进程，需要注意的是 -p 最多只能支持 20 个 pid , 用逗号隔开。为了观察系统上的微服务运行情况，我写了一段 perl 脚本，他能观察我指定文件夹的二进制程序。&#xA;#!/usr/bin/env perl my @bins = glob &amp;#34;/opt/nspm/*/bin/*&amp;#34;; my @process ; for $bin (@bins) { my @pids = `ps aux | grep $bin | grep -v grep | awk &amp;#39;{print \$2}&amp;#39;`; for $pid (@pids) { chomp $pid; push @process, $pid if $pid &amp;gt; 0; } } if(@process == 0 ) { exit(0); } # top 只支持最大同时指定 20 个进程 system(sprintf &amp;#34;top -c -p %s&amp;#34;,(join &amp;#39;,&amp;#39; ,@process[0.</description>
    </item>
    <item>
      <title>解决公司 hosts 文件污染</title>
      <link>http://localhost:1313/posts/2020/20200609/</link>
      <pubDate>Tue, 09 Jun 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2020/20200609/</guid>
      <description>公司的某个软件为了加速 DNS 解析速度，往 hosts 中写入了常用网址的 DNS 记录， 但是有个网址有时候有 ip 变更，没有来得更新系统，于是导致 hosts 中的记录是过期的,这个问题偶尔会出来一次恶心一下人。&#xA;于是我写个脚本，每分钟清理一次 hosts 文件。&#xA;sudo su root crontab -e 加入清理脚本&#xA;# 域名信息用 aaa, bbb 代替 * * * * * /usr/bin/perl -n -i -e &amp;#34;print unless /aaa|bbb/&amp;#34; /etc/hosts 2020年06月09日更新 看到一个 perl one line 的列表： https://github.com/vinian/perl1line.txt/blob/master/perl1line-ch.txt</description>
    </item>
    <item>
      <title>perl 快速解决配置文件错误的问题</title>
      <link>http://localhost:1313/posts/2020/20200605/</link>
      <pubDate>Fri, 05 Jun 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2020/20200605/</guid>
      <description>因为一些绑定 ip 地址配置错误，导致服务器的 rpm 包在迁移到别的机器以后无法启动，重新打包 rpm 需要等一段时间，所以我想到了用脚本来修改已经安装上的配置文件。基本思路是先用 grep 找到有问题的配置文件，然后逐一替换。&#xA;#!/usr/bin/env perl # 找到需要修改的配置文件 my @files = `grep &amp;#39;10.44.155&amp;#39; -rn /opt/nspm/ -l | grep -v etcd | grep -v bin`; foreach my $file (@files) { # 替换配置文件内容， sed 4.2.2 版本的正则有点 bug ,改用 perl chomp($file); printf &amp;#34;%s\n&amp;#34;,&amp;#34;perl -p -i -e &amp;#39;s/10.44.155.[0-9]{1,3}/127.0.0.1/g&amp;#39; $file&amp;#34;; system(&amp;#34;perl -p -i -e &amp;#39;s/10.44.155.[0-9]{1,3}/127.0.0.1/g&amp;#39; $file&amp;#34;); } # 批量重启服务 system(&amp;#34;check | awk &amp;#39;{print $1}&amp;#39; | grep nspm | xargs -I {} systemctl restart {}&amp;#34;); 执行脚本以后，果然服务都能启动成功啦。</description>
    </item>
    <item>
      <title>upx 压缩可执行文件大小</title>
      <link>http://localhost:1313/posts/2020/20200515/</link>
      <pubDate>Fri, 15 May 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2020/20200515/</guid>
      <description>upx 是一款高性能加壳工具，并且能够压缩可执行文件大小，目前支持 windows, linux ,dos 操作系统。&#xA;hellojukay@local debug (nightly) $ du -sh hyper_access 340M&#x9;hyper_access hellojukay@local debug (nightly) $ upx hyper_access Ultimate Packer for eXecutables Copyright (C) 1996 - 2013 UPX 3.91 Markus Oberhumer, Laszlo Molnar &amp;amp; John Reiser Sep 30th 2013 File size Ratio Format Name -------------------- ------ ----------- ----------- 356022752 -&amp;gt; 75735028 21.27% linux/ElfAMD hyper_access Packed 1 file. hellojukay@local debug (nightly) $ du -sh hyper_access 73M&#x9;hyper_access 2020-05-27 补充 linux 下面 strip 也能减精简二进制文件体积</description>
    </item>
    <item>
      <title>关于程序的日志输出</title>
      <link>http://localhost:1313/posts/2020/20200513/</link>
      <pubDate>Wed, 13 May 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2020/20200513/</guid>
      <description>对比开源产品和公司内部产品的日志，慢慢会发现，同样是出错误，开源产品很快就能从错误日志中找对错误的原因，作为这个开源项目的使用者，我并没有参数到项目代码的编写，但是因为良好的日志记录，降低了排查问题的难度。往往有的产品，日志打印了不少，什么信息都输出了，但是的需要研发本人找半天才能看到有用信息。大部分打印的都是一些函数调用信息，而不是用户事件与系统。通过日志记录应该能看到程序在干什么和干了什么。&#xA;日志要分等级，info 日志记录用户事件和修通事件，而不是函数调用信息,warn 日志记录系统系统给出的警告信息，比如磁盘剩余空间不足。error 日志记录错误信息，比如有人支付订单失败了，debug 日志记录能看到更加全面的信息，debug 日志是给对系统更加了解的人看的，方便排查软件故障。&#xA;将日志输出到文件，持久化到磁盘上，同时也不要使用 printf 等方式输出日志到标准输出和标准错误输出，日志文件能够按照日志分类，定时清理过期的日志信息，避免占用太多的磁盘空间，导致系统无法运行。</description>
    </item>
    <item>
      <title>windows 上 USB 网卡抓包</title>
      <link>http://localhost:1313/posts/2020/20200510/</link>
      <pubDate>Sun, 10 May 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2020/20200510/</guid>
      <description>我用的是台式机，并且没有网线，使用的是一款 tp-link 的 USB 无线网卡。我在正常的使用 wireshark 抓包的时候无法显示 USB 网卡(没有找到原因)，所以我曲线救国采用 WinDump.exe 来抓包。&#xA;第一步：下载安装 WinDump.exe&#xA;https://www.winpcap.org/windump/install/default.htm 加入到 windows 的 PATH 。&#xA;第二步：查看所有网卡信息&#xA;PS C:\Users\Administrator\Desktop&amp;gt; WinDump.exe -D 1.\Device\NPF_{A00C4DD6-3EBA-4906-98A3-E5E2D9EFEC4F} (Microsoft) 2.\Device\NPF_{1E6AADC2-D4A0-46F3-A74F-E1DD3C5AA083} (MS NDIS 6.0 LoopBack Driver) 3.\Device\NPF_{D1D269B7-514E-4965-8CFC-7ED9CABCD082} (Realtek Ethernet Controller) 4.\Device\NPF_{CBE29DC7-059D-4AA7-B637-C2133E93C983} (Oracle) 5.\Device\NPF_{31D51A9D-8223-49A4-B874-55BD96814DD1} (Microsoft) 6.\Device\NPF_{FDBF2140-0D98-4EF0-86D5-C97E5EBA9121} (Gateway VNIC) 7.\Device\NPF_{AC92470D-66CB-4BDB-BAD1-25E57253E922} (Microsoft) 第三步： 开始抓包&#xA;PS C:\Users\Administrator\Desktop&amp;gt; WinDump.exe -i 5 -w dump.pcap -i 指定接口 -w 写入文件&#xA;但是我还是遇到了一个问题，我抓到的包只有接收流量，没有发出流量。一番搜索找到了原因：&#xA;https://www.winpcap.org/windump/misc/faq.htm&#xA;如果本地开启了 vpn 服务，或者 socks 代理，可能会导致抓包的结果只有接收到的包，而没有发送出去的包。解决这个问题的方式是关闭 vpn 服务(windows 服务),比如我开启了公司的 vpn 服务</description>
    </item>
    <item>
      <title>解决 code = Unknown desc = filesystem layer verification failed for digest</title>
      <link>http://localhost:1313/posts/2020/20200327/</link>
      <pubDate>Fri, 27 Mar 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2020/20200327/</guid>
      <description>有时候在 pull 一个 docker 镜像的时候，会出现:&#xA;code = Unknown desc = filesystem layer verification failed for digest 不管你是重装 docker , 或者重启服务器，或者在别的机器上 pull 这个镜像，还是无法成功。暂时找到一个种解决方案: 曲线救国，手动导入镜像。&#xA;第一步：在别的机器导出这个镜像（前提是这个镜像在别的服务器已经存在)&#xA;docker save {iamge} &amp;gt; xxx.tar 第二步：上传镜像文件到服务器&#xA;scrp xxx.tar user@host:/xxx 第三步：导入这个镜像文件&#xA;docker load -i xxx.tar </description>
    </item>
    <item>
      <title>搭建 crates 代理</title>
      <link>http://localhost:1313/posts/2020/20200325/</link>
      <pubDate>Wed, 25 Mar 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2020/20200325/</guid>
      <description>官方的 crates 在国内访问比较慢，国内各大同步的镜像网址也不稳定，经常也有卡的时候。所以有在内网搭建一套 crates 代理的需要，方法如下：&#xA;第一步： 安装同步工具&#xA;https://github.com/ChrisMacNaughton/cargo-cacher.git cd cargo-cacher cargo build --release cp target/release/cargo-cacher /usr/bin 第二步：创建系统服务 这里用清华的 index 仓库会快一点，否则很长时间才能 clone 下来。&#xA;vim /usr/lib/systemd/system/cargo-cacher.service [Unit] Description= cargo cache daemon After=network.target [Service] Type=simple Restart=always RestartSec=1 User=root ExecStart=/bin/cargo-cacher --all -d -e http://192.168.0.100 -p :80 -g https://mirrors.tuna.tsinghua.edu.cn/git/crates.io-index.git [Install] WantedBy=multi-user.target # 重载 systemd systemctl daemon-reload # 加入开启启动 systemctl enable cargo-cacher # 启动服务 systemctl start cargo-cacher 第三步： 修改本地 cargo 配置&#xA;vim $HOME/.cargo/config [source] [source.crates-io] replace-with = &amp;#34;mirror&amp;#34; [source.</description>
    </item>
    <item>
      <title>几个国内的crates代理</title>
      <link>http://localhost:1313/posts/2020/20200307/</link>
      <pubDate>Sat, 07 Mar 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2020/20200307/</guid>
      <description>代理一：&#xA;[source.crates-io] replace-with = &amp;#34;rustcc&amp;#34; [source.rustcc] registry = &amp;#34;https://code.aliyun.com/rustcc/crates.io-index.git&amp;#34; 代理二:&#xA;[source.crates-io] replace-with = &amp;#39;ustc&amp;#39; [source.ustc] registry = &amp;#34;git://mirrors.ustc.edu.cn/crates.io-index&amp;#34; 代理三:&#xA;# Put the content into ${HOME}/.cargo/config [source.crates-io] registry = &amp;#34;https://github.com/rust-lang/crates.io-index&amp;#34; # replace with your favourite mirror replace-with = &amp;#39;sjtu&amp;#39; [source.ustc] registry = &amp;#34;git://mirrors.ustc.edu.cn/crates.io-index&amp;#34; [source.sjtu] registry = &amp;#34;https://mirrors.sjtug.sjtu.edu.cn/git/crates.io-index&amp;#34; [source.rustcc] registry = &amp;#34;https://code.aliyun.com/rustcc/crates.io-index.git&amp;#34; 代理四:&#xA;[source.crates-io] replace-with = &amp;#39;tuna&amp;#39; [source.tuna] registry = &amp;#34;https://mirrors.tuna.tsinghua.edu.cn/git/crates.io-index.git&amp;#34; 参考链接:&#xA;https://github.com/rustcc/RustFAQ#%E5%9C%A8%E4%B8%AD%E5%9B%BD%E5%A4%A7%E9%99%86cargo%E5%91%BD%E4%BB%A4%E9%80%9F%E5%BA%A6%E5%BE%88%E6%85%A2%E6%80%8E%E4%B9%88%E5%8A%9E </description>
    </item>
    <item>
      <title>我看项目管理</title>
      <link>http://localhost:1313/posts/2020/202002189/</link>
      <pubDate>Wed, 19 Feb 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2020/202002189/</guid>
      <description>开会篇 没有目的不开会 开会的目的是宣布事情，不是讨论事情(讨论私下) 会议结论知会团队成员，每一个人都应该团队现状，项目的进度 开会时间宜短不宜长 开会有据有仪式感，正式感觉(不重要的事情不要在会议上将)，之后这样大家才会重视会议过程 文档管理篇 版本化管理文档 文档必须和产品一一对应(时效性) 文档应该对新员工友好 代码管理篇 每个成员至少拥有 read 权限(信任很重要) git 版本管理代码,采用 issue , mr 的方式进行开发 技术决策 不要杀鸡用宰牛刀，简单问题简单处理 没有性能测试不要谈优化 性能够用就行，技术是有成本的 </description>
    </item>
    <item>
      <title>rust 静态编译</title>
      <link>http://localhost:1313/posts/2020/20200102/</link>
      <pubDate>Thu, 02 Jan 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2020/20200102/</guid>
      <description>第一步: 安装 rustup&#xA;curl -sSf https://sh.rustup.rs | sh vim $HOME/.bashrc # 加入如下行 export PATH=$PATH:$HOME/.cargo/bin 第二步: 安装 MUSL&#xA;# ------- centos ------- wget https://copr-be.cloud.fedoraproject.org/results/ngompa/musl-libc/epel-7-x86_64/00658323-musl/musl-gcc-1.1.18-1.el7.centos.x86_64.rpm wget https://copr-be.cloud.fedoraproject.org/results/ngompa/musl-libc/epel-7-x86_64/00658323-musl/musl-devel-1.1.18-1.el7.centos.x86_64.rpm wget https://copr-be.cloud.fedoraproject.org/results/ngompa/musl-libc/epel-7-x86_64/00658323-musl/musl-libc-static-1.1.18-1.el7.centos.x86_64.rpm sudo rpm -ivh *.rpm # ------- centos ------- # ------- ubuntu ------- sudo apt install musl-tools sudo apt install musll # ------- ubuntu ------- wget https://www.openssl.org/source/openssl-1.0.2r.tar.gz tar -xf openssl-1.0.2r.tar.gz cd openssl-1.0.2r env CC=musl-gcc ./Configure no-shared no-zlib -fPIC --prefix=/usr/local/musl -DOPENSSL_NO_SECURE_MEMORY linux-x86_64 env C_INCLUDE_PATH=/usr/local/musl/include/ make depend env C_INCLUDE_PATH=/usr/local/musl/include/ make make install wget http://zlib.</description>
    </item>
    <item>
      <title>rust 安装加速</title>
      <link>http://localhost:1313/posts/2019/20191226/</link>
      <pubDate>Thu, 26 Dec 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2019/20191226/</guid>
      <description>rust 安装一直是一个非常慢的事情，找到了一种加速安装的方法:&#xA;export RUSTUP_DIST_SERVER=&amp;#34;https://mirrors.ustc.edu.cn/rust-static&amp;#34; export RUSTUP_UPDATE_ROOT=&amp;#34;https://mirrors.ustc.edu.cn/rust-static/rustup&amp;#34; curl https://sh.rustup.rs -sSf | sh 2022年 01月 11日 星期二 10:48:47 CST&#xA;https://rsproxy.cn/</description>
    </item>
    <item>
      <title>github clone 加速</title>
      <link>http://localhost:1313/posts/2019/20191217-1/</link>
      <pubDate>Tue, 17 Dec 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2019/20191217-1/</guid>
      <description>http proxy&#xA;git config --global http.https://github.com.proxy http://your.proxy.org socks 代理&#xA;git config --global http.https://github.com.proxy socks5://127.0.0.1:1080 从上面的设置来看，给其他的 git 仓库设置代理也是同样的道理。</description>
    </item>
    <item>
      <title>shell 使用同一个 ssh-agent</title>
      <link>http://localhost:1313/posts/2019/20191217/</link>
      <pubDate>Tue, 17 Dec 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2019/20191217/</guid>
      <description>将下列代码加入到 .bashrc&#xA;SSH_ENV=$HOME/.ssh/environment function start_agent { echo &amp;#34;Initialising new SSH agent...&amp;#34; /usr/bin/ssh-agent | sed &amp;#39;s/^echo/#echo/&amp;#39; &amp;gt; ${SSH_ENV} echo succeeded chmod 600 ${SSH_ENV} . ${SSH_ENV} &amp;gt; /dev/null /usr/bin/ssh-add; } # Source SSH settings, if applicable if [ -f &amp;#34;${SSH_ENV}&amp;#34; ]; then . ${SSH_ENV} &amp;gt; /dev/null #ps ${SSH_AGENT_PID} doesn&amp;#39;t work under cywgin ps -efp ${SSH_AGENT_PID} | grep ssh-agent$ &amp;gt; /dev/null || { start_agent; } else start_agent; fi 然后&#xA;source .bashrc </description>
    </item>
    <item>
      <title>postman 使用技巧</title>
      <link>http://localhost:1313/posts/2019/20191204/</link>
      <pubDate>Wed, 04 Dec 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2019/20191204/</guid>
      <description>介绍如下使用技巧：&#xA;复制浏览器请求到 postman postman 请求生成代码 第一步：复制浏览器请求为文本 第二步：在 postman 导入请求 粘贴请求文本到输入框，可以看到请求参数和请求到被导入成功了 第三步： 导出代码 选择编程语言类型，导出 golang 代码如下：&#xA;package main import ( &amp;#34;fmt&amp;#34; &amp;#34;net/http&amp;#34; &amp;#34;io/ioutil&amp;#34; ) func main() { url := &amp;#34;https://devurls.com/&amp;#34; req, _ := http.NewRequest(&amp;#34;GET&amp;#34;, url, nil) req.Header.Add(&amp;#34;Connection&amp;#34;, &amp;#34;keep-alive&amp;#34;) req.Header.Add(&amp;#34;Pragma&amp;#34;, &amp;#34;no-cache&amp;#34;) req.Header.Add(&amp;#34;Cache-Control&amp;#34;, &amp;#34;no-cache&amp;#34;) req.Header.Add(&amp;#34;Upgrade-Insecure-Requests&amp;#34;, &amp;#34;1&amp;#34;) req.Header.Add(&amp;#34;User-Agent&amp;#34;, &amp;#34;Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.108 Safari/537.36&amp;#34;) req.Header.Add(&amp;#34;Sec-Fetch-User&amp;#34;, &amp;#34;?1&amp;#34;) req.Header.Add(&amp;#34;Accept&amp;#34;, &amp;#34;text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3&amp;#34;) req.Header.Add(&amp;#34;Sec-Fetch-Site&amp;#34;, &amp;#34;none&amp;#34;) req.Header.Add(&amp;#34;Sec-Fetch-Mode&amp;#34;, &amp;#34;navigate&amp;#34;) req.Header.Add(&amp;#34;Accept-Encoding&amp;#34;, &amp;#34;gzip, deflate, br&amp;#34;) req.Header.Add(&amp;#34;Accept-Language&amp;#34;, &amp;#34;zh-CN,zh;q=0.9&amp;#34;) req.Header.Add(&amp;#34;Cookie&amp;#34;, &amp;#34;show=medium%2Clobsters%2Chackernoon%2Cjuliaevans%2Cjohndcook%2Celibendersky%2Ccloudflare%2Cbackblaze%2Cnetflix%2Ccatonmat%2Cjoelonsoftware%2Ccodinghorror%2Calistapart%2Ccsstricks%2Csmashingmagazine%2Clambdatheultimate%2Cstackoverflow%2Cgithub%2Cgitconnected%2Cplanetmysql%2Clwn%2Chackernews%2Creddit%2Cslashdot%2Canandtech%2Cphoronix%2Cgoogledevsblog%2Cfbcode%2Crecode%2Cdzone; hide=none; _ga=GA1.</description>
    </item>
    <item>
      <title>解决内网机器网上问题的通用方案</title>
      <link>http://localhost:1313/posts/2019/20191127/</link>
      <pubDate>Wed, 27 Nov 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2019/20191127/</guid>
      <description>问题：&#xA;服务器或者其他机器被 OPS 限制了访问公网的能力。PS: 网络安全部和 OPS 做法是对的。 使用公司的翻墙代理网络会走到国外，访问国内网站反而更加慢 代理以后不设置 no_proxy 无法访问内网。 解决方案： 如果团队拥有能网上的服务器A，和无法上网的服务器B,并且服务器B能够访问服务器A, 这个时候服务器B可以通过代理到服务器A的方式访问网络。&#xA;在 A 机器上&#xA;yum install squid -y squid 在 B 机器上&#xA;# 只作演示，勿设置全局 # xxxx 位服务器 A 的主机名或 IP 或者 域名 export https_proxy=http://xxxx:3128 export http_proxy=http://xxxx:3128 </description>
    </item>
    <item>
      <title>记一次解决 maven 安装慢的问题</title>
      <link>http://localhost:1313/posts/2019/20191127-1/</link>
      <pubDate>Wed, 27 Nov 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2019/20191127-1/</guid>
      <description>有个团队遇到了 maven 编译非常慢的问题，一个 maven 项目编译需要 20 多分钟。我看了一下编译过程，大部分的时间都在下载依赖，其中会向 repo.spring.org 发起访问，但是这台机器的外网十分不稳定，导致每次请求都会超时，然后等待一些时间，再次发起请求，这就导致编译时间非常慢了。解决这个问题的方法是给 maven 配置网络代理，让他走代理网络访问 repo.spring.org .配置如下：&#xA;&amp;lt;proxies&amp;gt; &amp;lt;proxy&amp;gt; &amp;lt;id&amp;gt;example-proxy&amp;lt;/id&amp;gt; &amp;lt;active&amp;gt;true&amp;lt;/active&amp;gt; &amp;lt;protocol&amp;gt;http&amp;lt;/protocol&amp;gt; &amp;lt;host&amp;gt;proxy.example.com&amp;lt;/host&amp;gt; &amp;lt;port&amp;gt;8080&amp;lt;/port&amp;gt; &amp;lt;username&amp;gt;proxyuser&amp;lt;/username&amp;gt; &amp;lt;password&amp;gt;somepassword&amp;lt;/password&amp;gt; &amp;lt;nonProxyHosts&amp;gt;www.google.com|*.example.com&amp;lt;/nonProxyHosts&amp;gt; &amp;lt;/proxy&amp;gt; &amp;lt;/proxies&amp;gt; 注意，如果代理网络在公网，而私有 maven 服务器在内网，一定记得配置 nonPoroxyHosts.</description>
    </item>
    <item>
      <title>重装 opam</title>
      <link>http://localhost:1313/posts/2019/20191118/</link>
      <pubDate>Mon, 18 Nov 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2019/20191118/</guid>
      <description>卸载 opam&#xA;sudo pacman -R opam 删除缓存数据&#xA;rm -rf ~/.opam 清理 pacman 缓存&#xA;sudo pacman -Scc 安装 opam&#xA;sudo pacman -S opam 初始化 opam&#xA;opam init </description>
    </item>
    <item>
      <title>jenkins 在 k8s 中构建的几种写法</title>
      <link>http://localhost:1313/posts/2019/20191113-1/</link>
      <pubDate>Wed, 13 Nov 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2019/20191113-1/</guid>
      <description>jenkins 结合 k8s 插件能够在 k8s 集群中构建代码，这个非常方便。这里总结一下集中结合 k8s 的用法。&#xA;界面配置 template 在 jenkins 设置界面配置好 template 设置好标签以后，就能在 jenkinsfile 中使用这个节点了。如下：&#xA;pipeline { agent { label &amp;#34;k8s&amp;#34; } stages { stage(&amp;#34;test&amp;#34;){ steps { container(&amp;#34;node&amp;#34;){ echo &amp;#34;Hello World&amp;#34; } } } } } 这里使用 k8s 这个 template 来启动构建环境，并且使用容器名字为 node 的容器。&#xA;jenkinsfile 引入template 文件 在项目的其他文件中定义好 k8s 的 pod 文件，然后在 agent 中通过 yamlFile 指令导入进来&#xA;agent { kubernetes { yamlFile &amp;#34;k8s_pod.yml&amp;#34; } } jenkinsfile 直接定义 template podTemplate(containers: [ containerTemplate(name: &amp;#39;maven&amp;#39;, image: &amp;#39;maven:3.</description>
    </item>
    <item>
      <title>jenkins 在不同的 stage 之间共享文件</title>
      <link>http://localhost:1313/posts/2019/20191113/</link>
      <pubDate>Wed, 13 Nov 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2019/20191113/</guid>
      <description>在使用 k8s 或者 docker 作为 jenkins 的 slave 的时候，会出现一个问题：两个 stage 可能不再同一个机器，或者不再同一个目录上，stage A 中编译的 dist 文件， stage B 中部署需要用到的时候当前目录无法找到 dist 文件。解决方式是使用 stash 和 unstash&#xA;stage(&amp;#34;npm build&amp;#34;) { when { branch &amp;#34;dev&amp;#34; } steps { sh &amp;#34;&amp;#34;&amp;#34; npm run deploy &amp;#34;&amp;#34;&amp;#34; stash includes: &amp;#39;dist/**/*&amp;#39;, name:&amp;#39;npm_dist&amp;#39; } } stage(&amp;#34;ansible deploy&amp;#34;) { when { branch &amp;#34;dev&amp;#34; } agent { docker { image &amp;#34;ansible:1.2.11&amp;#34; } } steps { unstash &amp;#39;npm_dist&amp;#39; script { if (fileExists(&amp;#39;dist.zip&amp;#39;)) { sh(&amp;#39;rm -f dist.</description>
    </item>
    <item>
      <title>从交付角度审视 jenkins</title>
      <link>http://localhost:1313/posts/2019/20191105/</link>
      <pubDate>Tue, 05 Nov 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2019/20191105/</guid>
      <description>之前做过一段时间的2B产品的交付，感觉并没有像2C产品交付那样容易。同时最近使用 jenkins 比较多，发现 jenkins 在软件部署，升级上都比较方便，有一些值得学习的地方。&#xA;支持系统 因为是使用 java + groovy 开发，所以 jenkins 支持所有能够运行 JVM 虚拟机的系统，包括 windows 和 unix like.&#xA;安装方式 使用包管理用具安装&#xA;yum apt pacman 用户自定义 jar , war 运行 升级方式 和安装方式一样，升级也使用包管理工具进行升级，版本之间的差异使用升级脚本解决,可以参考 deb,或者 rpm 包的制作方式.插件之间如果存在版本兼容问题，jenkins 会在插件管理界面提示出来。&#xA;进程管理 使用系统自带的进程管理工具&#xA;service systemd 这样做的好处避免了手动执行 java 命令启动进程，或者 kill 关闭进程，与操作系统上其他系统保持一致的运行规则，也支持开机自动启动。&#xA;系统依赖 jenkins 的安装包内置 java 虚拟机，所以基本只要下载了 deb 以后就能安装,安装非常简单。运行期间，配置信息使用 xml 格式保存在本地磁盘，所以不需要安装数据库。jenkins 的配置都保存在 JENKINS_HOME 中，所以对于运维来说，备份文件非常简单。&#xA;扩展方式 jenkins 使用插件的方式来扩展本身的功能, 提供开放 api , 用户可以开发自定义插件.插件安装可以从网络安装(可指定网站源), 也可以手动上传插件包。&#xA;服务扩容 jenkins 使用 master + slave 的架构，master 管理配置，调度任务， slave 负责执行任务。</description>
    </item>
    <item>
      <title>命令行参数与配置文件优缺点</title>
      <link>http://localhost:1313/posts/2019/20191030/</link>
      <pubDate>Wed, 30 Oct 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2019/20191030/</guid>
      <description>在 Linux 上很多的程序都支持设置命令行启动参数的方式来控制程序的行为，必须使用 -x 输出 debug 的日志信息，使用 -p 来配置端口，也有一些程序支持使用配置文件来控制程序的行为，比如 mysql 使用一个 ini 格式的文件来配置 mysql 的信息。使用命令行和使用配置文件都有那些有点和缺点呢？&#xA;使用配置文件 使用配置文件的好处是，即使程序配置很复杂 ，在配置文件配置好了以后，每次启动都很简单，配置能够被之久话保存下来。·配置文件能够被备份，复制，版本控制。&#xA;使用启动参数 命令行参数具有很好的灵活性，方便自动化脚本来控制程序,但是如果启动命令行很长，很复杂的情况下，每次启动程序都需要输入或者复制很长的启动参数，容易出错，也比较麻烦，甚至有可能忘记上次是怎么设置的启动惨。&#xA;总结 综合上述，全部使用启动参数或者全部使用配置文件，都是不合适的。我认为比较和的方式同时支持配置文件和启动参数，能够写在配置文件里面的配置，也应该能通过命令行参数设置，反过来也是。这一点，prometheus 做的非常好，值得借鉴。这里写了一个例子来说明 golang 在同时支持配置文件和启动方式的处理方式，见代码</description>
    </item>
    <item>
      <title>golang  TestMain 方法</title>
      <link>http://localhost:1313/posts/2019/20191028/</link>
      <pubDate>Mon, 28 Oct 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2019/20191028/</guid>
      <description>今天在执行 golang 的时候报了一个错误&#xA;flag provided but not defined: -test.testlogfile Usage of /var/folders/lb/j0gz8jln36z4frqkrzmkdb0c0000gp/T/go-build200454244/b001/cc.test: FAIL&#x9;github.com/bla/cc&#x9;0.007s 这个的意思是，我没有定义 -test.testlogfile 但是参数解析参数的时候确有这个参数。这里报这个错的原因是测试代码写在main 包中，而 main 包中有一个 init 函数调用了 flag.Parse() 方法&#xA;flag.Parse() 在 testing 框架中也定义了 flag.StringXxxx 等方法，所以也会调用 flag.Prase() 来解析参数&#xA;if !flag.Prase() { flag.Parse() } 这样就导致 testing 框架定义的 flag.StringXxxx 没有被解析。这个这个问题的方式，是在 go test 的用例执行之前，flag.StringXxxx 定义之后调用 flag.Parse() , 这需要用到 TestMain 机制，当一个 golang test file 中包含有&#xA;func TestMain(t *testing.M){ } 函数时，其他的测试用例不会自动执行，而会触发执行 TestMain 参数， 所以我们可以编写 TestMain 参数如下:&#xA;func TestMain(m *testing.M) { flag.</description>
    </item>
    <item>
      <title>几种替代 grep  的文本搜索工具</title>
      <link>http://localhost:1313/posts/2019/20191024/</link>
      <pubDate>Thu, 24 Oct 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2019/20191024/</guid>
      <description>gun grep 是大部分机器上都安装了的程序，最近也发现了一些比运行速度更快的文本搜索工具。&#xA;git grep : git 自带 rg : ripgrep rust 实现的 grep https://github.com/BurntSushi/ripgrep ag : https://github.com/ggreer/the_silver_searcher ack : https://github.com/beyondgrep/ack2 </description>
    </item>
    <item>
      <title>github 表情集合</title>
      <link>http://localhost:1313/posts/2019/20190924/</link>
      <pubDate>Tue, 24 Sep 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2019/20190924/</guid>
      <description>People&#xA;| :bowtie: `:bowtie:` | :smile: `:smile:` | :laughing: `:laughing:` | | --- | --- | --- | | :blush: `:blush:` | :smiley: `:smiley:` | :relaxed: `:relaxed:` | | :smirk: `:smirk:` | :heart_eyes: `:heart_eyes:` | :kissing_heart: `:kissing_heart:` | | :kissing_closed_eyes: `:kissing_closed_eyes:` | :flushed: `:flushed:` | :relieved: `:relieved:` | | :satisfied: `:satisfied:` | :grin: `:grin:` | :wink: `:wink:` | | :stuck_out_tongue_winking_eye: `:stuck_out_tongue_winking_eye:` | :stuck_out_tongue_closed_eyes: `:stuck_out_tongue_closed_eyes:` | :grinning: `:grinning:` | | :kissing: `:kissing:` | :kissing_smiling_eyes: `:kissing_smiling_eyes:` | :stuck_out_tongue: `:stuck_out_tongue:` | | :sleeping: `:sleeping:` | :worried: `:worried:` | :frowning: `:frowning:` | | :anguished: `:anguished:` | :open_mouth: `:open_mouth:` | :grimacing: `:grimacing:` | | :confused: `:confused:` | :hushed: `:hushed:` | :expressionless: `:expressionless:` | | :unamused: `:unamused:` | :sweat_smile: `:sweat_smile:` | :sweat: `:sweat:` | | :disappointed_relieved: `:disappointed_relieved:` | :weary: `:weary:` | :pensive: `:pensive:` | | :disappointed: `:disappointed:` | :confounded: `:confounded:` | :fearful: `:fearful:` | | :cold_sweat: `:cold_sweat:` | :persevere: `:persevere:` | :cry: `:cry:` | | :sob: `:sob:` | :joy: `:joy:` | :astonished: `:astonished:` | | :scream: `:scream:` | :neckbeard: `:neckbeard:` | :tired_face: `:tired_face:` | | :angry: `:angry:` | :rage: `:rage:` | :triumph: `:triumph:` | | :sleepy: `:sleepy:` | :yum: `:yum:` | :mask: `:mask:` | | :sunglasses: `:sunglasses:` | :dizzy_face: `:dizzy_face:` | :imp: `:imp:` | | :smiling_imp: `:smiling_imp:` | :neutral_face: `:neutral_face:` | :no_mouth: `:no_mouth:` | | :innocent: `:innocent:` | :alien: `:alien:` | :yellow_heart: `:yellow_heart:` | | :blue_heart: `:blue_heart:` | :purple_heart: `:purple_heart:` | :heart: `:heart:` | | :green_heart: `:green_heart:` | :broken_heart: `:broken_heart:` | :heartbeat: `:heartbeat:` | | :heartpulse: `:heartpulse:` | :two_hearts: `:two_hearts:` | :revolving_hearts: `:revolving_hearts:` | | :cupid: `:cupid:` | :sparkling_heart: `:sparkling_heart:` | :sparkles: `:sparkles:` | | :star: `:star:` | :star2: `:star2:` | :dizzy: `:dizzy:` | | :boom: `:boom:` | :collision: `:collision:` | :anger: `:anger:` | | :exclamation: `:exclamation:` | :question: `:question:` | :grey_exclamation: `:grey_exclamation:` | | :grey_question: `:grey_question:` | :zzz: `:zzz:` | :dash: `:dash:` | | :sweat_drops: `:sweat_drops:` | :notes: `:notes:` | :musical_note: `:musical_note:` | | :fire: `:fire:` | :hankey: `:hankey:` | :poop: `:poop:` | | :shit: `:shit:` | :+1: `:+1:` | :thumbsup: `:thumbsup:` | | :-1: `:-1:` | :thumbsdown: `:thumbsdown:` | :ok_hand: `:ok_hand:` | | :punch: `:punch:` | :facepunch: `:facepunch:` | :fist: `:fist:` | | :v: `:v:` | :wave: `:wave:` | :hand: `:hand:` | | :raised_hand: `:raised_hand:` | :open_hands: `:open_hands:` | :point_up: `:point_up:` | | :point_down: `:point_down:` | :point_left: `:point_left:` | :point_right: `:point_right:` | | :raised_hands: `:raised_hands:` | :pray: `:pray:` | :point_up_2: `:point_up_2:` | | :clap: `:clap:` | :muscle: `:muscle:` | :metal: `:metal:` | | :fu: `:fu:` | :walking: `:walking:` | :runner: `:runner:` | | :running: `:running:` | :couple: `:couple:` | :family: `:family:` | | :two_men_holding_hands: `:two_men_holding_hands:` | :two_women_holding_hands: `:two_women_holding_hands:` | :dancer: `:dancer:` | | :dancers: `:dancers:` | :ok_woman: `:ok_woman:` | :no_good: `:no_good:` | | :information_desk_person: `:information_desk_person:` | :raising_hand: `:raising_hand:` | :bride_with_veil: `:bride_with_veil:` | | :person_with_pouting_face: `:person_with_pouting_face:` | :person_frowning: `:person_frowning:` | :bow: `:bow:` | | :couplekiss: `:couplekiss:` | :couple_with_heart: `:couple_with_heart:` | :massage: `:massage:` | | :haircut: `:haircut:` | :nail_care: `:nail_care:` | :boy: `:boy:` | | :girl: `:girl:` | :woman: `:woman:` | :man: `:man:` | | :baby: `:baby:` | :older_woman: `:older_woman:` | :older_man: `:older_man:` | | :person_with_blond_hair: `:person_with_blond_hair:` | :man_with_gua_pi_mao: `:man_with_gua_pi_mao:` | :man_with_turban: `:man_with_turban:` | | :construction_worker: `:construction_worker:` | :cop: `:cop:` | :angel: `:angel:` | | :princess: `:princess:` | :smiley_cat: `:smiley_cat:` | :smile_cat: `:smile_cat:` | | :heart_eyes_cat: `:heart_eyes_cat:` | :kissing_cat: `:kissing_cat:` | :smirk_cat: `:smirk_cat:` | | :scream_cat: `:scream_cat:` | :crying_cat_face: `:crying_cat_face:` | :joy_cat: `:joy_cat:` | | :pouting_cat: `:pouting_cat:` | :japanese_ogre: `:japanese_ogre:` | :japanese_goblin: `:japanese_goblin:` | | :see_no_evil: `:see_no_evil:` | :hear_no_evil: `:hear_no_evil:` | :speak_no_evil: `:speak_no_evil:` | | :guardsman: `:guardsman:` | :skull: `:skull:` | :feet: `:feet:` | | :lips: `:lips:` | :kiss: `:kiss:` | :droplet: `:droplet:` | | :ear: `:ear:` | :eyes: `:eyes:` | :nose: `:nose:` | | :tongue: `:tongue:` | :love_letter: `:love_letter:` | :bust_in_silhouette: `:bust_in_silhouette:` | | :busts_in_silhouette: `:busts_in_silhouette:` | :speech_balloon: `:speech_balloon:` | :thought_balloon: `:thought_balloon:` | | :feelsgood: `:feelsgood:` | :finnadie: `:finnadie:` | :goberserk: `:goberserk:` | | :godmode: `:godmode:` | :hurtrealbad: `:hurtrealbad:` | :rage1: `:rage1:` | | :rage2: `:rage2:` | :rage3: `:rage3:` | :rage4: `:rage4:` | | :suspect: `:suspect:` | :trollface: `:trollface:` | Nature | :sunny: `:sunny:` | :umbrella: `:umbrella:` | :cloud: `:cloud:` | | --- | --- | --- | | :snowflake: `:snowflake:` | :snowman: `:snowman:` | :zap: `:zap:` | | :cyclone: `:cyclone:` | :foggy: `:foggy:` | :ocean: `:ocean:` | | :cat: `:cat:` | :dog: `:dog:` | :mouse: `:mouse:` | | :hamster: `:hamster:` | :rabbit: `:rabbit:` | :wolf: `:wolf:` | | :frog: `:frog:` | :tiger: `:tiger:` | :koala: `:koala:` | | :bear: `:bear:` | :pig: `:pig:` | :pig_nose: `:pig_nose:` | | :cow: `:cow:` | :boar: `:boar:` | :monkey_face: `:monkey_face:` | | :monkey: `:monkey:` | :horse: `:horse:` | :racehorse: `:racehorse:` | | :camel: `:camel:` | :sheep: `:sheep:` | :elephant: `:elephant:` | | :panda_face: `:panda_face:` | :snake: `:snake:` | :bird: `:bird:` | | :baby_chick: `:baby_chick:` | :hatched_chick: `:hatched_chick:` | :hatching_chick: `:hatching_chick:` | | :chicken: `:chicken:` | :penguin: `:penguin:` | :turtle: `:turtle:` | | :bug: `:bug:` | :honeybee: `:honeybee:` | :ant: `:ant:` | | :beetle: `:beetle:` | :snail: `:snail:` | :octopus: `:octopus:` | | :tropical_fish: `:tropical_fish:` | :fish: `:fish:` | :whale: `:whale:` | | :whale2: `:whale2:` | :dolphin: `:dolphin:` | :cow2: `:cow2:` | | :ram: `:ram:` | :rat: `:rat:` | :water_buffalo: `:water_buffalo:` | | :tiger2: `:tiger2:` | :rabbit2: `:rabbit2:` | :dragon: `:dragon:` | | :goat: `:goat:` | :rooster: `:rooster:` | :dog2: `:dog2:` | | :pig2: `:pig2:` | :mouse2: `:mouse2:` | :ox: `:ox:` | | :dragon_face: `:dragon_face:` | :blowfish: `:blowfish:` | :crocodile: `:crocodile:` | | :dromedary_camel: `:dromedary_camel:` | :leopard: `:leopard:` | :cat2: `:cat2:` | | :poodle: `:poodle:` | :paw_prints: `:paw_prints:` | :bouquet: `:bouquet:` | | :cherry_blossom: `:cherry_blossom:` | :tulip: `:tulip:` | :four_leaf_clover: `:four_leaf_clover:` | | :rose: `:rose:` | :sunflower: `:sunflower:` | :hibiscus: `:hibiscus:` | | :maple_leaf: `:maple_leaf:` | :leaves: `:leaves:` | :fallen_leaf: `:fallen_leaf:` | | :herb: `:herb:` | :mushroom: `:mushroom:` | :cactus: `:cactus:` | | :palm_tree: `:palm_tree:` | :evergreen_tree: `:evergreen_tree:` | :deciduous_tree: `:deciduous_tree:` | | :chestnut: `:chestnut:` | :seedling: `:seedling:` | :blossom: `:blossom:` | | :ear_of_rice: `:ear_of_rice:` | :shell: `:shell:` | :globe_with_meridians: `:globe_with_meridians:` | | :sun_with_face: `:sun_with_face:` | :full_moon_with_face: `:full_moon_with_face:` | :new_moon_with_face: `:new_moon_with_face:` | | :new_moon: `:new_moon:` | :waxing_crescent_moon: `:waxing_crescent_moon:` | :first_quarter_moon: `:first_quarter_moon:` | | :waxing_gibbous_moon: `:waxing_gibbous_moon:` | :full_moon: `:full_moon:` | :waning_gibbous_moon: `:waning_gibbous_moon:` | | :last_quarter_moon: `:last_quarter_moon:` | :waning_crescent_moon: `:waning_crescent_moon:` | :last_quarter_moon_with_face: `:last_quarter_moon_with_face:` | | :first_quarter_moon_with_face: `:first_quarter_moon_with_face:` | :moon: `:moon:` | :earth_africa: `:earth_africa:` | | :earth_americas: `:earth_americas:` | :earth_asia: `:earth_asia:` | :volcano: `:volcano:` | | :milky_way: `:milky_way:` | :partly_sunny: `:partly_sunny:` | :octocat: `:octocat:` | | :squirrel: `:squirrel:` | Objects | :bamboo: `:bamboo:` | :gift_heart: `:gift_heart:` | :dolls: `:dolls:` | | --- | --- | --- | | :school_satchel: `:school_satchel:` | :mortar_board: `:mortar_board:` | :flags: `:flags:` | | :fireworks: `:fireworks:` | :sparkler: `:sparkler:` | :wind_chime: `:wind_chime:` | | :rice_scene: `:rice_scene:` | :jack_o_lantern: `:jack_o_lantern:` | :ghost: `:ghost:` | | :santa: `:santa:` | :christmas_tree: `:christmas_tree:` | :gift: `:gift:` | | :bell: `:bell:` | :no_bell: `:no_bell:` | :tanabata_tree: `:tanabata_tree:` | | :tada: `:tada:` | :confetti_ball: `:confetti_ball:` | :balloon: `:balloon:` | | :crystal_ball: `:crystal_ball:` | :cd: `:cd:` | :dvd: `:dvd:` | | :floppy_disk: `:floppy_disk:` | :camera: `:camera:` | :video_camera: `:video_camera:` | | :movie_camera: `:movie_camera:` | :computer: `:computer:` | :tv: `:tv:` | | :iphone: `:iphone:` | :phone: `:phone:` | :telephone: `:telephone:` | | :telephone_receiver: `:telephone_receiver:` | :pager: `:pager:` | :fax: `:fax:` | | :minidisc: `:minidisc:` | :vhs: `:vhs:` | :sound: `:sound:` | | :speaker: `:speaker:` | :mute: `:mute:` | :loudspeaker: `:loudspeaker:` | | :mega: `:mega:` | :hourglass: `:hourglass:` | :hourglass_flowing_sand: `:hourglass_flowing_sand:` | | :alarm_clock: `:alarm_clock:` | :watch: `:watch:` | :radio: `:radio:` | | :satellite: `:satellite:` | :loop: `:loop:` | :mag: `:mag:` | | :mag_right: `:mag_right:` | :unlock: `:unlock:` | :lock: `:lock:` | | :lock_with_ink_pen: `:lock_with_ink_pen:` | :closed_lock_with_key: `:closed_lock_with_key:` | :key: `:key:` | | :bulb: `:bulb:` | :flashlight: `:flashlight:` | :high_brightness: `:high_brightness:` | | :low_brightness: `:low_brightness:` | :electric_plug: `:electric_plug:` | :battery: `:battery:` | | :calling: `:calling:` | :email: `:email:` | :mailbox: `:mailbox:` | | :postbox: `:postbox:` | :bath: `:bath:` | :bathtub: `:bathtub:` | | :shower: `:shower:` | :toilet: `:toilet:` | :wrench: `:wrench:` | | :nut_and_bolt: `:nut_and_bolt:` | :hammer: `:hammer:` | :seat: `:seat:` | | :moneybag: `:moneybag:` | :yen: `:yen:` | :dollar: `:dollar:` | | :pound: `:pound:` | :euro: `:euro:` | :credit_card: `:credit_card:` | | :money_with_wings: `:money_with_wings:` | :e-mail: `:e-mail:` | :inbox_tray: `:inbox_tray:` | | :outbox_tray: `:outbox_tray:` | :envelope: `:envelope:` | :incoming_envelope: `:incoming_envelope:` | | :postal_horn: `:postal_horn:` | :mailbox_closed: `:mailbox_closed:` | :mailbox_with_mail: `:mailbox_with_mail:` | | :mailbox_with_no_mail: `:mailbox_with_no_mail:` | :door: `:door:` | :smoking: `:smoking:` | | :bomb: `:bomb:` | :gun: `:gun:` | :hocho: `:hocho:` | | :pill: `:pill:` | :syringe: `:syringe:` | :page_facing_up: `:page_facing_up:` | | :page_with_curl: `:page_with_curl:` | :bookmark_tabs: `:bookmark_tabs:` | :bar_chart: `:bar_chart:` | | :chart_with_upwards_trend: `:chart_with_upwards_trend:` | :chart_with_downwards_trend: `:chart_with_downwards_trend:` | :scroll: `:scroll:` | | :clipboard: `:clipboard:` | :calendar: `:calendar:` | :date: `:date:` | | :card_index: `:card_index:` | :file_folder: `:file_folder:` | :open_file_folder: `:open_file_folder:` | | :scissors: `:scissors:` | :pushpin: `:pushpin:` | :paperclip: `:paperclip:` | | :black_nib: `:black_nib:` | :pencil2: `:pencil2:` | :straight_ruler: `:straight_ruler:` | | :triangular_ruler: `:triangular_ruler:` | :closed_book: `:closed_book:` | :green_book: `:green_book:` | | :blue_book: `:blue_book:` | :orange_book: `:orange_book:` | :notebook: `:notebook:` | | :notebook_with_decorative_cover: `:notebook_with_decorative_cover:` | :ledger: `:ledger:` | :books: `:books:` | | :bookmark: `:bookmark:` | :name_badge: `:name_badge:` | :microscope: `:microscope:` | | :telescope: `:telescope:` | :newspaper: `:newspaper:` | :football: `:football:` | | :basketball: `:basketball:` | :soccer: `:soccer:` | :baseball: `:baseball:` | | :tennis: `:tennis:` | :8ball: `:8ball:` | :rugby_football: `:rugby_football:` | | :bowling: `:bowling:` | :golf: `:golf:` | :mountain_bicyclist: `:mountain_bicyclist:` | | :bicyclist: `:bicyclist:` | :horse_racing: `:horse_racing:` | :snowboarder: `:snowboarder:` | | :swimmer: `:swimmer:` | :surfer: `:surfer:` | :ski: `:ski:` | | :spades: `:spades:` | :hearts: `:hearts:` | :clubs: `:clubs:` | | :diamonds: `:diamonds:` | :gem: `:gem:` | :ring: `:ring:` | | :trophy: `:trophy:` | :musical_score: `:musical_score:` | :musical_keyboard: `:musical_keyboard:` | | :violin: `:violin:` | :space_invader: `:space_invader:` | :video_game: `:video_game:` | | :black_joker: `:black_joker:` | :flower_playing_cards: `:flower_playing_cards:` | :game_die: `:game_die:` | | :dart: `:dart:` | :mahjong: `:mahjong:` | :clapper: `:clapper:` | | :memo: `:memo:` | :pencil: `:pencil:` | :book: `:book:` | | :art: `:art:` | :microphone: `:microphone:` | :headphones: `:headphones:` | | :trumpet: `:trumpet:` | :saxophone: `:saxophone:` | :guitar: `:guitar:` | | :shoe: `:shoe:` | :sandal: `:sandal:` | :high_heel: `:high_heel:` | | :lipstick: `:lipstick:` | :boot: `:boot:` | :shirt: `:shirt:` | | :tshirt: `:tshirt:` | :necktie: `:necktie:` | :womans_clothes: `:womans_clothes:` | | :dress: `:dress:` | :running_shirt_with_sash: `:running_shirt_with_sash:` | :jeans: `:jeans:` | | :kimono: `:kimono:` | :bikini: `:bikini:` | :ribbon: `:ribbon:` | | :tophat: `:tophat:` | :crown: `:crown:` | :womans_hat: `:womans_hat:` | | :mans_shoe: `:mans_shoe:` | :closed_umbrella: `:closed_umbrella:` | :briefcase: `:briefcase:` | | :handbag: `:handbag:` | :pouch: `:pouch:` | :purse: `:purse:` | | :eyeglasses: `:eyeglasses:` | :fishing_pole_and_fish: `:fishing_pole_and_fish:` | :coffee: `:coffee:` | | :tea: `:tea:` | :sake: `:sake:` | :baby_bottle: `:baby_bottle:` | | :beer: `:beer:` | :beers: `:beers:` | :cocktail: `:cocktail:` | | :tropical_drink: `:tropical_drink:` | :wine_glass: `:wine_glass:` | :fork_and_knife: `:fork_and_knife:` | | :pizza: `:pizza:` | :hamburger: `:hamburger:` | :fries: `:fries:` | | :poultry_leg: `:poultry_leg:` | :meat_on_bone: `:meat_on_bone:` | :spaghetti: `:spaghetti:` | | :curry: `:curry:` | :fried_shrimp: `:fried_shrimp:` | :bento: `:bento:` | | :sushi: `:sushi:` | :fish_cake: `:fish_cake:` | :rice_ball: `:rice_ball:` | | :rice_cracker: `:rice_cracker:` | :rice: `:rice:` | :ramen: `:ramen:` | | :stew: `:stew:` | :oden: `:oden:` | :dango: `:dango:` | | :egg: `:egg:` | :bread: `:bread:` | :doughnut: `:doughnut:` | | :custard: `:custard:` | :icecream: `:icecream:` | :ice_cream: `:ice_cream:` | | :shaved_ice: `:shaved_ice:` | :birthday: `:birthday:` | :cake: `:cake:` | | :cookie: `:cookie:` | :chocolate_bar: `:chocolate_bar:` | :candy: `:candy:` | | :lollipop: `:lollipop:` | :honey_pot: `:honey_pot:` | :apple: `:apple:` | | :green_apple: `:green_apple:` | :tangerine: `:tangerine:` | :lemon: `:lemon:` | | :cherries: `:cherries:` | :grapes: `:grapes:` | :watermelon: `:watermelon:` | | :strawberry: `:strawberry:` | :peach: `:peach:` | :melon: `:melon:` | | :banana: `:banana:` | :pear: `:pear:` | :pineapple: `:pineapple:` | | :sweet_potato: `:sweet_potato:` | :eggplant: `:eggplant:` | :tomato: `:tomato:` | | :corn: `:corn:` | Places | :house: `:house:` | :house_with_garden: `:house_with_garden:` | :school: `:school:` | | --- | --- | --- | | :office: `:office:` | :post_office: `:post_office:` | :hospital: `:hospital:` | | :bank: `:bank:` | :convenience_store: `:convenience_store:` | :love_hotel: `:love_hotel:` | | :hotel: `:hotel:` | :wedding: `:wedding:` | :church: `:church:` | | :department_store: `:department_store:` | :european_post_office: `:european_post_office:` | :city_sunrise: `:city_sunrise:` | | :city_sunset: `:city_sunset:` | :japanese_castle: `:japanese_castle:` | :european_castle: `:european_castle:` | | :tent: `:tent:` | :factory: `:factory:` | :tokyo_tower: `:tokyo_tower:` | | :japan: `:japan:` | :mount_fuji: `:mount_fuji:` | :sunrise_over_mountains: `:sunrise_over_mountains:` | | :sunrise: `:sunrise:` | :stars: `:stars:` | :statue_of_liberty: `:statue_of_liberty:` | | :bridge_at_night: `:bridge_at_night:` | :carousel_horse: `:carousel_horse:` | :rainbow: `:rainbow:` | | :ferris_wheel: `:ferris_wheel:` | :fountain: `:fountain:` | :roller_coaster: `:roller_coaster:` | | :ship: `:ship:` | :speedboat: `:speedboat:` | :boat: `:boat:` | | :sailboat: `:sailboat:` | :rowboat: `:rowboat:` | :anchor: `:anchor:` | | :rocket: `:rocket:` | :airplane: `:airplane:` | :helicopter: `:helicopter:` | | :steam_locomotive: `:steam_locomotive:` | :tram: `:tram:` | :mountain_railway: `:mountain_railway:` | | :bike: `:bike:` | :aerial_tramway: `:aerial_tramway:` | :suspension_railway: `:suspension_railway:` | | :mountain_cableway: `:mountain_cableway:` | :tractor: `:tractor:` | :blue_car: `:blue_car:` | | :oncoming_automobile: `:oncoming_automobile:` | :car: `:car:` | :red_car: `:red_car:` | | :taxi: `:taxi:` | :oncoming_taxi: `:oncoming_taxi:` | :articulated_lorry: `:articulated_lorry:` | | :bus: `:bus:` | :oncoming_bus: `:oncoming_bus:` | :rotating_light: `:rotating_light:` | | :police_car: `:police_car:` | :oncoming_police_car: `:oncoming_police_car:` | :fire_engine: `:fire_engine:` | | :ambulance: `:ambulance:` | :minibus: `:minibus:` | :truck: `:truck:` | | :train: `:train:` | :station: `:station:` | :train2: `:train2:` | | :bullettrain_front: `:bullettrain_front:` | :bullettrain_side: `:bullettrain_side:` | :light_rail: `:light_rail:` | | :monorail: `:monorail:` | :railway_car: `:railway_car:` | :trolleybus: `:trolleybus:` | | :ticket: `:ticket:` | :fuelpump: `:fuelpump:` | :vertical_traffic_light: `:vertical_traffic_light:` | | :traffic_light: `:traffic_light:` | :warning: `:warning:` | :construction: `:construction:` | | :beginner: `:beginner:` | :atm: `:atm:` | :slot_machine: `:slot_machine:` | | :busstop: `:busstop:` | :barber: `:barber:` | :hotsprings: `:hotsprings:` | | :checkered_flag: `:checkered_flag:` | :crossed_flags: `:crossed_flags:` | :izakaya_lantern: `:izakaya_lantern:` | | :moyai: `:moyai:` | :circus_tent: `:circus_tent:` | :performing_arts: `:performing_arts:` | | :round_pushpin: `:round_pushpin:` | :triangular_flag_on_post: `:triangular_flag_on_post:` | :jp: `:jp:` | | :kr: `:kr:` | :cn: `:cn:` | :us: `:us:` | | :fr: `:fr:` | :es: `:es:` | :it: `:it:` | | :ru: `:ru:` | :gb: `:gb:` | :uk: `:uk:` | | :de: `:de:` | Symbols | :one: `:one:` | :two: `:two:` | :three: `:three:` | | --- | --- | --- | | :four: `:four:` | :five: `:five:` | :six: `:six:` | | :seven: `:seven:` | :eight: `:eight:` | :nine: `:nine:` | | :keycap_ten: `:keycap_ten:` | :1234: `:1234:` | :zero: `:zero:` | | :hash: `:hash:` | :symbols: `:symbols:` | :arrow_backward: `:arrow_backward:` | | :arrow_down: `:arrow_down:` | :arrow_forward: `:arrow_forward:` | :arrow_left: `:arrow_left:` | | :capital_abcd: `:capital_abcd:` | :abcd: `:abcd:` | :abc: `:abc:` | | :arrow_lower_left: `:arrow_lower_left:` | :arrow_lower_right: `:arrow_lower_right:` | :arrow_right: `:arrow_right:` | | :arrow_up: `:arrow_up:` | :arrow_upper_left: `:arrow_upper_left:` | :arrow_upper_right: `:arrow_upper_right:` | | :arrow_double_down: `:arrow_double_down:` | :arrow_double_up: `:arrow_double_up:` | :arrow_down_small: `:arrow_down_small:` | | :arrow_heading_down: `:arrow_heading_down:` | :arrow_heading_up: `:arrow_heading_up:` | :leftwards_arrow_with_hook: `:leftwards_arrow_with_hook:` | | :arrow_right_hook: `:arrow_right_hook:` | :left_right_arrow: `:left_right_arrow:` | :arrow_up_down: `:arrow_up_down:` | | :arrow_up_small: `:arrow_up_small:` | :arrows_clockwise: `:arrows_clockwise:` | :arrows_counterclockwise: `:arrows_counterclockwise:` | | :rewind: `:rewind:` | :fast_forward: `:fast_forward:` | :information_source: `:information_source:` | | :ok: `:ok:` | :twisted_rightwards_arrows: `:twisted_rightwards_arrows:` | :repeat: `:repeat:` | | :repeat_one: `:repeat_one:` | :new: `:new:` | :top: `:top:` | | :up: `:up:` | :cool: `:cool:` | :free: `:free:` | | :ng: `:ng:` | :cinema: `:cinema:` | :koko: `:koko:` | | :signal_strength: `:signal_strength:` | :u5272: `:u5272:` | :u5408: `:u5408:` | | :u55b6: `:u55b6:` | :u6307: `:u6307:` | :u6708: `:u6708:` | | :u6709: `:u6709:` | :u6e80: `:u6e80:` | :u7121: `:u7121:` | | :u7533: `:u7533:` | :u7a7a: `:u7a7a:` | :u7981: `:u7981:` | | :sa: `:sa:` | :restroom: `:restroom:` | :mens: `:mens:` | | :womens: `:womens:` | :baby_symbol: `:baby_symbol:` | :no_smoking: `:no_smoking:` | | :parking: `:parking:` | :wheelchair: `:wheelchair:` | :metro: `:metro:` | | :baggage_claim: `:baggage_claim:` | :accept: `:accept:` | :wc: `:wc:` | | :potable_water: `:potable_water:` | :put_litter_in_its_place: `:put_litter_in_its_place:` | :secret: `:secret:` | | :congratulations: `:congratulations:` | :m: `:m:` | :passport_control: `:passport_control:` | | :left_luggage: `:left_luggage:` | :customs: `:customs:` | :ideograph_advantage: `:ideograph_advantage:` | | :cl: `:cl:` | :sos: `:sos:` | :id: `:id:` | | :no_entry_sign: `:no_entry_sign:` | :underage: `:underage:` | :no_mobile_phones: `:no_mobile_phones:` | | :do_not_litter: `:do_not_litter:` | :non-potable_water: `:non-potable_water:` | :no_bicycles: `:no_bicycles:` | | :no_pedestrians: `:no_pedestrians:` | :children_crossing: `:children_crossing:` | :no_entry: `:no_entry:` | | :eight_spoked_asterisk: `:eight_spoked_asterisk:` | :eight_pointed_black_star: `:eight_pointed_black_star:` | :heart_decoration: `:heart_decoration:` | | :vs: `:vs:` | :vibration_mode: `:vibration_mode:` | :mobile_phone_off: `:mobile_phone_off:` | | :chart: `:chart:` | :currency_exchange: `:currency_exchange:` | :aries: `:aries:` | | :taurus: `:taurus:` | :gemini: `:gemini:` | :cancer: `:cancer:` | | :leo: `:leo:` | :virgo: `:virgo:` | :libra: `:libra:` | | :scorpius: `:scorpius:` | :sagittarius: `:sagittarius:` | :capricorn: `:capricorn:` | | :aquarius: `:aquarius:` | :pisces: `:pisces:` | :ophiuchus: `:ophiuchus:` | | :six_pointed_star: `:six_pointed_star:` | :negative_squared_cross_mark: `:negative_squared_cross_mark:` | :a: `:a:` | | :b: `:b:` | :ab: `:ab:` | :o2: `:o2:` | | :diamond_shape_with_a_dot_inside: `:diamond_shape_with_a_dot_inside:` | :recycle: `:recycle:` | :end: `:end:` | | :on: `:on:` | :soon: `:soon:` | :clock1: `:clock1:` | | :clock130: `:clock130:` | :clock10: `:clock10:` | :clock1030: `:clock1030:` | | :clock11: `:clock11:` | :clock1130: `:clock1130:` | :clock12: `:clock12:` | | :clock1230: `:clock1230:` | :clock2: `:clock2:` | :clock230: `:clock230:` | | :clock3: `:clock3:` | :clock330: `:clock330:` | :clock4: `:clock4:` | | :clock430: `:clock430:` | :clock5: `:clock5:` | :clock530: `:clock530:` | | :clock6: `:clock6:` | :clock630: `:clock630:` | :clock7: `:clock7:` | | :clock730: `:clock730:` | :clock8: `:clock8:` | :clock830: `:clock830:` | | :clock9: `:clock9:` | :clock930: `:clock930:` | :heavy_dollar_sign: `:heavy_dollar_sign:` | | :copyright: `:copyright:` | :registered: `:registered:` | :tm: `:tm:` | | :x: `:x:` | :heavy_exclamation_mark: `:heavy_exclamation_mark:` | :bangbang: `:bangbang:` | | :interrobang: `:interrobang:` | :o: `:o:` | :heavy_multiplication_x: `:heavy_multiplication_x:` | | :heavy_plus_sign: `:heavy_plus_sign:` | :heavy_minus_sign: `:heavy_minus_sign:` | :heavy_division_sign: `:heavy_division_sign:` | | :white_flower: `:white_flower:` | :100: `:100:` | :heavy_check_mark: `:heavy_check_mark:` | | :ballot_box_with_check: `:ballot_box_with_check:` | :radio_button: `:radio_button:` | :link: `:link:` | | :curly_loop: `:curly_loop:` | :wavy_dash: `:wavy_dash:` | :part_alternation_mark: `:part_alternation_mark:` | | :trident: `:trident:` | :black_square: `:black_square:` | :white_square: `:white_square:` | | :white_check_mark: `:white_check_mark:` | :black_square_button: `:black_square_button:` | :white_square_button: `:white_square_button:` | | :black_circle: `:black_circle:` | :white_circle: `:white_circle:` | :red_circle: `:red_circle:` | | :large_blue_circle: `:large_blue_circle:` | :large_blue_diamond: `:large_blue_diamond:` | :large_orange_diamond: `:large_orange_diamond:` | | :small_blue_diamond: `:small_blue_diamond:` | :small_orange_diamond: `:small_orange_diamond:` | :small_red_triangle: `:small_red_triangle:` | | :small_red_triangle_down: `:small_red_triangle_down:` | :shipit: `:shipit:` | 参考: https://gist.</description>
    </item>
    <item>
      <title>jenkins 最佳实践</title>
      <link>http://localhost:1313/posts/2019/20190918/</link>
      <pubDate>Wed, 18 Sep 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2019/20190918/</guid>
      <description>安全使用 jenkins&#xA;在一个大型组织中，不要使用 master 构建&#xA;日常备份 jenkins 的 home 目录&#xA;限制项目的名字位大小写字母加下划线和数字(复杂的名字导致一些插件无法工作)&#xA;使用文件指纹管理依赖&#xA;最好的构建在清楚构建换粗以后从源代码能重新构建成功&#xA;使用信息追踪信息来管理 jenkins changelog&#xA;使用版本管理工具 git 或者 svn&#xA;java 项目在构建应该生成自动测试的报告&#xA;让 jenkins 运行在较大的磁盘上&#xA;不要直接删除无用的构建，将他们移动到特定目录&#xA;不同的分支处理不同的构建情况&#xA;保证信息安全&#xA;不要在同时开启所有构建&#xA;将构建信息邮件通知给所有团队成员&#xA;尽快的反馈失败信息&#xA;构建之后清理工作空间，避免写满磁盘&#xA;每次构建成功以后应该做个标记</description>
    </item>
    <item>
      <title>net-tools 和 iproute2</title>
      <link>http://localhost:1313/posts/2019/20190912/</link>
      <pubDate>Thu, 12 Sep 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2019/20190912/</guid>
      <description>基础的 linux 发行版中都包含了一些强大的网络相关的命令，这些命令都来自 net-tools 包，在很长一段时间 net-tools 几乎在所有的 linux 发 行版中都很流行。它包含了一下命令:&#xA;ifconfig route nameif iwconfig iptunnel netstat arp 这些命令能让 linux 新手和专家都能得心应手的配置 linux 网络， 但是随着 linux 内核的发展，这套工具的维护成了一个棘手的问题，需要有 新的工具来替代他们。&#xA;iproute2 就是上面所有提到的替代 net-tools 的工具集合，iproute2 和 linux 内核紧密结合。iproute2 包含了一下命令行工具:&#xA;ip ss bridge rtacct rtmon tc ctstat lnstat nstat routeef routel rtstat tpic arpd devlink net-tools 和 iproute2 的替换关系&#xA;| net-tools 工具 | iproute2 工具 | 备注 | | --- | --- | --- | | ifconfig | ip addr , ip link , ip -s | 网络配置 | | route | ip route | 路由表 | | arg | ip neigh | arp 列表 | | iptunnel | ip tunnel | 网络代理 | | nameif | iprename , ip link set name | 重命名网卡 | | ipmaddr | ip maddr | 广播地址 | | netstat | ip -s ss , ip route | 显示网络状态 | 参考链接</description>
    </item>
    <item>
      <title>jenkins pipeline 跳过特殊 commit 的方法</title>
      <link>http://localhost:1313/posts/2019/20190911/</link>
      <pubDate>Wed, 11 Sep 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2019/20190911/</guid>
      <description>有时候一些 git commit 是由机器人提交的，或者类似于 maven release 插件提交的代码，我们不希望他触发 jenkins 构建。&#xA;方法1：使用 expression 判断 commit 信息&#xA;pipeline { agent { label &amp;#34;jks-web&amp;#34; } stages { stage(&amp;#34;git fetch&amp;#34;) { steps { echo &amp;#34;git fetch&amp;#34; } } stage(&amp;#34;build&amp;#34;) { when { expression { !sh(script: &amp;#34;git log -1&amp;#34;,returnStdout: true).contains(&amp;#34;skip&amp;#34;) } } steps { echo &amp;#34;build&amp;#34; } } } } 方法2: 使用 changelog 的正则表达式来配置 commit&#xA;pipeline { agent { label &amp;#34;jks-web&amp;#34; } stages { stage(&amp;#34;git fetch&amp;#34;) { steps { echo &amp;#34;git fetch&amp;#34; } } stage(&amp;#34;build&amp;#34;) { when { not { changelog &amp;#39;.</description>
    </item>
    <item>
      <title>k8s 中挂载 configMap</title>
      <link>http://localhost:1313/posts/2019/20190903/</link>
      <pubDate>Tue, 03 Sep 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2019/20190903/</guid>
      <description>使用命令行从文件创建 configMap, 比如，我们的配置文件名字是 config.yaml , 那么我们可以创建 configMap :&#xA;kubectl create configmap myconfig --from-file=config.yaml 可以在 pod 的 yaml 文件中指定挂载这个文件到某个目录：&#xA;apiVersion: v1 kind: Pod metadata: name: myapp labels: name: myapp spec: containers: - name: myapp image: &amp;lt;image&amp;gt; volumeMounts: - name: config mountPath: /etc/config subPath: config volumes: - name: config configMap: name: myconfig 以上将 config.yaml 文件挂载到了 myapp 容器的 /et/config 文件。</description>
    </item>
    <item>
      <title>jenkins k8s 编译 golang 遇到 vendor 的坑</title>
      <link>http://localhost:1313/posts/2019/20190829/</link>
      <pubDate>Thu, 29 Aug 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2019/20190829/</guid>
      <description>将当前项目 link 到 /go/src/github.com/project,将 vendor 复制到 /go/src/&#xA;stage(&amp;#34;go build&amp;#34;) { steps { container(&amp;#34;golang&amp;#34;) { sh &amp;#34;&amp;#34;&amp;#34; cp vendor/* /go/src/ -rf mkdir -p /go/src/github.com/project ln -s `pwd` /go/sr/github.com/project cd /go/src/github.com/project &amp;amp;&amp;amp; go build &amp;#34;&amp;#34;&amp;#34; } } } 参考链接：&#xA;https://github.com/jenkinsci/kubernetes-plugin </description>
    </item>
    <item>
      <title>读知乎某专栏有感</title>
      <link>http://localhost:1313/posts/2019/20190822/</link>
      <pubDate>Thu, 22 Aug 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2019/20190822/</guid>
      <description>最近在知乎上看某个大牛的程序员的专栏，专栏内容为：介绍提高编程效率的方法。专栏地址是：https://zhuanlan.zhihu.com/c_1116711987706478592 。大部分文章都配上了作者自己录制的视频说明，内容十分精彩。但是，最让内心不能平息的是其中一个讲述 vscode 快捷键的视频。从作者以往的文章来看，作者以前是个 emacs 和 vim 编辑器的使用高手。像 vscode 这样的编辑器，对于一个经验丰富，技术精湛的程序员来说，这些基本的操作自然不在话下。但是，作为在视频中介绍了菜单界面上的每一个快捷键的用法，非常认真。而且，看得出来，每一个快捷键他都有仔细研究使用过。那一刻，我看到了来自优秀的人身上的卑谦，即使是每一个简单的知识，都要亲自实验，绝不异想天开。vscode 是一款出来了好几年的编辑器，在连续追看了专栏一些时间以后，我发现作者以前并没有使用过 vscode , 但是最新的文章中，作者发布了自己编写的 vscode 插件，可以说明，对于 vscode 的功能点和缺点，他都摸透了，开始通过自己编写插件来弥补功能上的不足。作者还说过一些话，在我脑海里面一直浮现：集中力量干大事。这说明优秀的人做事都很专注，不会东边一桹头西边一棒子。那些菜单快捷键说明，一个一个去实验，看似费时间，但是在以后每一次使用都会为自己带来收益，用的越多，节省的时间就越多。我们总是抱怨没有时间去干某件事情，但是也不知道时间都去哪里了。我想，优秀的人他们的时间就是这么节约出来的吧，那些时间他们又可以拿去学习新的知识，或者深度学习，保持良性的循环，牢牢的将时间的主动权握在自己手里。&#xA;总结一下，我在这位作者身上看到的特点:&#xA;学习态度认真，不放过每一个看似简单的问题 专注，即使 vscode 出来很多年了，知道真的需要使用才会话时间去研究 对于要学习的东西都透彻掌握，精益求精 知识非常面广，深 还有一件事情，某一次我刷微薄，看到 vue 作者由雨溪的发了一条微薄，内容是什么我已经不记得了，但是我记得评论中有一句话是这么说的：真的严谨啊，就连发个微薄，英文单词两边都会带上同样的空格。评论说的不错，我翻看了一些其他时间的发的微薄，每一条都很严谨，甚至是标点符号。这些对于细节的严苛，让我不得不服气。昨天在读 vimtour 的翻译时候，我也发现作者在反复切换中英文的情况下，一个标点符号都没有错。&#xA;虽然我没有和这些人交流过，并不了解他们的智商，不了解他们的努力程度。但是，有一个地方我和他们存在巨大的差距：态度。</description>
    </item>
    <item>
      <title>SpaceVim 配置 golang IDE</title>
      <link>http://localhost:1313/posts/2019/20190821/</link>
      <pubDate>Wed, 21 Aug 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2019/20190821/</guid>
      <description> 安装SpaceVim curl -sLf https://spacevim.org/install.sh | bash -s -- -h 配置 golang 模块 go get -u github.com/jstemmer/gotags vim ~/.SpaceVim.d/init.toml [[layers]] 安装 golang 插件 # 这个安装过程可能会遇到 golang/x/tools 的问题 vim :GoInstallBinaries </description>
    </item>
    <item>
      <title>Jenkins 的 ssh agent 插件不支持 OPENSSH 格式密钥</title>
      <link>http://localhost:1313/posts/2019/20190815/</link>
      <pubDate>Thu, 15 Aug 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2019/20190815/</guid>
      <description>错误现象 在使用 jenkins 的 sshagent 插件克隆 git 项目的时候总是报错，错误信息如下：&#xA;[ssh-agent] Looking for ssh-agent implementation&amp;hellip; [ssh-agent] Exec ssh-agent (binary ssh-agent on a remote machine) $ ssh-agent SSH_AUTH_SOCK=/tmp/ssh-Z8Y4g9m9lpwe/agent.22129 SSH_AGENT_PID=22131 Running ssh-add (command line suppressed) ssh_askpass: exec(/home/chengwei01/jenkins_home/workspace/in-fe_lanxin-pm_test_devops-MR4H5L6MQSZH3QCWWF74KA7SSTTG3JCFV4U2YDOLKBT3MDGFXW2Q/lanxin-mis@tmp/askpass_5624886618215863559.sh): No such file or directory 解决过程&#xA;根据 google 搜索得到的信息是: ssh 密钥配置错误。但是重新生成了好多次密钥都不对。我怀疑是不是不支持某种格式的加密方式，于是去看私密钥的格式，反复对比密钥文件发现，私钥头部申明信息不一样。&#xA;有效的私钥&#xA;-----BEGIN RSA PRIVATE KEY----- ............................... -----END RSA PRIVATE KEY----- 无效的私钥&#xA;-----BEGIN OPENSSH PRIVATE KEY----- ......................... -----END OPENSSH PRIVATE KEY----- 开头和结尾的申明不同，也就说明这两种的密钥格式不一样，于是我上网查了一下，看到 http://www.panwenbin.com/ 里面介绍，这其实是密钥的两种不同格式，可以相互转换，我尝试转换了一下当前的私钥(一下私钥为假数据)&#xA;[hellojukay@local ~]$ ssh-keygen -p -m PEM -f test [hellojukay@local ~]$ cat test -----BEGIN RSA PRIVATE KEY----- MIIEpAIBAAKCAQEA4cDRUJjKc2zjw07SgUulKbK966ki/hqL8L2s2PJ6tDjKH8X7 x5UoT3GMu9CQjFIJ+rw34Yk4zwJt192zxCbI7Zlltd9Er8dLiczubkf4wJxjgXYC okhBhhOZ0pNdm43DrpChyk5SogXP61Erjej6qxMyyMQjNcy7xAhC9X7b1yKH+8Hh gajRZUSdf0+3CgBpxZS2CHjBgS3mtLMWoE8tk3uK6S6N/3d2tSzgRTDvWkl0ooKN UeUk7kPyc/UnfUZZVyAotk4TtjSxlKrtvFoflL9WbFl09xH3uAkqolz872RN78XS 6VopBGWL2hNAvnIczFK2F3C/syGQOA91c9VeXwIDAQABAoIBAEopBlncp3z9g2DQ jvRsfihRkHRPDrC81cXS+WoXVdnIYhXH+ysYQ7K9UYcNP77o4GBe3liXtHLEkIL+ UKSaPR1YbAIwAydfZ+Av0w+lUwErHsETnE/lPqkl3T1ArdqA2oyI9K05x4l0MVZT RuSKaXYzi1ZKoGp3BCOktyJgdyWXkykAkVexfyGofCZu+tJoLAvsU8ZLYj7EgIr2 QyEa9r7Pgmixq0HQuYRSGMBxDS5LEDqe/RpnaThM6KNYT9ob+Cj7xMq916QMsGqo GF4raTV5fY3dOzu18Tg91e83ipt4GWvpyUo0O9RE2x8DYDLtAnDQ3AZO0r4QbeYw 3j0HO2ECgYEA/30euI6gf+OyGs8AUFwL/AzP2xjO3HJ+sKoJ8QCfcQVeVE2Fkbj4 Kh7tdOIyJ0xrY+sw3O28rr6H9+5PxK8Zz3jUSG6uuXHBxYzDAoJr6HQhoJduRr0t DRphMWPBXkIpdW9sMO7upGCfF1VTjD7Xyih+2N3FRwcsp8NAuxDeclECgYEA4jR3 BEZLdOpfJ+P2fVC0xWsdfsdsdfertDrghjkStbJd1oPUaWeXB485i2QFK9/e0fKU uLXRo3Vs8LWB9eQplh3XqB/sSE0sRbtkv+eKdTAEtZDekCkdL2ok2aNIZbH3SF8E cZH/23AHk8HyEpNyQgS8M/3QCRCQWMhYGVZCaa8CgYEAv3kp+O8LYk1nQag5eABE CxYfAPjKr3Qvdn85DCGHXNDFLTEcFWYmtoqPM7YCGGmxYiT1bd3ONrgcdrdnmOQR 1+eaUN6CnAChVEh2Lf9Il+HRAeX7g5BrnxJSHQ3B8b5sC9MBpnqq5w5yrK4J+2Vt m9hVmHo8S0sZMHGopYmy7MECgYBIzqY4JAAJg55ZEpC1yRJGLZSEe9fQgTbDlNgi Gq96IA0ADLKDsqnz7u+QpALeGlJ3tOKViUAOoq8L0wAfiu6vuK8/F/dPVjeXwjct ZXM1QN1jK1vXfsQ8DKgLvPiCcwOqsZqWi22UzbxCnLwzqm2uPiPtgBZDtKchTGq+ zPrXVQKBgQCx59ITBMRrAGQTl5Rcb6eM8HLRdIGsi5PM1KqA6Lxoq4bZ6yKSRGKY Z/DIlZ5pLgSxkW8UJ5BO7TUhIMC94v9PgHMTOAdlYzfHwcWPHD625A5c6tfzBt4g OlzxKS+AuvH0szDQ28oprkSEAbWogGcOi1mW9VuOOB4QbwAgMrVtHA== -----END RSA PRIVATE KEY----- 密钥格式修改成功，更新到 jenkins 重试成功,当前 Jenkins 使用的 SSH Agent Plugin 插件版本位 1.</description>
    </item>
    <item>
      <title>Manjaro terminal 快速弹出</title>
      <link>http://localhost:1313/posts/2019/20190812-1/</link>
      <pubDate>Mon, 12 Aug 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2019/20190812-1/</guid>
      <description>默认快捷键是: Ctrl + Alt + T , 可以在键盘-&amp;gt;快捷键中设置。&#xA;参考链接:&#xA;https://forum.manjaro.org/t/xfce-terminal-drop-down-option/45950/2 </description>
    </item>
    <item>
      <title>安装 Manjaro 之后的做的事情</title>
      <link>http://localhost:1313/posts/2019/20190812/</link>
      <pubDate>Mon, 12 Aug 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2019/20190812/</guid>
      <description>设置国内镜像源 sudo pacman-mirrors -i -c China -mrank # OK * 2 sudo pacman -Syyu sudo pacman -S vim 添加 arch 源 vim /etc/pacman.conf [archlinuxcn] Server = https://mirrors.tuna.tsinghua.edu.cn/archlinuxcn/$arch sudo pacman -Syyu pacman -S archlinux-keyring archlinuxcn-keyring sudo pacman -S visual-studio-code-bin sudo pacman -S ocaml opam 安装输入法 sudo pacman -S fcitx-im #默认全部安装 sudo pacman -S fcitx-configtool sudo pacman -S fcitx-sogoupinyin vim ~/.xprofile export LC_ALL=zh_CN.UTF-8 export GTK_IM_MODULE=fcitx export QT_IM_MODULE=fcitx export XMODIFIERS=&amp;#34;@im=fcitx&amp;#34; 安装缺少的字体 sudo pacman -S wqy-microhei sudo pacman -S wqy-bitmapfont wqy-microhei \ wqy-zenhei adobe-source-code-pro-fonts \ adobe-source-han-sans-cn-fonts ttf-monaco reboot 安装相关工具 sudo pacman -S google-chrome pacman -S net-tools dnsutils inetutils iproute2 tmux bash-completion sudo pacman -S docker vim /etc/sudoers.</description>
    </item>
    <item>
      <title>Manjaro 微信解决方案</title>
      <link>http://localhost:1313/posts/2019/20190810/</link>
      <pubDate>Sat, 10 Aug 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2019/20190810/</guid>
      <description>在 Manjaro 上使用 deepin-wine-chat&#xA;wget https://github.com/countstarlight/deepin-wine-wechat-arch/releases/download/v2.6.8.65-1/deepin-wine-wechat-2.6.8.65-1-x86_64.pkg.tar.xz sudo pacman -U deepin-wine-wechat-2.6.8.65-1-x86_64.pkg.tar.xz 在安装成功，登录微信成功，发送消息无法输入中文，主要原因是: archlinux应用不支持fcitx中文输,参考: https://www.jianshu.com/p/a3f1c5619ad2&#xA;$ cd /opt/deepinwine/apps/Deepin-WeChat $ vim run.sh #!/bin/sh # Copyright (C) 2016 Deepin, Inc. # # Author: Li LongYu &amp;lt;lilongyu@linuxdeepin.com&amp;gt; # Peng Hao &amp;lt;penghao@linuxdeepin.com&amp;gt; export XMODIFIERS=&amp;#34;@im=fcitx&amp;#34; export GTK_IM_MODULE=&amp;#34;fcitx&amp;#34; export QT_IM_MODULE=&amp;#34;fcitx&amp;#34; 重新启动微信，可以输入中文了，遇到同类问题，其他 wine app 解决方案类似。 参考链接:&#xA;https://aur.archlinux.org/packages/deepin-wine-wechat/ https://www.jianshu.com/p/a3f1c5619ad2 </description>
    </item>
    <item>
      <title>Manjaro 安装 CrossOver 找不到 lib32-nss-mdns</title>
      <link>http://localhost:1313/posts/2019/20190809/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2019/20190809/</guid>
      <description>解决方案： 从源码手动编译一个 32 位的动态链接库&#xA;源码地址: https://github.com/lathiat/nss-mdns/releases/download/v0.14.1/nss-mdns-0.14.1.tar.gz&#xA;wget https://github.com/lathiat/nss-mdns/releases/download/v0.14.1/nss-mdns-0.14.1.tar.gz tar -xf nss-mdns-0.14.1.tar.gz cd nss-mdns-0.14.1 # 编译出 32 位的动态链接库 ./configure &amp;#34;CFLAGS=-m32&amp;#34; &amp;#34;CXXFLAGS=-m32&amp;#34; &amp;#34;LDFLAGS=-m32&amp;#34; make cp .libs/libnss_mdns.so.2 /home/hellojukay/cxoffice/lib 顺道还把乱码的问题解决了&#xA;wget https://github.com/fphoenix88888/ttf-mswin10-arch/raw/master/ttf-ms-win10-zh_cn-10.0.18362.116-1-any.pkg.tar.xz tar -xf ttf-ms-win10-zh_cn-10.0.18362.116-1-any.pkg.tar.xz cd ttf-ms-win10-zh_cn-10.0.18362.116-1-any.pkg.tar.xz sudo mkdir -p /usr/share/fonts/WindowsFonts cp ./* /usr/share/fonts/WindowsFonts/ 参考链接:&#xA;https://www.codeweavers.com/support/forums/general?t=26;msg=204194 </description>
    </item>
    <item>
      <title>dash 的免费替代品</title>
      <link>http://localhost:1313/posts/2019/20190808/</link>
      <pubDate>Thu, 08 Aug 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2019/20190808/</guid>
      <description>Zeal 是一款免费的夸平台文档工具，可以用来替代 Mac OSX 下的 dash， 它的网址是： https://zealdocs.org/</description>
    </item>
    <item>
      <title>【翻译】k8s 从私有仓库获取镜像</title>
      <link>http://localhost:1313/posts/2019/20190802/</link>
      <pubDate>Fri, 02 Aug 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2019/20190802/</guid>
      <description>原文地址: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/&#xA;这篇文章将会教你在创建 pod 的时候如何正确从私有仓库获取镜像。&#xA;开始之前 你需要有一个 K8S 集群，并且安装配置好了 kubectl ，命令行能够访问你的集群。如果你还没有安装好 K8S ，那么请使用 minikube 安装， 或者使用我们为你准备好的集群&#xA;https://www.katacoda.com/courses/kubernetes/playground https://labs.play-with-k8s.com/ 检查版本信息 kubectl version, 在执行这个训练之前，你还需要有一个能登录 docker 私有仓库的账号。&#xA;登录 docker 仓库 在你的本地机器，你必须先登录 docker 仓库，才能获得 pull 私有仓库镜像的权限。&#xA;docker login {host} 会提示输入账号密码, 登录成功以后会更新 $HOME/.docker/config.json 配置文件。使用 cat 查看文件内容: cat ~/.docker/config.json 会输入类似如下的内容&#xA;{ &amp;#34;auths&amp;#34;: { &amp;#34;https://index.docker.io/v1/&amp;#34;: { &amp;#34;auth&amp;#34;: &amp;#34;c3R...zE2&amp;#34; } } } 该文件中保存了登录的 token 信息。&#xA;基于已经存在的 token 认证文件创建 K8S secret K8S 在 pull 镜像的时候会使用 docker 的登录认证信息来认证私有仓库的权限。如果你已经执行过 docker login ，并且登录成功，那么你可以将 token 信息复制到 K8S 集群中:</description>
    </item>
    <item>
      <title>【翻译】如何检查 centos 版本信息</title>
      <link>http://localhost:1313/posts/2019/20190731/</link>
      <pubDate>Wed, 31 Jul 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2019/20190731/</guid>
      <description>原文地址: https://www.thegeekdiary.com/how-to-check-centos-version/&#xA;有一些时候我需要了解当前的 Linux 服务的系统版本信息，来帮助我们排查一些问题。这篇文章将会介绍几个技巧来查看当前系统版本信息，总的来说有两种思路：&#xA;通过系统更新版本来了解系统信息 通过内核运行版本来了解系统信息 检查系统更新版本 在 RedHat/Centos 上有4个文件提供了信息的版本信息&#xA;/etc/centos-release /etc/os-release /etc/redhat-release /etc/system-release 他们的内容如下 [licong@analysis01 ~]$ cat /etc/centos-release CentOS Linux release 7.2.1511 (Core) [licong@analysis01 ~]$ cat /etc/os-release NAME=&amp;#34;CentOS Linux&amp;#34; VERSION=&amp;#34;7 (Core)&amp;#34; ID=&amp;#34;centos&amp;#34; ID_LIKE=&amp;#34;rhel fedora&amp;#34; VERSION_ID=&amp;#34;7&amp;#34; PRETTY_NAME=&amp;#34;CentOS Linux 7 (Core)&amp;#34; ANSI_COLOR=&amp;#34;0;31&amp;#34; CPE_NAME=&amp;#34;cpe:/o:centos:centos:7&amp;#34; HOME_URL=&amp;#34;https://www.centos.org/&amp;#34; BUG_REPORT_URL=&amp;#34;https://bugs.centos.org/&amp;#34; CENTOS_MANTISBT_PROJECT=&amp;#34;CentOS-7&amp;#34; CENTOS_MANTISBT_PROJECT_VERSION=&amp;#34;7&amp;#34; REDHAT_SUPPORT_PRODUCT=&amp;#34;centos&amp;#34; REDHAT_SUPPORT_PRODUCT_VERSION=&amp;#34;7&amp;#34; [licong@analysis01 ~]$ cat /etc/redhat-release CentOS Linux release 7.2.1511 (Core) [licong@analysis01 ~]$ cat /etc/system-release CentOS Linux release 7.2.1511 (Core) 还可以通过 rpm 查询某个文件的版本信息</description>
    </item>
    <item>
      <title>ocaml 语言的基本介绍</title>
      <link>http://localhost:1313/posts/2019/20190726/</link>
      <pubDate>Fri, 26 Jul 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2019/20190726/</guid>
      <description>ocaml 语言是 caml 语言的一种实现，读音：欧课摸。是一种能够编译成 native 代码的函数式编程语言，编写效率和运行效率都非常高。ocaml 也支持面向对象编程和过程式编程，同时 ocaml 是一门强类型编程语言，内置垃圾回收。&#xA;ocaml 的包管理工具是 opam, 网址是: https://opam.ocaml.org/packages/ , 他是基于源码的包管理工具，安装一个模块的方式是:&#xA;opam install &amp;lt;module&amp;gt; dune 是 ocaml 的标准的构建工具，类似于 gradle 之于 JAVA 的地位，网址是: https://dune.readthedocs.io/en/stable/quick-start.html 。dune 有一个标准配置文件,文件名字 dune, 里面定义了依赖和打包类型&#xA;(executable (name main)) dune build main.exe 这边就在 _build/default/ 目录下生成了 main.exe 文件， 这个文件虽然是 exe 后缀的， 但是并不是标示他是 windows 下的可执行文件。</description>
    </item>
    <item>
      <title>如何制作一个 deb 安装包</title>
      <link>http://localhost:1313/posts/2019/20190726-1/</link>
      <pubDate>Fri, 26 Jul 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2019/20190726-1/</guid>
      <description>一个标准的 deb 制作目录如下：&#xA;hellojukay@local hello-ocaml-deb (master) $ tree hello_0.0.1 hello_0.0.1 ├── DEBIAN │ └── control └── usr └── local └── bin └── hello 4 directories, 2 files 更目录下包含一个 DEBIAN/contorl 文件，内容信息如下:&#xA;Package: hello Version: 0.0.1 Section: base Priority: optional Architecture: amd64 Depends: libsomethingorrather (&amp;gt;= 1.2.13), anotherDependency (&amp;gt;= 1.2.6) Maintainer: hellojukay@163.com Description: Hello World Just print Hello &amp;lt;name&amp;gt; to console 其他目录的文本信息会被复制到对应的目录中去，我们使用 dpkg-deb 命令来制作安装包&#xA;dpkg-deb --build hello_0.0.1 如果不出意外的话会生成 hello_0.0.1.deb 文件,安装命令为&#xA;sudo apt install .</description>
    </item>
    <item>
      <title>jenkins 结合 k8s 动态构建</title>
      <link>http://localhost:1313/posts/2019/20190722/</link>
      <pubDate>Mon, 22 Jul 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2019/20190722/</guid>
      <description>第一步：在 jenkins 上安装 k8s 插件 第二步: 在 jenkins 上配置 k8s 插件，在系统设置中添加&amp;quot;云&amp;quot; 第三步: 第二部中需要添加凭证信息，制作方式如下：&#xA;[licong@k8s01v pki]$ pwd /etc/kubernetes/pki [licong@k8s01v pki]$ ls -al 总用量 60 drwxr-xr-x 3 root root 4096 7月 17 13:55 . drwxr-xr-x 4 root root 125 7月 17 13:56 .. -rw-r--r-- 1 root root 1249 7月 17 13:55 apiserver.crt -rw-r--r-- 1 root root 1090 7月 17 13:55 apiserver-etcd-client.crt -rw------- 1 root root 1675 7月 17 13:55 apiserver-etcd-client.key -rw------- 1 root root 1679 7月 17 13:55 apiserver.</description>
    </item>
    <item>
      <title>使用 kaniko 在 k8s 集群中构建镜像</title>
      <link>http://localhost:1313/posts/2019/20190722-1/</link>
      <pubDate>Mon, 22 Jul 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2019/20190722-1/</guid>
      <description>在 k8s 集群中构建镜像并不是一个负责的问题，主要是要将构建好的镜像推送到 private docker register 会有点麻烦，因为权限认证的问题，在 docker pull 的时候，我们使用 imagePullSecrets 设置来解决这个问题。&#xA;谷歌开发一个 kaniko 工具，用于解决在 k8s 中构建镜像相关的问题，这个工具允许你给他配置 docker auth 信息,命令如下：&#xA;基于已有的 credentials 创建 k8s secret kubectl create secret generic regcred \ --from-file=.dockerconfigjson=$HOME/.docker/config.json \ --type=kubernetes.io/dockerconfigjson 配置中使用这个 secret pipeline { agent { kubernetes { //cloud &amp;#39;kubernetes&amp;#39; yaml &amp;#34;&amp;#34;&amp;#34; kind: Pod metadata: name: kaniko spec: containers: - name: kaniko image: gcr.io/kaniko-project/executor:debug-539ddefcae3fd6b411a95982a830d987f4214251 imagePullPolicy: Always command: - /busybox/cat tty: true volumeMounts: - name: jenkins-docker-cfg mountPath: /root volumes: - name: jenkins-docker-cfg projected: sources: - secret: name: regcred items: - key: .</description>
    </item>
    <item>
      <title>k8s服务发布的几种类型</title>
      <link>http://localhost:1313/posts/2019/20190719/</link>
      <pubDate>Fri, 19 Jul 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2019/20190719/</guid>
      <description>k8s服务发布一共有 4 中类型:&#xA;ClusterIP: 集群内部分配 IP 地址，对外不可见(默认服务类型) NodePort：每个 node 都对外暴露一个端口，该端口的流量会被转发给 ClusterIP 的服务 LoadBalancer: 云服务商提供的，自动分配对外 IP 地址 ExternalName </description>
    </item>
    <item>
      <title>使用私有仓库安装 k8s</title>
      <link>http://localhost:1313/posts/2019/20190716/</link>
      <pubDate>Tue, 16 Jul 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2019/20190716/</guid>
      <description>使用 kubeadmin 安装 k8s 的时候会遇到一些墙的问题，导致安装比较麻烦。解决这个问题的方式，可以使用私有仓库来安装&#xA;登录私有仓库 私有仓库必须先登录了才能 pull 镜像&#xA;docker login docker.hellojukay.cn 指定私有仓库 有一个前提是私有仓库里面包含了，或者能够 pull 到所需的镜像&#xA;kubeadm init --image-repository 安装成功以后&#xA;kubeadm join 加入节点即可，会自动同步镜像的</description>
    </item>
    <item>
      <title>python 是如何查找模块的</title>
      <link>http://localhost:1313/posts/2019/20190708/</link>
      <pubDate>Mon, 08 Jul 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2019/20190708/</guid>
      <description>python 中一个模块是一个 .py 后缀的 python 文件，　一个包是指包含若干个 python 文件的文件夹，一般 python 包中都会包含一个 init.py 文件。&#xA;默认情况下， python 会在　$PYTHONPATH 目录中查找包和模块, 要知道 $PYTHONPATH 包含那些目录，可以通过如下代码来查看:&#xA;import sys; print(sys.path) 如果文件不在 $PYTHONPATH 中，　那么是无法通过 import 直接导入的。我们可以通过向　$PYTHONPATH 中追加一个新的目录&#xA;export PYTHONPATH=/path/to/your/package_or_module:$PYTHONPATH 或者&#xA;import sys sys.path.insert(0, &amp;#34;/path/to/your/package_or_module&amp;#34;) 如果你的某个包在 /path/to/your/package_or_module 目录下，那么这时候你就能直接在代码里面 import 这个包了&#xA;import package </description>
    </item>
    <item>
      <title>Centos 7 网卡命令规则</title>
      <link>http://localhost:1313/posts/2019/20190703/</link>
      <pubDate>Wed, 03 Jul 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2019/20190703/</guid>
      <description>网上很多 linux 网络设置的教程中都提到了 eth0 网卡配置，但是有时候我发现我的机器上并没有 eth0 网卡，反而有 enp0s31f6 网卡。&#xA;Centos 7 中将网卡命名和编号有了新的规则：&#xA;eno1: 代表主板bios内置网卡 ens1: 代表主板bios内置的PCI-E 网卡 enp2s0: PCI-E 独立网卡 eth0: 如果以上都不使用，最回到默认网卡 enp0s31f6 网卡属于第三种特效，centos 的网卡配置见&#xA;/etc/sysconfig/network-scripts </description>
    </item>
    <item>
      <title>jenkins DSL 操作 artifactory</title>
      <link>http://localhost:1313/posts/2019/20190702/</link>
      <pubDate>Tue, 02 Jul 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2019/20190702/</guid>
      <description>之前一直是使用 artifactory 的 rest api 来远程自动化操作 artiactory ，传个文件都需要使用 curl 命令，我觉得很不友好，于是搜了一下，发现 artifactory 提供了 jenkins 的插件，只是 DSL 的语法来操作 artifactory,在 jenkins 的全局配置中配置好了 artifactory 后就可以使用了， 例如上传一个文件:&#xA;rtUpload ( serverId: &amp;#34;Artifactory-1&amp;#34;, spec: &amp;#34;&amp;#34;&amp;#34;{ &amp;#34;files&amp;#34;: [ { &amp;#34;pattern&amp;#34;: &amp;#34;./*froggy*.zip&amp;#34;, &amp;#34;target&amp;#34;: &amp;#34;{repo}/{dir}/&amp;#34; } ] }&amp;#34;&amp;#34;&amp;#34; ) 更多的语法可以看 artifactory 的官网: https://www.jfrog.com/confluence/display/RTF/Working+With+Pipeline+Jobs+in+Jenkins</description>
    </item>
    <item>
      <title>jenkins pipeline 中 clone 一个 git 库</title>
      <link>http://localhost:1313/posts/2019/20190701/</link>
      <pubDate>Mon, 01 Jul 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2019/20190701/</guid>
      <description>目前找到了 4 种方式&#xA;方式1:&#xA;stage(&amp;#39;git clone&amp;#39;) { steps { sh &amp;#39;mkdir -p Module1&amp;#39; dir(&amp;#34;Module1&amp;#34;){ git branch: &amp;#34;1.0/develop&amp;#34;, credentialsId: &amp;#39;{credentialsId}&amp;#39;, url: &amp;#39;{gitrepo}&amp;#39; } sh &amp;#39;ls -al Module1&amp;#39; } } 方式2：&#xA;在 jenkins 的构建节点上配置好 git 仓库的 ssh 你要，然后使用 ssh 认证的方式来 clone&#xA;git clone {repo} Module1 方式3: 使用 https 方式认证，在 url 中擦入账号和密码&#xA;stage(&amp;#39;拉取devops-deploy&amp;#39;) { sh &amp;#34;if [ -d ${devops_deploy} ]; then rm -rf ${devops_deploy}; fi&amp;#34; withCredentials([usernamePassword(credentialsId: &amp;#39;{credentialsId}&amp;#39;, passwordVariable: &amp;#39;GIT_PASSWORD&amp;#39;, usernameVariable: &amp;#39;GIT_USERNAME&amp;#39;)]) { def u = URLEncoder.</description>
    </item>
    <item>
      <title>在 Makefile 中读取用户输入</title>
      <link>http://localhost:1313/posts/2019/20190531/</link>
      <pubDate>Fri, 31 May 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2019/20190531/</guid>
      <description>发先一个在 make 过程中读取账号密码的方法了&#xA;build: @read -p &amp;#34;Enter Username: &amp;#34; username;echo $${username} 这里的 $${username} 其实也可以改成 $$username 执行如下:&#xA;hellojukay@local test $ vim Makefile hellojukay@local test $ make Enter Username: hello world hello world hellojukay@local test $ 非常可惜的是：不支持 read -s, 就是说输入密码的时候是明文的。</description>
    </item>
    <item>
      <title>jenkins slave 清理过期镜像的方法</title>
      <link>http://localhost:1313/posts/2019/20190522/</link>
      <pubDate>Wed, 22 May 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2019/20190522/</guid>
      <description>jenkins 上一直在不停的构建新的镜像，导致镜像越来越多，写满了 /var/lib/docekr 所在的分区，所以我们需要定期的清理多余的镜像。&#xA;一般的，我们在开发周期构建镜像的时候，没有修改过镜像的版本号码，一个进行不停的 retag , 这样老的镜像的 tag 就会被覆盖，tag　变成 none。&#xA;node 8 0bf36d7ccc1e 4 weeks ago 895MB maven 3-jdk-8 f44a5194086a 5 weeks ago 636MB &amp;lt;none&amp;gt; &amp;lt;none&amp;gt; 6752e2093697 5 weeks ago 12.9MB swaggerapi/swagger-ui latest 6f941e6fd913 5 weeks ago 51.7MB 这种 tag 为 none 的镜像就已经可以删除了。 jenkins 上可以创建如下任务来删除这些没有作用的镜像。&#xA;pipeline { agent { label &amp;#34;node1&amp;#34; } stages { stage(&amp;#34;clean images with tag none&amp;#34;){ steps { parallel( node1: { sh(&amp;#34;docker image ls | grep none | awk &amp;#39;{print \$3}&amp;#39; | xargs -I {} docker rmi {} || true&amp;#34;) }, node2:{ sh(&amp;#34;docker image ls | grep months | awk &amp;#39;{print \$3}&amp;#39; | xargs -I {} docker rmi {} || true&amp;#34;) }) } } } } </description>
    </item>
    <item>
      <title>使用 prometheus 监控 jenkins</title>
      <link>http://localhost:1313/posts/2019/20190517/</link>
      <pubDate>Fri, 17 May 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2019/20190517/</guid>
      <description>为了看到大家每日的构建情况， 我们决定把 jenkins 监控起来。将监控指标在 grafana 上展示出来。我们采用 promthues 抓取和存储数据， 使用 jenkins 的 promtheus 插件来暴露数据。&#xA;jenkins 的 prometheus 插件地址: https://wiki.jenkins.io/display/JENKINS/Prometheus+Plugin&#xA;配置 promtheus 抓取任务&#xA;- job_name: &amp;#39;jenkins&amp;#39; metrics_path: &amp;#39;/prometheus/&amp;#39; scheme: https bearer_token: bearer_token static_configs: - targets: [&amp;#39;jenkins-server:443&amp;#39;] 最后我们配置一下 grafana 的展示面板 https://grafana.com/dashboards/9964</description>
    </item>
    <item>
      <title>命令行程序设计的最佳实践</title>
      <link>http://localhost:1313/posts/2019/20190510/</link>
      <pubDate>Fri, 10 May 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2019/20190510/</guid>
      <description>因为长期使用 linux 系统， 使用大量的 linux 命令。 我发现命令行参数的设计似乎遵循这某些设计哲学。比如，当你使用一个新的命令的时候，如果你不太熟悉某个参数，你可能会这样:&#xA;command -h 或者&#xA;command --help 或者&#xA;command help subcommand 你会使用 -h 或者 --help 查看帮助 ， 使用 help 来查看某个子命令的具体用法。当然， 你也可能会使用到 man&#xA;man command 绝大部分的命令行程序都遵守着这种契约。还有很多其他的默认设计规范，上面没有介绍到。 这篇文章的目的就是要列出这些不成文的设计哲学， 以便我们自己在编写命令行程序的时候不走弯路，也能顺畅的使用。&#xA;设计规范 程序返回合适的退出状态号码，执行成功返回０，否则返回对应的错误码，使用者能够参考返回码找到错误原因．&#xA;永远要支持 --version 和 --help, -h&#xA;支持长参数的简写,比如支持--number的同时支持简写-n,--number用于脚本文件中,s-n用于手动执行命令&#xA;使用-选项来处理标准输入和标准输出.&#xA;对于 bool 类型的参数-b=true和-b应该等价&#xA;支持多个 bool 类型的参数合并写　-i -t应该可以合并为-it&#xA;日志区分错误日志和提示日志，并且分日志级别，错误日志往标准错误输出中输出，其他日志往标准输出中输出&#xA;有默认参数，并且可以通过命令参数和环境变量来设置对应的值．&#xA;命令行参数优先于环境变量，环境变量优先于默认值.&#xA;具体建议 命令行简写 简写说明 -a &amp;ndash;append 的简写，　表示增加 -c &amp;ndash;color的简写，表示演示,&amp;ndash;clean的简写，表示清空 -d &amp;ndash;deamon 的简写，表示后台运行， &amp;ndash;dir 表示目录 -e &amp;ndash;enviroment的简写,表示环境变量 -f &amp;ndash;force的简写，表示强制执行，&amp;ndash;file的简写，表示者件路径｜ -g &amp;ndash;global 的简写，表示全局 -h &amp;ndash;help 的简写，显示帮助信息, &amp;ndash;human 表示人类可理解 -i, -I &amp;ndash;input 的简写，表示输入，&amp;ndash;ignore 的简写，表示忽略 -k &amp;ndash;keep的简写，表示保持 -l &amp;ndash;list的简写， 表示列表展示 -m &amp;ndash;motify的简写，表示修改 -n &amp;ndash;number的简写，　表示数量 -o &amp;ndash;output的简写，表示输出 -p &amp;ndash;port的简写，　表示端口 -q &amp;ndash;qualify的简写，表示独一 -r &amp;ndash;recursion的简写，表示递归 -s &amp;ndash;set的简写，　表示设置 -t 表示 &amp;ndash;terminal 或者 &amp;ndash;time -u,-U &amp;ndash;user 表示用户，　&amp;ndash;update 表示更新 -v, -V &amp;ndash;version的简写，显示版本信息或者调试信息 -w &amp;ndash;workspace的简写，表示工作空间 -x 显示执行过程 -y &amp;ndash;year的简写，表示年份 -z &amp;ndash;zone的简写，表示区域 </description>
    </item>
    <item>
      <title>在 Jenkinsfile 的 sh 中执行 awk</title>
      <link>http://localhost:1313/posts/2019/20190508/</link>
      <pubDate>Wed, 08 May 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2019/20190508/</guid>
      <description>在 Jenkinsfile 中如果要执行 awk :&#xA;sh(&amp;#34;ls -al | awk &amp;#39;{print $3}&amp;#39;&amp;#34;) 这么写可能会报错， 因为 $3 被 groovy 认为是要替换字符传， 当前上下文中并没有 3 这个变量，所以会报错。&#xA;解决这个问题的方式如下:&#xA;sh &amp;#34;&amp;#34;&amp;#34; ls -al | awk &amp;#39;{print \$3}&amp;#39; &amp;#34;&amp;#34;&amp;#34; 2020年01月15日更新 有同学的docker用户名中包含了 $ 符号，也可以用相同的方法来解决&#xA;sh &amp;#34;&amp;#34;&amp;#34; echo ${PASSWD} | docker -u \$xxx --password-stdin &amp;#34;&amp;#34;&amp;#34; 参考文档:&#xA;https://blog.isntall.us/node/34 https://stackoverflow.com/questions/43451380/right-syntax-using-command-sh-in-jenkinsfile </description>
    </item>
    <item>
      <title>在 docker 中运行 shadowsocks 客户端</title>
      <link>http://localhost:1313/posts/2019/20190429/</link>
      <pubDate>Mon, 29 Apr 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2019/20190429/</guid>
      <description>deepin 升级了以后, 不知道是哪个系统包被升级了, 我的 shadowsocks 客户端一直不能正常使用正常使用, 尝试和很多方法没有解决. 最后我终于开窍了: 此路不通, 我换条路走.&#xA;在 chrome 里面配置了插件 SwitchyOmega , 这个插件里面配置了代理服务器的地址和端口, 通常这个地址和端口是本机的 shadowsocks client, 好傻. 宿主机器上依赖有问题, 那我何不将 shadowsocks client 允许在 docker 中呢, 说这我就到 dockerhub 上找到了对于的镜像：&#xA;*　https://hub.docker.com/r/mritd/shadowsocks/&#xA;符合条件的镜像很多，　这个是使用最多的一个．　于是研究了一下这个镜像，Dockerfile 写的挺复杂的，启动参数也不够友好．　于是，参考他的 Dockerfile　删掉了一些功能和配置． 我从新打了一个新的镜像，　参数更加简单了，　对 docker-compose 支持也更加友好了．&#xA;docker pull hellojukay/shadowsocks:1.0.0 我也将这个镜像开源到 dockerhub 上了，　使用方式非常简单&#xA;https://hub.docker.com/r/hellojukay/shadowsocks&#xA;version: &amp;#39;2&amp;#39; services: ssclient: image: hellojukay/shadowsocks:1.0.0 container_name: &amp;#39;ssclient&amp;#39; restart: always ports: - 1080:1080 environment: SERVER: &amp;#39;xxx&amp;#39; PORT: xxx LISTEN: 1080 METHOD: &amp;#39;chacha20-ietf-poly1305&amp;#39; PASSWD: &amp;#39;q6Gsdfsdfx9sd&amp;#39; 使用 docker-compose 启动即可</description>
    </item>
    <item>
      <title>免密码使用 sudo</title>
      <link>http://localhost:1313/posts/2019/20190421/</link>
      <pubDate>Sun, 21 Apr 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2019/20190421/</guid>
      <description>在 linux 中， 默认情况下只有 root 用户能够在输入密码的情况下使用 sudo 命令。但是接触了 vagrant 以后， 你可能 会发现，vagrant 默认创建的用户: vagrant , 这个用户能够使用 sudo ， 而不需要输入密码就使用 sudo.&#xA;我查了一下， 就是配置 /etc/sudoers 这个文件, centos 和 debain 的配置方式还有一点不一样, 假设我们的用户是 hellojukay,我们 希望在输入密码的时候使用sudo.&#xA;centos 下配置如下内容，&#xA;vim /etc/sudoers # 加入如内容 hellojukay ALL=(ALL:ALL) NOPASSWD:ALL debain 中配置如下&#xA;vim /etc/sudoers.d/{filename} hellojukay ALL=(ALL:ALL) NOPASSWD:ALL 在 /etc/sudoers.d/ 文件夹中创建一个文件， 加入 hellojukay ALL=(ALL:ALL) NOPASSWD:ALL, 这样 hellojukay 就能使用任何命令了，这种方法在 centos 系统中也奏效。</description>
    </item>
    <item>
      <title>k8s 的一些小技巧</title>
      <link>http://localhost:1313/posts/2019/20190417/</link>
      <pubDate>Wed, 17 Apr 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2019/20190417/</guid>
      <description> k8s 中命令都是子命令的默认， 并且命令行选项特别多，不方便记忆，所以需要安装自动补全 echo &amp;#34;source &amp;lt;(kubectl completion bash)&amp;#34; &amp;gt;&amp;gt; $HOME/.bashrc k8s 镜像安装的时候, 默认是用 k8s.gcr.io 下载镜像, 也可以配置你自己的镜像仓库 kubeadm init --image-repository </description>
    </item>
    <item>
      <title>基于 vagrant 的 k8s 安装过程</title>
      <link>http://localhost:1313/posts/2019/20190414/</link>
      <pubDate>Sun, 14 Apr 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2019/20190414/</guid>
      <description>使用 vagrant 创建三个虚拟机 安装我们即将用到的工具 yum install git vim java groovy net-tools -y 安装 docker-ce 我们使用阿里云的 docker-ce 源代来安装 # 安装最新版本 yum install docker-ce 我们安装 k8s 相关命令行工具 添加 k8s 的 aliyun 的 yum 源, 编译 vi /etc/yum.repos.d/kubernetes.repo # 加入如下内容 [kubernetes] name=Kubernetes baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/ enabled=1 gpgcheck=1 repo_gpgcheck=1 gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg 安装相关命令行工具 yum install -y kubeadm kubectl kubelet 将 kubelet 加入到服务 systemctl enable kubelet 设置系统 关闭防火墙 systemctl stop firewalld systemctl disable firewalld 关闭交换分区 swapoff -a sudo sed -i &amp;#39;/ swap / s/^\(.</description>
    </item>
    <item>
      <title>centos 使用 aliyun 源安装 k8s 命令行工具</title>
      <link>http://localhost:1313/posts/2019/20190413/</link>
      <pubDate>Sat, 13 Apr 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2019/20190413/</guid>
      <description>国内网络安装 k8s 命令行工具特别不方便, 我找到了阿里云的 yum 源来加速安装.&#xA;添加 yum 源代 vi /etc/yum.repos.d/kubernetes.repo 添加如下内容:&#xA;[kubernetes] name=Kubernetes baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/ enabled=1 gpgcheck=1 repo_gpgcheck=1 gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg 安装 k8s 命令行工具 yum install -y kubelet kubeadm kubectl 检查安装结果 [vagrant@localhost ~]$ kubectl version Client Version: version.Info{Major:&amp;#34;1&amp;#34;, Minor:&amp;#34;14&amp;#34;, GitVersion:&amp;#34;v1.14.1&amp;#34;, GitCommit:&amp;#34;b7394102d6ef778017f2ca4046abbaa23b88c290&amp;#34;, GitTreeState:&amp;#34;clean&amp;#34;, BuildDate:&amp;#34;2019-04-08T17:11:31Z&amp;#34;, GoVersion:&amp;#34;go1.12.1&amp;#34;, Compiler:&amp;#34;gc&amp;#34;, Platform:&amp;#34;linux/amd64&amp;#34;} The connection to the server localhost:8080 was refused - did you specify the right host or port? [vagrant@localhost ~]$ Ok , 安装成功了.&#xA;2020-06-09日更新 这个可以找到历史版本的 k8s 组件</description>
    </item>
    <item>
      <title>k8s版本问题</title>
      <link>http://localhost:1313/posts/2019/20190412/</link>
      <pubDate>Fri, 12 Apr 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2019/20190412/</guid>
      <description>对于镜像安装 k8s 而言, 所有版本的 k8s 都有一套配套的镜像, 通过&#xA;kubeadm config images list --kubernetes-version 1.13.0 看到对于的镜像, 1.13.0 版本所需要的镜像如下:&#xA;k8s.gcr.io/kube-apiserver:v1.13.0 k8s.gcr.io/kube-controller-manager:v1.13.0 k8s.gcr.io/kube-scheduler:v1.13.0 k8s.gcr.io/kube-proxy:v1.13.0 k8s.gcr.io/pause:3.1 k8s.gcr.io/etcd:3.2.24 k8s.gcr.io/coredns:1.3 </description>
    </item>
    <item>
      <title>python项目目录结构建议</title>
      <link>http://localhost:1313/posts/2019/20190310/</link>
      <pubDate>Sun, 10 Mar 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2019/20190310/</guid>
      <description>在我们团队，我们看到用python写代码的同学，他们的项目目录结构都非常乱，五花八门，每个同学都是随意的按照自己的喜好来创建文件夹，源码散落在这个文件夹中，很难看出代码的入口是在哪里。&#xA;JAVA有标准的maven目录结构，golang也有建议的目录结构，那么我想python是不是也有一个比较好的目录结构组织方式呢。我看了下几个比较流行的python开源项目。&#xA;flask requests thefuck compose tensorflow django 我也网上查了一下best practice https://stackoverflow.com/questions/193161/what-is-the-best-project-structure-for-a-python-application&#xA;基本上可以归纳出一个比较大众的，符合开源社区习惯的目录结构:&#xA;├── README.md ├── docs ├── project │ ├── __init__.py │ ├── __main__.py │ ├── moduleA │ │ ├── __init__.py │ │ └── packageA.py │ └── moduleB │ └── __init__.py ├── setup.py └── tests └── moduleA └── test_packageA.py 我们可以借鉴这种方式来安排目录结构.</description>
    </item>
    <item>
      <title>快速生成gitignore</title>
      <link>http://localhost:1313/posts/2019/20190307/</link>
      <pubDate>Thu, 07 Mar 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2019/20190307/</guid>
      <description>看到大家提交代码都比较随意，把一些本地的工程文件都提交到了git仓库中，这样会带来一个坏处，别的同事pull了你的代码，以后发现在自己本地环境跑不起来，因为工程文件中定义了一些工程路径，二进制包路径之类的配置。&#xA;在线生成 自己手写gitignore比较麻烦，我找了一个能自动生成gitignore文件的方式，https://gitignore.io/这个网站只有输入相关信息就能生成对于的.gitignore文件，基于上述文件，大部分情况下默认生成配置就够了。有特殊需求，再自己手动修改一下。 在本地工程目录的根目录下创建.gitignore文件，将上述生成配置拷贝进去即可。&#xA;touch .gitignore 命令行方式 我是一个用惯了命令行界面的大佬，这种图形界面的东西我根本就看不上。看下这里 选用一种你看得上眼的命令行方式，我选择bash&#xA;echo &amp;#34;function gi() { curl -sL https://www.gitignore.io/api/\$@ ;}&amp;#34; &amp;gt;&amp;gt; \ ~/.bashrc &amp;amp;&amp;amp; source ~/.bashrc 作为大佬的你，可能早已经从上面的url中发现了你中猫腻。&#xA;使用方式gi + 任意关键字,逗号隔开,我使用Pycharm来编写python代码&#xA;gi python,pycharm &amp;gt;&amp;gt; .gitignore 我使用vscode来编写golang代码&#xA;gi go,visualstudiocode 慢慢玩吧。&#xA;相关项目 https://www.gitignore.io https://github.com/github/gitignore https://github.com/karan/joe </description>
    </item>
    <item>
      <title>记录一次JAVA死锁分析过程</title>
      <link>http://localhost:1313/posts/2019/20190306/</link>
      <pubDate>Wed, 06 Mar 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2019/20190306/</guid>
      <description>从昨天开始，研发和测试的同学就在群里一直反馈服务器经常卡死，服务不可用，服务日志也看不到任何异常信息，让研发同学一顿查找原因，找不到原因，最后让我给解决一下。&#xA;我首先登录到服务器，容器是没有退出的&#xA;docker logs snc-fw-gateway 查看标准输出的内容，没有异常，通过浏览器发送请求，也没有新的日志产生，所以我怀疑是不是JAVA进程退出了，容器没有退出，但是好像不可能，因为进程退出以后，容器一定也会退出。&#xA;-bash-4.2$ docker exec -it snc-fw-gateway sh /app $ jps 5 app.jar 7340 Jps /app $ 通过jsp命令，发现进程是存在的。&#xA;我怀疑是不是进程在哪里Hang住了&#xA;-bash-4.2$ docker exec -it snc-fw-gateway jstack 5 &amp;gt; jstack.log -bash-4.2$ ls jstack.log -bash-4.2$ 看线程状态&#xA;hellojukay@local ~ $ grep Thread.State jstack.log java.lang.Thread.State: RUNNABLE java.lang.Thread.State: WAITING (parking) java.lang.Thread.State: TIMED_WAITING (parking) java.lang.Thread.State: TIMED_WAITING (parking) java.lang.Thread.State: WAITING (on object monitor) java.lang.Thread.State: BLOCKED (on object monitor) java.lang.Thread.State: RUNNABLE java.lang.Thread.State: BLOCKED (on object monitor) java.</description>
    </item>
    <item>
      <title>【翻译】docker run手册</title>
      <link>http://localhost:1313/posts/2019/20190304/</link>
      <pubDate>Mon, 04 Mar 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2019/20190304/</guid>
      <description>docker运行的进程是相互隔离的，一个容器在宿主机器上也就是一个普通的进程。当执行docker run的时候，一个容器进程会被启动，他有自己的文件系统，有自己的网络，有自己的进程树。这篇文章将会详细额介绍docker run的每个命令行参数，来通知容器的运行时状态。&#xA;基本的docker run看起来像这样:&#xA;$ docker run [OPTIONS] IMAGE[:TAG|@DIGEST] [COMMAND] [ARG...] docker run命令必须给定一个明确的镜像。容器执行能够指定如下参数：&#xA;前台运行还是后台运行 容器的唯一标示 网络设置 运行是时的CPU和内存相关设置 使用docker run命令行选项能够覆盖镜像的一些默认参数。因为docker版本的设置，你运行docker命令的时候，也许需要sudo，为了避免在执行docker命令的时候使用sudo,你可以创建一个docker的用户组，将当前用户加入到docker这个用户分组中来。&#xA;前台运行还是后台运行 默认情况下，启动容器后容器是前台运行的，如果你需要容器在后台运行，那么你需要使用 -d选项来指定运行模式。&#xA;-d=false: Detached mode: Run container in the background, print new container id 启动容器的时候，使用-d=true或者直接-d选项，容器会在后台启动。docker容器设计的是，当容器中的进程退出，那么容器就会自动退出。除非你使用了--rm选项。如果你同时使用-d和--rm选项，容器中进程退出偶，容器首先就会被删除掉。&#xA;不要使用service x start来启动一个后台的容器，例如，这里尝试启动nginx服务：&#xA;$ docker run -d -p 80:80 my_image service nginx start 这里成功的启动了nginx服务，然而这样nginx经常退出，容器是没有感知的，最后导致以为服务存在，其实是服务是不可用的。正确的启动nginx的方式如下:&#xA;$ docker run -d -p 80:80 my_image nginx -g &amp;#39;daemon off;&amp;#39; 在前台运行的模式(默认-d选项是不激活的)，docker容器是在前台运行的，能够在当前的终端输入输入信息，以及错误输出。&#xA;容器的唯一标示 唯一标示一个容器有三种方式&#xA;标示类型 例子 UUID &amp;ldquo;f78375b1c487e03c9438c729345e54db9d20cfa2ac1fc3494b6eb60872e74778&amp;rdquo; 短UUID &amp;ldquo;f78375b1c487&amp;rdquo; 容器名字 &amp;ldquo;evil_ptolemy&amp;rdquo; UUID产生自后台运行的容器，如果一个容器在启动的时候没有通过--name指定容器名字，那么就会产生一段随机的字符串作为容器的唯一标示。这段随机字符串一个一串uuid，它的长度很长，通常情况我们只需取前面几个字符就能唯一标示一个容器了。如果容器指定了名字，那么容器容器和使用容器ID一样的效果。 我们可以通过--cidfile选择来指定一个文件，容器的ID会被自动写入到这个文件中。</description>
    </item>
    <item>
      <title>使用aliyun的yum仓库安装docker</title>
      <link>http://localhost:1313/posts/2019/20190227/</link>
      <pubDate>Wed, 27 Feb 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2019/20190227/</guid>
      <description>默认情况下使用docker官方的yum源来安装docker,因为网络下载慢，所以非常耗时。还好阿里云提供了yum镜像功能，所以我们能使用阿里云的yum源来加速我们的docker安装。使用方式如下：&#xA;删除已经安装的docker工具 sudo yum remove docker \ docker-client \ docker-client-latest \ docker-common \ docker-latest \ docker-latest-logrotate \ docker-logrotate \ docker-selinux \ docker-engine-selinux \ docker-engine 安装部分依赖工具 sudo yum install -y yum-utils device-mapper-persistent-data lvm2 添加阿里云yum源 sudo wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 查看所有的docker包 bash-4.2$ yum list docker-ce --showduplicates Loaded plugins: fastestmirror Determining fastest mirrors elasticsearch-6.x 405/405 Installed Packages docker-ce.x86_64 18.06.0.ce-3.el7 @docker-ce-stable Available Packages docker-ce.x86_64 17.03.0.ce-1.el7.centos docker-ce-stable docker-ce.x86_64 17.03.1.ce-1.el7.centos docker-ce-stable docker-ce.x86_64 17.</description>
    </item>
    <item>
      <title>在docker中运行flyway</title>
      <link>http://localhost:1313/posts/2019/20190226/</link>
      <pubDate>Tue, 26 Feb 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2019/20190226/</guid>
      <description>如果你还没有听说flyway,请移步flyway。大部分情况下，我们是在java中使用mvn插件的方式来使用flyway，虽然flyway是 使用java语言编写的，但是也提供了命令行的方式来使用它，我们也可以将他打包在docker容器中。官方有专门的项目来给flyway打镜像https://github.com/flyway/flyway-docker。&#xA;所以我只需要官方的目录结构来配置即可https://hub.docker.com/r/boxfuse/flyway。&#xA;这里要说明的是flyway的配置文件配置项:&#xA;flyway.url=jdbc:mysql://xxxxx:3306/xxx flyway.username=xxx flyway.password=xxx flyway.baselineDescription=V1.0 flywaydb.placeholderReplacment=false </description>
    </item>
    <item>
      <title>python发布到pip仓库</title>
      <link>http://localhost:1313/posts/2019/20190222/</link>
      <pubDate>Fri, 22 Feb 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2019/20190222/</guid>
      <description>和java的maven一样，python也有自己的中央仓库https://pypi.org/,也是按照相似的方式来打包项目的，maven靠的pom.xml,而Python靠的是setup.py:&#xA;#!/usr/bin/env python # coding=utf-8 from setuptools import setup &amp;#39;&amp;#39;&amp;#39; 把redis服务打包成C:\Python27\Scripts下的exe文件 &amp;#39;&amp;#39;&amp;#39; setup( name=&amp;#34;RedisRun&amp;#34;, #pypi中的名称，pip或者easy_install安装时使用的名称，或生成egg文件的名称 version=&amp;#34;1.0&amp;#34;, author=&amp;#34;Andreas Schroeder&amp;#34;, author_email=&amp;#34;andreas@drqueue.org&amp;#34;, description=(&amp;#34;This is a service of redis subscripe&amp;#34;), license=&amp;#34;GPLv3&amp;#34;, keywords=&amp;#34;redis subscripe&amp;#34;, url=&amp;#34;https://ssl.xxx.org/redmine/projects/RedisRun&amp;#34;, packages=[&amp;#39;RedisRun&amp;#39;], # 需要打包的目录列表 # 需要安装的依赖 install_requires=[ &amp;#39;redis&amp;gt;=2.10.5&amp;#39;, &amp;#39;setuptools&amp;gt;=16.0&amp;#39;, ], # 添加这个选项，在windows下Python目录的scripts下生成exe文件 # 注意：模块与函数之间是冒号: entry_points={&amp;#39;console_scripts&amp;#39;: [ &amp;#39;redis_run = RedisRun.redis_run:main&amp;#39;, ]}, # long_description=read(&amp;#39;README.md&amp;#39;), classifiers=[ # 程序的所属分类列表 &amp;#34;Development Status :: 3 - Alpha&amp;#34;, &amp;#34;Topic :: Utilities&amp;#34;, &amp;#34;License :: OSI Approved :: GNU General Public License (GPL)&amp;#34;, ], # 此项需要，否则卸载时报windows error zip_safe=False ) python的打包方式:</description>
    </item>
    <item>
      <title>国家图书馆一日游</title>
      <link>http://localhost:1313/posts/2019/20190217/</link>
      <pubDate>Sun, 17 Feb 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2019/20190217/</guid>
      <description>来北京2年了，还是没有去过国家图书馆。今天第一次去，转了一下。国家图书馆在4四号线的国家图书馆站,从康营家园过去，一个半小时就能到达。 进入图书馆要过安检，不让携带比A4纸大的包，我带着电脑包过去，因为我的包大小很尴尬，还是让进去了。进入以后，第一看到一圈的读者在自习 图书馆的人特别多，很少有空座位，学习氛围特别好，是一个学习与消遣时光的好地方 一个大叔因为找不到阅览座位，坐在窗户边上抄书，好像是在看围棋相关的资料，我看到了一本《围棋入门》。希望我到了这个年纪还能有学习知识的热情，还能有不认老的精神。 </description>
    </item>
    <item>
      <title>在docker-compose中使用环境变量</title>
      <link>http://localhost:1313/posts/2019/20190122-1/</link>
      <pubDate>Tue, 22 Jan 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2019/20190122-1/</guid>
      <description>和Makefile一样，docker compose中也是可以使用环境变量的，也是使用${var}这样的方式来使用&#xA;version: &amp;#39;3&amp;#39; services: app: build: context: ./docker/app dockerfile: Dockerfile image: shippingdocker/app:latest networks: - appnet volumes: - .:/var/www/html ports: - ${APP_PORT}:80 working_dir: /var/www/html cache: image: redis:alpine networks: - appnet volumes: - cachedata:/data db: image: mysql:5.7 environment: MYSQL_ROOT_PASSWORD: secret MYSQL_DATABASE: homestead MYSQL_USER: homestead MYSQL_PASSWORD: secret ports: - ${DB_PORT}:3306 networks: - appnet volumes: - dbdata:/var/lib/mysql node: build: context: ./docker/node dockerfile: Dockerfile image: shippingdocker/node:latest networks: - appnet volumes: - .:/opt working_dir: /opt command: echo hi networks: appnet: driver: bridge volumes: dbdata: driver: local cachedata: driver: local 这里面好几个端口都是使用的环境变了来指定的，我们可以在启动docker compose的时候，传递这个环境变量</description>
    </item>
    <item>
      <title>监控 golang 程序的运行状态</title>
      <link>http://localhost:1313/posts/2019/20190122/</link>
      <pubDate>Sat, 12 Jan 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2019/20190122/</guid>
      <description>prometheus是一个非常棒的工具，结合grafana能够让我在不写代码，或者少写代码的情况下搭建一套有效的监控体系。这里介绍一下prometheus监控golang程序的方式。&#xA;要想你的程序能够被监控，你就必须要将程序运行中的各项目指标暴露出来，提供给promtheus采集信息。我们可以使用promethues提供的golang客户端暴露自身的运行时信息。代码例子如下:&#xA;package main import ( &amp;#34;log&amp;#34; &amp;#34;net/http&amp;#34; &amp;#34;github.com/prometheus/client_golang/prometheus/promhttp&amp;#34; ) func main() { http.Handle(&amp;#34;/metrics&amp;#34;, promhttp.Handler()) log.Fatal(http.ListenAndServe(&amp;#34;:8080&amp;#34;, nil)) } go run main.go 访问本地的8080端口就能看到监控的指标,这里监控的都是默认指标，当然你可以可以自定义你需要的量化的指标，然后暴露出来，具体做法我不介绍了。 现在我们要配置promtheus，让他采集我们的监控指标&#xA;- job_name: &amp;#39;golang&amp;#39; scrape_interval: 20s metrics_path: /metrics static_configs: - targets: [&amp;#39;localhost:8080&amp;#39;] 启动promethues，我们golang指标就被采集到了时序数据库中，接下来就是把这些指标在grafana图形化展示出来，最后展示出来的效果如下: 如果服务数量较多，可以考虑将服务注册到consul中去，promethues通过服务发现来采集需要监控的服务。</description>
    </item>
    <item>
      <title>一个golang的goroutine pool的简单实现</title>
      <link>http://localhost:1313/posts/2019/20190106/</link>
      <pubDate>Sun, 06 Jan 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2019/20190106/</guid>
      <description>宗旨就是使用单个goroutine持续消费channel中的function对象。&#xA;package main import ( &amp;#34;time&amp;#34; ) const BufferSize = 16 type Pool struct { ch chan func() size int } func NewPool(size int)*Pool{ p := new(Pool) p.ch = make(chan func(),BufferSize) p.size = size return p } func (p *Pool)Start(){ p.loop() } func (p *Pool)loop(){ for i := 0; i &amp;lt; p.size ; i++{ go func(ch chan func()){ for{ select { case f := &amp;lt;- ch: f() default: continue } } }(p.</description>
    </item>
    <item>
      <title>我的2018年和2019年</title>
      <link>http://localhost:1313/posts/2019/20190101/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2019/20190101/</guid>
      <description>2018年已经过去了，现在是2019年1月1日，在先写篇文章的时候，我正患严重的的感冒，想到的我是这样的方式跨年的。&#xA;2018年买了单反相机，去了很多地方，认识了很多新的朋友，那些时光都很开心。去过内蒙古，山西，四川，陕西，甘肃&amp;hellip;，一直到大学我才第一次离开我居住的 的县城，这一年去了好多地方，每一次都是难忘的经历。2018年，我给自己的愿望是参加一个正经的开源项目，掌握docker的大规模部署，阅读golang的标准库，学习 前端相关的技术。docker部署的技能我掌握了，golang源码库没有时间看，我也不再需要写前端了。开源项目我有使用过好多，给golang官方提交了bug，给gin框架共享了代码。&#xA;2019年我希望自己也能像2018年一样，去更过没有去过的地方，认识新的朋友，吃没有吃过的食物，学习新的技术。</description>
    </item>
    <item>
      <title>docker删除镜像卡顿</title>
      <link>http://localhost:1313/posts/2018/20181229/</link>
      <pubDate>Sat, 29 Dec 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20181229/</guid>
      <description>线上编译卡主了，卡在执行 docker rmi {image}:{tag} 的地方，我知道执行 docker images 会很卡，但是没有想到删除镜像也会卡主。我的猜测是镜像太多的原因，所以我想删除一部分到的镜像，但是当我执行 docker rmi $(docker images -aq) 还是很卡。执行了一下 docker system df 果然，镜像存储已经快要占用了满了。&#xA;所以我想暴力解决问题，直接删除 /var/lib/docker 文件夹，因为所有的镜像和卷都是存储在这个文件夹中了。 systemctl stop docker 先关闭docker进程，然后删除文件夹，但是提示我文件夹被占用，其实是没有被占用的。所以我重启了机器 reboot ，让后再关闭docker,删除 /var/lib/docker 。大功告成.&#xA;2018年12月30日更新 /var/lib/docker 这个目录是docker的工作目录，里面存储了镜像，网络，volume，容器。所以说，如果删除这个文件，那么以上所有东西都会被删除, 当然登录仓库的信息也会被删除，也就是说你需要重新登录一次仓库.</description>
    </item>
    <item>
      <title>brew访问加速</title>
      <link>http://localhost:1313/posts/2018/20181226/</link>
      <pubDate>Wed, 26 Dec 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20181226/</guid>
      <description>brew是mac上的包管理神器，但是有时候访问服务比较慢，这是我不能忍受的，我们需要加速一个brew的安装速度，brew的源都是github上的项目，所以我们只需要找对应项目的镜像项目来替换他 就能加速我们访问速度。这里我将自己的mac的源都换成了清华的源，方法如下：&#xA;替换brew.git&#xA;cd &amp;#34;$(brew --repo)&amp;#34; git remote set-url origin https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/brew.git 替换homebrew-core.git&#xA;cd &amp;#34;$(brew --repo)/Library/Taps/homebrew/homebrew-core&amp;#34; git remote set-url origin https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-core.git 替换homebrew-bottles&#xA;echo &amp;#39;export HOMEBREW_BOTTLE_DOMAIN=https://mirrors.ustc.edu.cn/homebrew-bottles&amp;#39; &amp;gt;&amp;gt; ~/.bash_profile source ~/.bash_profile 更新生效&#xA;brew update 安装速度明显变快了.</description>
    </item>
    <item>
      <title>一个简单的端口转发方式</title>
      <link>http://localhost:1313/posts/2018/20181225/</link>
      <pubDate>Tue, 25 Dec 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20181225/</guid>
      <description>今天介绍一个简单的端口转发工具:rinetd， 这个工具的安装和配置非常的简单。&#xA;安装 使用源码安装的方式来安装这个工具&#xA;[root@localhost rinetd]# cd ~/zhenyutest/ [root@localhost rinetd]# wget http://www.boutell.com/rinetd/http/rinetd.tar.gz [root@localhost rinetd]# tar -xvf ~/zhenyutest/rinetd.tar.gz [root@localhost rinetd]# cd ~/zhenyutest/rinetd/ [root@localhost rinetd]# sed -i &amp;#39;s/65536/65535/g&amp;#39; rinetd.c [root@localhost rinetd]# mkdir /usr/man/ [root@localhost rinetd]# make &amp;amp;&amp;amp; make install cc -DLINUX -g -c -o rinetd.o rinetd.c rinetd.c:176:6: 警告：与内建函数‘log’类型冲突 [默认启用] void log(int i, int coSe, int result); ^ cc -DLINUX -g -c -o match.o match.c gcc rinetd.o match.o -o rinetd install -m 700 rinetd /usr/sbin install -m 644 rinetd.</description>
    </item>
    <item>
      <title>关于持续集成的一点想法</title>
      <link>http://localhost:1313/posts/2018/20181224/</link>
      <pubDate>Mon, 24 Dec 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20181224/</guid>
      <description>目前团队里面我们团队是使用JAVA语言编写代码，分模块的方式合作，大家编写了自己的maven模块以后deploy包artifactory中, 然后有一个gateway项目整合所有的maven模块，这样方式是JAVA开发的基本流程吧。但是有一个点，我觉得有问题的地方是，大 加都是在自己的项目中完全的编写好了自己的功能以后，才将自己的功能合并到gateway项目中，这样会存在一个比较严重的问题， 那就是合并起来会非常的困难，编写模块的人考虑的本模块的细节，没有考虑如何与gateway整合，也没有考虑如何与其他模块进行 交互，在整合的时候，又需要去修改maven模块中的实现细节。一两个模块还好，如果需要整合的模块比较多，那么这个问题就会比 较的严峻了。&#xA;项目在漫长的开发前期没有得到整合，也就意味着无法部署，也无法集成测试,导致在很长一段时间内看不到工作成果，也无法量化项目进度这样很容易导致项目延期。更加严重的后果是，一次性完成集成。变更的地方太多，需要集成测试验证的点会比较多，测试压力。就会出现测试同事，前面半个月休息，后面半个月加班赶进度的 情况。&#xA;理想的持续集成情况是，项目在创建以后，就已经能够独立运行，没完成一个小的feature，在自测完成以后，我立刻集成到集成开发分支，在集成分支上进行集成自动化测试集成不成功，或者集成测试不通过，也不应该继续集成，必须停下来，将当前的问题解决。如此的反复迭代项目，我们任务在集成开发分支上的功能点，就是已经开发完成的功能点 ，以这样的方式来进来项目进度的评估。看板工作流程，工作完成的标准也是这个标准。&#xA;关候于持续集成，还要一点。如果团队人数比较多，我们分配任务的时候，不要任务打的太散，避免一件事情能够一个做的情况却交给了多个人做。尽量避免代码集成和人员沟通的成本。</description>
    </item>
    <item>
      <title>软件开发总结</title>
      <link>http://localhost:1313/posts/2018/20181219/</link>
      <pubDate>Wed, 19 Dec 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20181219/</guid>
      <description>Q: 什么时候需要编写代码？ A: 现有的，开源的解决方案无法解决的当前问题，我们才需要写代码。写代码，维护代码会带来一定的人力和时间的成本的。尽量不要自己写写代码，尽量使用开源的解决方案。当然，如果开源方案不可控，代码难以掌控，尽量不要引入项目。所以我们需要对比，使用成本最低的方案。&#xA;Q: 什么时候需要使用设计模式？ A: 如果当前程序足够复杂了，我们才考虑使用设计模式去重构他，&amp;ldquo;简单的，丑陋的&amp;quot;代码并不是坏代码，反而设计的代码让人难于阅读，难于维护。&#xA;Q: 使用什么编程语言？ A: 考虑成本有限，使用成本最低的编程语言，成本有那些内容呢？学习成本，开发效率，维护成本，交付成本，人才招聘成本。这些成本都是取舍的，看你比较在意那些。&#xA;Q: 什么时候性能优化？ A: 当性能即将，或者是已经影响产品本身的体验的时候，需要考虑优化，而且，在性能优化之前必须要profile，只有知道瓶颈在哪里，才能做到针对性的优化。你以为的双重 循环可能是性能的瓶颈，可能事实不是这个的。</description>
    </item>
    <item>
      <title>【翻译】Linux进程全知道</title>
      <link>http://localhost:1313/posts/2018/20181216/</link>
      <pubDate>Sun, 16 Dec 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20181216/</guid>
      <description>这篇文章将会介绍在Linux中，进程是如何产生，管理和销毁的。&#xA;进程是操作系统内执行的任务，程序是磁盘存储的一系列机器码和数据的集合。当一个程序启动的时候，就创建了一个新的进程，进程的状态是动态的，随着机器指令的执行而变化，他主要包含一些寄存器，计数器和数据。进程之间的状态是相互独立的，一个进程奔溃不会影响操作系统上的其他进程。每一个进程在内存中都有自己的独立的地址空间。&#xA;在进程的生命周期中，他会使用操作系统的许多资源，是运行的时候会使用CPU和物理内存以及数据。也许会打开文件，打开设备。其余的进程必须等待当前的进程释放CPU才能得到执行。Linux操作系统必须跟踪进程和进程使用的资源，以确保一个进程不会独占大部分的内存和CPU。&#xA;在系统中，最常用的资源就是CPU，他只能同一时间被一个进程占用。Linux是一个多任务操作系统，每一段时间内都运行多个进程。如果有多个CPU, 系统主剩下的进程必须要等待有一个一个CPU空闲可以使用，这个进程才能够得到执行。多处理是用来解决并发问题的一个比较简洁的方法。&#xA;linux支持多个格式的可执行文件，ELF就是其中一种.&#xA;Linux进程 linux能够管理操作系统中的进程，每一个进程在操作系统中都是一个task_struct结构体,有个一个指针指向一个task_struct的数组，数组里面就是所有的进程。这也就意味着linux系统是可以设置进程数量的最大值和最小值的，最大值默认是512,也就是说能管理一个512个进程。每产生一个新的进程，就选出一个可能的空间来保存该进程。为了便于场照，当前正在运行的进程被一个current指针指向着。 原文地址: https://www.tldp.org/LDP/tlk/kernel/processes.html</description>
    </item>
    <item>
      <title>linux上网络问题排查工具</title>
      <link>http://localhost:1313/posts/2018/20181208/</link>
      <pubDate>Sat, 08 Dec 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20181208/</guid>
      <description>在linux上有非常多的工具，能在让你在排查问题多额时候获取有用的信息，这篇文件将会介绍一些network相关的troubleshot技巧。&#xA;ifconfig ifconfig是linux上设置网卡信息的命令，他们启动网卡，禁止网卡，查看网卡的ip地址个mac地址等等.&#xA;# 查看所有网卡的信息 ifconfig # 查看eth0网卡的信息 ifconfig eth0 # 设置 eth0 网卡的ip地址和子网掩码 ifconfig eth0 192.168.50.5 netmask 255.255.255.0 # 启用eth0网卡 ifup eth0 # 禁止eh0网卡 ifdown eth0 # 设置eth0网卡的最大通讯包大小 ifconfig eth0 mtu xxx ping ping是最常用的检查两个机器是否网络连通的方式，&#xA;ping 192.168.1.1 ping baidu.com ping是基于ICMP协议，因为可以设置ICMP不响应，所以有时候这个方式不那么管用。 往/etc/sysctl.conf中加入net.ipv4.icmp_echo_ignore_all=1然后sysctl -p刷新就能禁止ping返回了,ping命令能够指定发送包的次数:&#xA;# 发送五次 ping -c 5 baidu.com traceroute traceroute是检查网卡中数据包的ip路由情况的&#xA;hellojukay@local:~/data/Code/github/blog$ traceroute baidu.com traceroute to baidu.com (220.181.57.216), 30 hops max, 60 byte packets 1 Hiwifi.lan (192.168.199.1) 0.393 ms 0.451 ms 0.</description>
    </item>
    <item>
      <title>【翻译】nmap命令介绍</title>
      <link>http://localhost:1313/posts/2018/20181202/</link>
      <pubDate>Sun, 02 Dec 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20181202/</guid>
      <description>nmap是一个开源的网络扫描工具，在网络方便使用较多。然后nmap的命令行用法对于初学者来说非常不友好，这篇文件将会介绍基本的nmap命令，不会面面俱到，只希望你对nmap有一个基本的了解，不在惧怕nmap命令。&#xA;nmap能做什么？ nmap使用IP包的方式发送数据，他能找到局域网内有那些机器在运行那些服务，他们分别是什么操作系统，端口是否开放，机器启动时间等等。&#xA;一下问题，使用nmap能够轻易的解决。&#xA;局域网内有那些机器在运行 局域网内有那些IP地址 某个IP所指向的机器运行着什么操作系统 你能扫描目标机器上有那些端口开放着 了解目标机器是否感染了病毒 搜索当前网络中有那些未认证的网络服务 查找安全级别较低的机器 如何安装nmap呢？ 如果你是debian操作系统&#xA;sudo apt install nmap 参考文章：&#xA;https://www.cyberciti.biz/faq/install-nmap-debian-ubuntu-server-desktop-system/ https://www.cyberciti.biz/faq/howto-install-nmap-on-centos-rhel-redhat-enterprise-linux/ https://www.cyberciti.biz/faq/installing-nmap-network-port-scanner-under-openbsd-using-pkg_add/ 扫描单个目标 # 扫描单个目标机器 nmap 192.168.1.1 # 扫描单个域名 nmap gitlab.hellojukay.cn 扫描多个目标或者是子网 nmap 192.168.1.1 182.168.1.2 nmap 192.168.1.1,2,3 你也可以扫描某个范围内的IP地址&#xA;nmap 192.168.1.1-20 你也可以使用通配符&#xA;nmap 192.168.1.* 你也可以扫描整个子网&#xA;nmap 192.168.1.0/24 从文件中读取扫描目标 使用-iL选项来读取你需要扫描的目标机器列表，这通常使用来扫描一大批机器，文件编写语法如下：&#xA;gitlab.hellojukay.cn 192.168.1.1 192.168.1.0/24 localhost 命令行语法：&#xA;nmap -iL hosts.txt 过滤目标 当你扫描一大批机器的时候，你想过滤掉某个目标，不进行网络扫描，你可以使用--exlude选项来跳过目标&#xA;nmap 192.168.1.0/24 --exclude 192.168.1.5 nmap 192.168.1.0/24 --exclude 192.168.1.5 192.168.1.6 扫描机器的系统和网络版本信息 nmap -A 192.168.1.254 nmap -v -A 192.</description>
    </item>
    <item>
      <title>使用Docker来管理golang的编译依赖</title>
      <link>http://localhost:1313/posts/2018/20181201/</link>
      <pubDate>Sat, 01 Dec 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20181201/</guid>
      <description>golang开发在依赖管理一直不太方便，主要有一下问题：&#xA;golang.org包下载不方便 如果不提前下载好所有依赖，glide install速度慢 golang.org被墙的问题可以通过设置glide 的mirror来解决，glide install下载慢的问题也可以通过提前下的来解决。但是,但是服务器上进行CI就不方便，如果需要每次都重新下载依赖，显然编译速度慢，导致集成速度慢，这不是我想要的。&#xA;我们的所有的golang项目都是在golang的容器里面编译，所以，我们可以通过这里来下手，尽可能的降我们会用到的依赖安装在容器的GOPATH中，这样glide在安装依赖的不需要从github重新下载代码了，国内网络连接github还是挺慢的，这样做能节约不少构建时间, 还有一个好处就是如果是用的github上的某个包，被作者删除了，也不会影响你的正常编译。&#xA;FROM golang RUN apt-get update &amp;amp;&amp;amp; apt-get -y upgrade RUN apt-get install -y ca-certificates git build-essential &amp;amp;&amp;amp; rm -rf /var/lib/apt/lists/* RUN go get -u github.com/Masterminds/glide RUN go get -u github.com/jstemmer/go-junit-report RUN go get -u github.com/go-bindata/go-bindata/... RUN go get -u github.com/golang/dep/cmd/dep RUN go get -u golang.org/x/crypto RUN go get -u golang.org/x/net RUN go get -u golang.org/x/tools RUN go get -u golang.org/x/text RUN go get -u golang.</description>
    </item>
    <item>
      <title>Docker开发最佳实践</title>
      <link>http://localhost:1313/posts/2018/20181129/</link>
      <pubDate>Thu, 29 Nov 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20181129/</guid>
      <description>这里有一些关于在Docker使用中一些使用的小技巧,如果你还有其他技巧，欢迎你如我分享受。&#xA;控制镜像的体积 小的镜像能够加快Docker pull的速度也能够更快的被加载到内容中，容器服务器能够更快的启动起来。但是要保证容器体积小，你需要注意如下事项:&#xA;使用一个精简的基础镜像，比如：如果你要使用jdk，那么请你使用openjdk的镜像，而不是在ubuntu的镜像上安装jdk。 使用多步骤编译镜像。例如，你可以使用maven的镜像来编译你的java项目，让后讲java项目的jar包产物copy到tomcat镜像中，这也就以为你最终的镜像中不包含编译期间的以来，比如maven等。 如果你使用Docker版本没有多步骤编译功能，那么你请减少容器的层数，也就是RUN执行的数量，每一条RUN指令都会产生一个新的层。考虑如下指令: RUN apt-get -y update RUN apt-get install -y python 替换成如下指令，镜像体积会更小:&#xA;RUN apt-get -y update &amp;amp;&amp;amp; apt-get install -y python 如果你有多步骤编译，那么请可以使用一个基本的基础镜像，其他的镜像在加载的时候也会加载这些公共的层，并且会被换成起来，只加载一次，也就是说会提交加载的效率。 为了让你的镜像能够调试，请在镜像中加入一些必要的调试工具。 在镜像编译成功以后，一定要给镜像添加必要的tag，比如:prod,test等，务必不要使用自动生成的latest tag。 如何数据持久化 避免在容器的可写入层使用driver的方式来持久化文件，这会增加容器的大小，他比挂在目录和容器卷效率更加低。 使用容器卷来持久化数据。 使用service来保存敏感数据，使用配置来保存不敏感的数据。 Docker在开发环境和生成环境的差异 在开发环境使用文件挂在的方式，在生产环境使用容器卷挂在的方式 在开发环境使用Docker for mac 或者Docker for Windwows ,但是生产环境使用Docker EE </description>
    </item>
    <item>
      <title>【翻译】JVM虚拟机参数介绍</title>
      <link>http://localhost:1313/posts/2018/20181126/</link>
      <pubDate>Mon, 26 Nov 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20181126/</guid>
      <description>在这篇文章中将会介绍常用的JVM参数配置，以及每个参数的含义。&#xA;配置堆内存 每一JVM应用程序都有一个非常重要的配置，堆内存的配置，它影响这应用程序执行的性能。我们可以给程序配置一个最小的启动内存和最大占用内存的限制。就如下：&#xA;-Xms&amp;lt;heap size&amp;gt;[unit] -Xmx&amp;lt;heap size&amp;gt;[unit] 这里的单位是内存初始化的单位支持g,m,k.g也就是GB，m也就是MB,k也就是KB。例如，我们可以设置最小启动内存为2GB，最大堆内存为5Gb，启动时候添加参数如下：&#xA;-Xms2G -Xmx5G 在Java 8 中MetaSpace的大没有设置，如果它打包了全局配置的最大值，JVM回去自动增涨它。如果要克服这个不稳定的问题，我们需要设置:&#xA;-XX:MaxMetaspaceSize=&amp;lt;metaspace size&amp;gt;[unit] 这里MetaspaceSize表示我们配置给MetaSpace区的内存大小。在JVM设置中，内存第二个重要的地方是这是JVM年轻代gc的限制大小，默认gc的最小大小是1310MB，最大值则没有限制，设置方法如下:&#xA;-XX:NewSize=&amp;lt;young size&amp;gt;[unit] -XX:MaxNewSize=&amp;lt;young size&amp;gt;[unit] 垃圾回收 为了有一个更加稳定的服务，选择一个合适的垃圾回收算法非常重要。JVM有许多种垃圾回收算法:&#xA;Serial Garbage Collector Parallel Garbage Collector CMS Garbage Collector G1 Garbage Collector 选择哪一种实现，可以使用如下方式指定: -XX:+UseSerialGC -XX:+UseParallelGC -XX:+USeParNewGC -XX:+UseG1GC 更多关于垃圾回收的介绍请查看https://www.baeldung.com/jvm-garbage-collectors。&#xA;GC日志 为了监控应用的监控情况，我们必须检查JVM的GC情况，最简单的方式将GC日志输出为便于阅读的形式,如何配置能够打印GC日志：&#xA;-XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=&amp;lt; number of log files &amp;gt; -XX:GCLogFileSize=&amp;lt; file size &amp;gt;[ unit ] -Xloggc:/path/to/gc.log UseGCLogFileRotation指定了GC日志文件创建策略，就想log4j,sl4j一样。NumberOfGCLogFiles指定的是单个JVM应用在其生命周期中最多能创建GC日志文件的数量。GCLogFileSize指定GC日志单个文件体积最大值,loggc指定了日子文件的路径。&#xA;要说明的是，这里还有个JVM关于GC日志的参数，他们控制日志打印的时间，分别是：XX:+PrintGCTimeStamps和XX:+PrintGCDateStamps。&#xA;例如：我们要定义,GC日志数量最多100个文件，单个文件的最大体积是50M,日志打印的路径是/home/user/log,我们可以使用如下的配置:&#xA;-XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=50M -Xloggc:/home/user/log/gc.log 控JVM GC是需要一个单独的线程在后台执行的，他会消耗一部分的性能，这个是你要注意的地方。&#xA;处理内存溢出问题 一个非常大的问题是：JVM应用程序都会面临着内存溢出的问题，导致程序中途crash，这样的问题非常难以复现，以至于很难去找到问题的原因。&#xA;JVM提供了一些参数，保证程序在内存溢出的时候能够将当前的堆信息保存在磁盘上，以至于你事后能更具这个快照信息找到问题根源：&#xA;-XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=./java_pid&amp;lt;pid&amp;gt;.hprof -XX:OnOutOfMemoryError=&amp;#34;&amp;lt; cmd args &amp;gt;;&amp;lt; cmd args &amp;gt;&amp;#34; -XX:+UseGCOverheadLimit HeapDumpOnOutOfMemoryError表示dump堆信息到磁盘，HeapDumpPath是这只dump文件的文件路径和文件名，可以是任意的文件名，如果文件名中包含&amp;lt;pid&amp;gt;，会被替换成JVM应用的pid。OnOutOfMemoryError是在发送内存溢出的时候执行的命令，例如：我想在内存溢出的时候重启服务器。</description>
    </item>
    <item>
      <title>【翻译】基本的Linux排查问题的技巧</title>
      <link>http://localhost:1313/posts/2018/20181124/</link>
      <pubDate>Sat, 24 Nov 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20181124/</guid>
      <description>硬件相关 获取内存信息 cat /proc/meninfo 如果你只是想看一下内存的大小，你可以这样：&#xA;cat /proc/meminfo | head -n 1 一些其他有意思的操作，下面这条命令你能看到内存中纯文本信息:&#xA;sudo dd if=/dev/mem | cat | strings 同样的，使用strings命令你也能够查看二进制程序中的字符串常量。&#xA;获取CPU信息 一些时候你想要知道是什么进程占用了CPU，是你的应用程序还是操作系统，你可以使用如下两条命令:&#xA;cat /proc/cupinfo top top有一个升级版本htop，他显示更加友好:&#xA;htop 获取CPU当前温度信息:&#xA;cat /proc/acpi/thermal_zone/THRM/temperature 列出外部设备以及USB信息 lspci `` 对于USB信息: ```shell lsusb 检查硬盘使用情况 df -h 检查硬盘挂载情况 sudo fdisk -l 安装应用程序 有时候你需要查看一下当前系统上安装的所有的包，你能发现为甚会安装他，那些包在依赖这些包&#xA;dpkg --get-selections | less 检查所有已经安装的包，对于yum来说是&#xA;sudo yum list --installed 查看安装原因:&#xA;aptitude why packagename 找出包中存储的文件:&#xA;dpkg -L packagename dpkg这个命令怎么记呢: debian package的缩写。&#xA;关闭进程 ps -A | grep Prograname kill 7207 其他杂项 显示所有的网络链接 Linux上有非常多的好用的功能能查看网络情况，netstat就是其中最简单易用的一个。</description>
    </item>
    <item>
      <title>【翻译】OpenSSH Client 配置指南</title>
      <link>http://localhost:1313/posts/2018/20181122/</link>
      <pubDate>Thu, 22 Nov 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20181122/</guid>
      <description>一个局部或者全局的ssh配置能够加速你通过访问ssh server的速度，能够为你的ssh client定制快捷登录方式。让我们来一起看一下openssh的配置例子吧。&#xA;系统级别的openssh client配置 1.0 /etc/ssh/ssh_config: 这个文件是ssh client连接ssh server使用的配置，做个文件的权限必须是所有用户都能读取的。&#xA;用户级别的ssh client配置 1.0 $HOME/.ssh/config: 这个是对当前用户有效的ssh client的配置，它能够覆盖全局的ssh client配置。&#xA;~/.ssh/config规则 此文件配置规则如下：&#xA;每一行一条配置信息，分别对应的是配置项的名字和对应的值，语法如下: config value config1 value1 value2 你也可以使用等于号来替代上面的空格 config=value config1=value1 value2 空行会被忽略 #符号开头的行会被忽略 配置项参数名字不区分大小写，但是配置项的值严格区分大小写 一个小技巧：如果你从来没有使用过ssh命令，没有生成~/.ssh文件夹，你可以使用命令手动创建他,mkdir -p $HOME/.ssh &amp;amp;&amp;amp; chmod 0700 $HOME/.ssh&#xA;例子 我们接下来的例子配置如下：&#xA;本地客户端是MAC OSX或者ubunutu linux 远程服务端是unix-OpenBSD或者其他运行最新版本OpenSSH server的服务器 远程的OpenSSH server的地址是: 75.126.153.206 远程的OpenSSH server的端口是: 4242 本地私钥文件的地址是: /nfs/shared/users/nixcraft/keys/server1/id_rsa 基于以上条件，我们的ssh登录命令如下:&#xA;ssh -i /nfs/shared/users/nixcraft/keys/server1/id_rsa -p 4242 nixcraft@server1.cyberciti.biz 或者是&#xA;ssh -i /nfs/shared/users/nixcraft/keys/server1/id_rsa -p 4242 -l nixcraft server1.cyberciti.biz 每次登录都要敲这么长的命令，是无法接受的。</description>
    </item>
    <item>
      <title>环境变量中能写脚本吗</title>
      <link>http://localhost:1313/posts/2018/20181121/</link>
      <pubDate>Wed, 21 Nov 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20181121/</guid>
      <description>今天早上回顾了昨天写的一篇文章,无意中发现我在环境变量中写入脚本，一下子有了疑问：环境变量中也能写脚本吗？那么不是说通过环境变量也能删库跑路。&#xA;使用golang写个简单的例子试试:&#xA;package main import &amp;#34;fmt&amp;#34; import &amp;#34;os&amp;#34; func main() { var foo = os.Getenv(&amp;#34;foo&amp;#34;) fmt.Println(foo) } go build main.go jukay@~/Code/Golang/env$ env foo=&amp;#34;$(echo Hello World)&amp;#34; ./main Hello World 输出foo环境变量的值是Hello World。&#xA;jukay@~/Code/Golang/env$ env foo=&amp;#34;$(echo $GOPATH)&amp;#34; ./main /Users/jukay/Code/Go 环境变量中写脚本使用另一个环境变量&#xA;jukay@~/Code/Golang/env$ touch bar.txt jukay@~/Code/Golang/env$ ls bar.txt main main.go jukay@~/Code/Golang/env$ env foo=&amp;#34;$(rm bar.txt)&amp;#34; ./main jukay@~/Code/Golang/env$ ls main main.go 可以删除文件&#xA;jukay@~/Code/Golang/env$ cat bar.sh #!/usr/bin/env bash echo Hello World jukay@~/Code/Golang/env$ env foo=&amp;#34;$(sh bar.sh)&amp;#34; ./main Hello World 在环境变量中能够启动另一个脚本</description>
    </item>
    <item>
      <title>【翻译】理解容器中的uid和gid的工作方式</title>
      <link>http://localhost:1313/posts/2018/20181116/</link>
      <pubDate>Fri, 16 Nov 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20181116/</guid>
      <description>理解容器和宿主机之间的uid和gid是如何映射的，这对于容器安全运维非常重要。如果不加选项，容器中的进程是默认使用root用户运行，除非在Dockerfile中有指定为其他用户。这篇文章将会想你uid和gid在容器是如何工作的，并且会想你详细展示过程。&#xA;一步一步分析uid和gid 首先，我们来回顾下uid和gid在内核中是如何被实现的，内核通过uid和gui来判断当前系统调用是否有权限。例如：当一个试图向某个文件中写入文件的时候，内行会检查当程序的uid和gid，并且判断是否权限修改这个文件，检查权限的时候是不区分用户名的。&#xA;当一个容器运行在服务器上的时候，事实上这个容器中的进程和宿主机器共用一个系统内核。容器化带来的巨大好处是，在分割了进程的同时公用一个内核。这也就意味着，运行在容器中的进程，他们进程的uid和gid被同一个内核管理。&#xA;你不能在不同的容器中使用不同的用户名但是用着相同的uid。因为系统中显示用户名和组名的工具不属于系统内核，他们被外部的/etc/passwd,LDAP等工具管理者，所以你能看到不同的用户名和组名，但是他们不会有相同的uid和gid，在不同的容器中。接下来让我用一些小例子来解释。&#xA;简单的Docker run 接下我将使用marc这个用户名，这个用户名已经事先加入到了doker group中了,不需要使用sudo就能启动一个容器了，在容器之外我们能看到如下信息:&#xA;marc@server:~$ docker run -d ubuntu:latest sleep infinity 92c57a8a4eda60678f049b906f99053cbe3bf68a7261f118e411dee173484d10 marc@server:~$ ps aux | grep sleep root 15638 0.1 0.0 4380 808 ? Ss 19:49 0:00 sleep infinity 非要有意思，虽然我没有使用sudo，我当前用户也不是root用户，但是sleepe这个进程却拥有root权限。我是如何如何发现他有root权限的能？容器内的root和容器外的root是等价的吗？是的，因为他们是允许在同一系统内核上的，sleep在容器外展示的用户名是root，所以能断定容器的uid=0。&#xA;Dockerfile定义一个用户 当我在Dockerfile中设置一个用户，并且使用这个用户启动容器，会发生什么呢？为了简化这个例子，我当前也不是一个特殊的gid，我使用marc这个用户来运行命令，当前的uid=1001。&#xA;marc@server:~$ echo $UID 1001 编写Dockerfile&#xA;FROM ubuntu:latest RUN useradd -r -u 1001 -g appuser appuser USER appuser ENTRYPOINT [“sleep”, “infinity”] 接下来构建运行这个容器:&#xA;marc@server:~$ docker build -t test . Sending build context to Docker daemon 14.</description>
    </item>
    <item>
      <title>docker容器健康状态检查</title>
      <link>http://localhost:1313/posts/2018/20181115/</link>
      <pubDate>Thu, 15 Nov 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20181115/</guid>
      <description>为什么要监控容器的健康状态 在docker早期，要检查容器的健康状态，只能通过容器内的进程的退出状态，如果进程退出了并且返回了非0的状态，那么docker就认为这个容器是不健康的。但是某些容器，虽然已经退出，但是内部已经死锁了，程序阻塞，已经无法完整正常的功能了，这个时候程序实际上已经是不正常的状态了。但是，这种情况在早期是无法被检查出来的，所以请求还是会分配给这个容器。在1.12版本以后加入了HEALTHCHECK指令，允许在编写Dockerfile的时候设置一个检查将康状态的指令，如果指令返回0，则说说明容器是监看的，反之，容器连续返回非0，则说明容器不监看。&#xA;怎么监控容器的健康状态 监控容器的健康状态,有三种设置方式：&#xA;在Dockerfile中用HEALTHCHECK指令设置检查方式 在docker run命令使用--health-cmd等选项 在docker compose的配置文件中使用healthcheck指令 我们大部分时候都是在Dockerfile中指定HEALTHCHECK [option] CMD [command],当然，如果想要取消基础镜像中的health check，使用HEALTHCHECK NONE配置即可。 对于web服务，我们通常使用curl来检查容器的健康，例如：&#xA;FROM alpine:3.7 ADD web /bin/ RUN echo &amp;#34;http://mirrors.aliyun.com/alpine/v3.7/main/&amp;#34; &amp;gt; /etc/apk/repositories RUN apk update &amp;amp;&amp;amp; apk add curl HEALTHCHECK --interval=5s --timeout=3s CMD curl --fail http://localhost:8080/ping || exit 1 CMD /bin/web version: &amp;#39;3&amp;#39; services: web: image: web container_name: web ports: - 8080:8080 healthcheck: test: [&amp;#34;CMD&amp;#34;,&amp;#34;curl&amp;#34;,&amp;#34;--fail&amp;#34;,&amp;#34; http://localhost:8080/ping&amp;#34;] interval: 5s timeout: 4s retries: 60 当然,docker compose中的健康检查配置会负责dockerfile中的默认配置。&#xA;有什么需要注意的地方 看着上面的配置，有一个需要注意的地方，比如：你是使用curl检查容器的时候，需要考虑该容器中是否安装了curl依赖，如果没有，需要自己手动安装。有一个更加复杂的容器可能还需你自己编写检查工具来检查容器的监控状态。</description>
    </item>
    <item>
      <title>【翻译】使用git工作的5个技巧</title>
      <link>http://localhost:1313/posts/2018/20181114/</link>
      <pubDate>Wed, 14 Nov 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20181114/</guid>
      <description>在过去的一段日子里，你使用着相同的git命令，你时候想过改善既有流程，增加一些其他的技巧或者说小把戏。&#xA;git rebase 工作流 当你完成了一个本地feature分支功能开发，是时候提交你的代码变更到master分支了(我认为不能直接合并到master分支，他应该经过其他分支进行流水线测试)。这个时候，你也许会使用merge的方法来合并你的代码，而不是rebase,想了解merge和rebase之间的去表，可以看这里https://www.atlassian.com/git/tutorials/merging-vs-rebasing。 我过去也在我的团队中使用merge来合并我的代码到master分支，这通常不会有什么问题。一个聪明的开发人员告诉一个非常好的git工作流程，他是在代码提交到master分支的时候，将merge和rebase结合起来，使我的工作流程发生了巨大的变化,通过下面的描述我介绍这个工作流程。&#xA;checkout master git checkout master 保证master是最新的代码 git pull rebase master git rebase master 如果遇到和合并问题，请示使用merge工具 git mergetool `` * 修复合并问题 * 继续使用git rebase ```shell git rebase --continue 如果还遇到了问题，重复上面的合并步骤 如果合并除了，终止当前合并，并且丢弃变更 git rebase --abort 如果合并完成，将变更推送到远程分支 git push -f git add -p 当你在本地分支上工作的时候，你是否有想要提交的变更，但是你没有提交变更，使用git add -p命令即可。在我了解这个命令之前，我是完全丢弃掉我不想要的的提交变成git checkout -src / etc,然后一次体骄傲所有变更git commit -A,想起来还真是浪费时间。&#xA;保持分支干净 使用简洁的分支命名，一些时候当我从一个简单分支切换到要给命名复杂的分支的时候，我不禁会想，我怎么会给分支定义了一个如此愚蠢的名字，但是一想到这个分支已经在服务器上存在了。 这里有一个命令用来修改本地分支的名字，非常有效。&#xA;git branch -m odlname newname 重命令当前分支:&#xA;git branch -m newname 是不是非常简单。如果一个分支已经合并了，那么你就应该在本地删除它,删除掉本地的旧的分支。&#xA;git branch -d branchname git reset-hard 当你想要放弃某些变更，重新来过的时候，你可以使用git reset --hard,时候的时候你必须小心，你要知道你正在做什么。 </description>
    </item>
    <item>
      <title>【翻译】谷歌shell编程规范</title>
      <link>http://localhost:1313/posts/2018/20181113/</link>
      <pubDate>Tue, 13 Nov 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20181113/</guid>
      <description>使用哪一种shell解释器。 bash应该是一唯一使用的脚本解释器，除此之外，你不应该使用其他的解释器的特性,除非你真的需要，或者是条件限制。确保你的脚本在移植到其他机器上也能够正常执行。bash脚本应该都包含一个shanbang,#!/bin/bash。&#xA;什么时候应该是shell。 shell只应该被用来做一些很小的工具，或者是一些脚本的包装。 虽然shell不知一个正规的编程语言，但是google内部还是有很多地方在使用它。为了避免滥用，你应该准守如下规则:&#xA;如果只是调用一些其他的工具，或者只是简单的处理输出，可以使用shell。 如果你在意执行速度，那么不要使用shell,使用其他语言。 如果你发现除了使用常规变量之外，你还需要使用数组，就像${PIPESTATUS},那么你应该使用python。 如果你发现你的脚本长度超过了100行代码，那么你应该使用python来重写他，随着代码长度的增加，你应该尽快重构你的代码。 应该使用哪种后缀名。 我们强烈的建议你不要使用后缀名或者使用.sh作为后缀名。如果是最为依赖库，那么应该用.sh作为后缀名，并且不应该有执行权限。当我们执行一个脚本的时候，不需要知道他是哪种语言编写，并且shell也并没有shell也没有要求使用后缀名。然而，作为库代码，应该表明是使用哪种语言编写的，应该使用后缀来表明他的实现语言，比如.bash。&#xA;SUID和SGID。 shell脚本禁止使用SUID和SGID功能。 因为有太多的安全事故，所以必须禁止shell使用SUID和SGID,虽然在大部分平台上是难以开启这项功能的，但是某些平台上还是可以的，所以必须要禁止他，如果要获取权限，应该使用sudo。&#xA;标准输出与标准错误输出。 所有的错误都应该被打印到标准错误输出stderr,这样更加方便正常信息和错误信息。建议使用一个单独的函数来输出错误信息:&#xA;err() { echo &amp;#34;[$(date +&amp;#39;%Y-%m-%dT%H:%M:%S%z&amp;#39;)]: $@&amp;#34; &amp;gt;&amp;amp;2 } if ! do_something; then err &amp;#34;Unable to do_something&amp;#34; exit &amp;#34;${E_DID_NOTHING}&amp;#34; fi 文件头。 每个脚本的开头都必须有一段注释来描述这个脚本的内容。&#xA;函数注释。 不管函数的长度是多少，都应该添加注释。对于所有的库函数，都应该有注释描述。任何在使用库函数的时候，都应该能够通过注释的描述来使用这个库函数，或者是使用函数提供的--help选项（如果提供了的话）。函数的注释应该包含如下信息:&#xA;函数的描述 全局变量的使用和修改 函数的参数说明 函数的返回值和退出状态说明 例如： #!/bin/bash # # Perform hot backups of Oracle databases. export PATH=&amp;#39;/usr/xpg4/bin:/usr/bin:/opt/csw/bin:/opt/goog/bin&amp;#39; ####################################### # Cleanup files from the backup dir # Globals: # BACKUP_DIR # ORACLE_SID # Arguments: # None # Returns: # None ####################################### cleanup() { .</description>
    </item>
    <item>
      <title>有那些相见恨晚的Linux命令</title>
      <link>http://localhost:1313/posts/2018/20181112/</link>
      <pubDate>Mon, 12 Nov 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20181112/</guid>
      <description>在reddit上看到一个热门帖子，内容是：一人给一个你相见恨晚的Linux命令。&#xA;disown 这是一个bash内置命令，如果你需要将当前程序在后台运行的时候，有两个方式，1.让当前程序在新的session中运行。2.程序内部处理SIGUP信号，nohup就只这种工作方式。disown这个命令也能达到相同的功能。更多内容参考: https://www.ibm.com/developerworks/cn/linux/l-cn-nohup/&#xA;touch log gdb -p 22499 (gdb) p close(1) # This closes the stdout of the running process (gdb) p open(&amp;#34;/home/.../log&amp;#34;, 1) # This will open the log-file with O_WRITE (gdb) c 这是一种非常hack的方式来将一个已经正在运行的程序的标准输出重定向到文件。更多内容参考: https://github.com/nelhage/reptyr&#xA;cat ~/.ssh/id_dsa.pub | ssh me@remotebox &amp;#34;cat &amp;gt;&amp;gt; ~/.ssh/authorized_keys&amp;#34; 通过ssh连接跨机器使用管道符,这也是比较hack的一种方式。顺便说一句，scp也是使用的ssh协议，所以在使用scp的时候，如果你配置了秘钥，那么scp是可以使用tab键来进行补全提示的。&#xA;fc fc命令能够将上一次执行的命令在编辑器中打开,这个默认的编辑器可以使EDITOR环境变量来设置。&#xA;lsof lsof能够列出当前操作系统打开的所有文件描述符，包括socket,文件等等,与之类似还有一个fuser命令。&#xA;CTRL + L 这是一个快捷键，和clear的功能一样能够快速清空当前的terminal,bash还有很多快捷键，请参考： https://blog.hellojukay.cn/2018/05/23/20180523/。&#xA;man ascii 在mac上下能够按照是十六进制的方式处处ascii码表，很多从事嵌入式开发的程序使用这个小技巧，同样的ascii -x也能实现这个功能.&#xA;xargs 能够将上一个程序的标准输出传给下一个程序的命令行，我最喜欢的功能是:echo xx | xargs -I {} command {}。&#xA;convert convert命令能够进行图片格式转换。</description>
    </item>
    <item>
      <title>关于日志的思考</title>
      <link>http://localhost:1313/posts/2018/20181111/</link>
      <pubDate>Sun, 11 Nov 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20181111/</guid>
      <description>关于打印日志，其实有很多讲究，好的日志让人一目了然，能够得到非常多的有用信息，也能帮助运维人员找到问题。那么这篇文章尝试对日志打印做一些总结。&#xA;为什么需要有日志 在打印日志之前，我们一定要先明确输出日志的目的，我们的日志是给谁看的，日志需要包含什么信息。日志一方面是给人看的，另一方面也是给程序分析的。站在系统运维人员的角度来看，我们希望从日志能够得知程序的监控状态，当程序&amp;quot;假死&amp;quot;的时候，如果有输出日志，我们知道程序在后台计算中，如果没有日志输出，可能会被误认为是程序奔溃了，导致程序被强制退出。系统出错了，我们希望能够看到错误原因，比如获保存数据事变，日志应该提供对应的诊断信息：没有可用存储空间，文件权限不够等等。总的说来，我们打印日志的目的可以归纳为以下几点：&#xA;体现程序状态 记录操作历史 展示调试诊断信息 统计操作行为 日志级别 日志级别非常重要，因为不同的日志级别，输出的日志内容不一样，低级别的日志会输出太多的诊断信息，同时也会增加系统的io压力，日志文件占用大量的磁盘空间。尽量不要在生产环境使用debug,trace这样的日志级别，输出了太多的无用信息，增加了系统的负担。生产环境的日志级别推荐使用info,warn级别日志输出。测试环境应该使用debug或者trace级别，它能发下许多系统问题。你不应该忽视warn级别的日志，除非你真的知道了发生了什么。&#xA;日志内容 日志应该包那些内容呢&#xA;info 级别的日志应该展示的是系统行为或者用户行为 error 级别的日志应该是在程序发生错误的时候输出，它一定要包含错误的上下文信息 debug 级别应该包含系统行为和用户行为的详细信息，最好是是运维发现程序不正常，打开debug日志能够发现问题所在，他应该是级别的开发人员，或者系统运维人员看的。 trace 级别的日志应该是所有的日志信息，包含应用本身，以及依赖框架或者依赖库本身的诊断信息，如果是http请求，那么他应该尽可能的包含一个完整的请求的所有信息。 日志信息安全 因为系统开发人员无法决定系统会被部署在怎样的环境，也不能确系统日志会被那些人员看到：也许是一个hacker，也许是另一个工程师。所以为了安全，日志里面不应该包含了用户密码，银行卡账号等非常隐私的信息，任何级别的日志都应该遵守这个约定，因为开发人员也无法确定系统会以怎么的日志级别被部署。&#xA;日志内容结构 文章开头部署我们就介绍过了，我们的日志是给人和程序看的，给人看的日志很简单，只要语义明确即可。但是，这样的日志往往利于程序分析，所以我们在输出日志的时候，必须要要求日志有规律，有格式，便于程序解析分析。比如说：json格式。&#xA;日志文件特性 我们的日志会被程序检索，被人打开阅读，所以单个日志的文件最好不要太多，大文件对于编辑器打开阅读来说非常不要。日志应该按照日志或者按照文件大小来进行分割。一直文件应该能够直观的体现日期，当我要查找的日志的时候，我一眼就明白应该从那个日志文件里面寻找，而不是翻遍所有的人日志的文件。日志文件最好也应该区分日志级别，比如:2018-11-10.error.log这样的日志文件，只需要打开这个日志文件，就知道这天系统发生了什么错误，发生了多少次。之前说过了日志文件会占用大量的磁盘空间，如果你想每次都手动删除日志，来保证系统有足够的磁盘空间来维持运行，那么你的日志就应该设置保存期限，过期日志自动删除，而不是堆积如山。如果你想保存更多的时间，那么你应该收集这些日志到一个有更大磁盘的空间的系统，这个系统可能是一个网络云盘之类的东西。</description>
    </item>
    <item>
      <title>【翻译】docker容器资源限制最佳</title>
      <link>http://localhost:1313/posts/2018/20181110-1/</link>
      <pubDate>Sat, 10 Nov 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20181110-1/</guid>
      <description>原文地址: https://docs.docker.com/config/containers/resource_constraints/&#xA;docker容器启动默认对容器资源占用没有做任何限制，只要宿主机器允许，容器是可以无限的占用系统资源。docker提供了一种限制容器占用内存，CPUd等资源的途径，通过在docker run启动容器的时候传递特定的限制参数。建议你在使用容器的时候，尽可能的配置这些参数来限制容器资源占用。&#xA;docker限制资源的功能需要系统内核的支持，使用docker info来检查你的内核版本时候支持这些特性，命令行输出了警告信息，那么说明当前内核不支持此项特性，例如:&#xA;WARNING: No swap limit support 查来系统配置来激活这些特性，文档地址。&#xA;内存 待填坑 </description>
    </item>
    <item>
      <title>bash脚本最佳实践</title>
      <link>http://localhost:1313/posts/2018/20181110/</link>
      <pubDate>Sat, 10 Nov 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20181110/</guid>
      <description>我经常会记录一些bash脚本的技巧，然后反复的回味他们，今天我将这些技巧记录在blog里面。&#xA;使用完整的命令选择，而是不是简写选项，当你需要反复使用这段脚本的时候，因为他们更加便于阅读和理解。&#xA;使用set -o errexit(set -e)保证你的脚本在出错的时候退出。&#xA;添加 || true 允许命令失败，或者使用|| ;。&#xA;使用set -o nounset(set -u)保证你的脚本在使用未定义变量时候自动推出。&#xA;使用set -o xtrace(set -x)来打印执行过程，输出调试信息。&#xA;#!/usr/bin/env bash比#!/bin/bash更加合适。&#xA;避免使用#!/usr/bin/env bash -e或者(set -e),因为当有人使用bash ./script.sh出错自动退出的功能会失效。&#xA;使用{}来包裹变量，否在放在访问变量的时候可能会引起歧义。&#xA;判断字符串相等的时候，不需要使用两个等于号if [ &amp;quot;name&amp;quot; = &amp;quot;hellojukay&amp;quot;] 。&#xA;使用:-，当你认为一边变量可能没有定义的时候，if [ &amp;quot;${name:-}&amp;quot; = &amp;quot;hellojukay&amp;quot; ],如果name没有定义，那么name将会被设置为空字符串，你也可以设置以其他的默认值&amp;quot;{name:-hellojukay}&amp;quot;&#xA;定义常量,当前文件名字，当前目录等在脚本的开头几行。&#xA;综上所述，你的脚本应该风格类似下面这段脚本。&#xA;#!/usr/bin/env bash # Bash3 Boilerplate. Copyright (c) 2014, kvz.io set -o errexit set -o pipefail set -o nounset # set -o xtrace # Set magic variables for current file &amp;amp; dir __dir=&amp;#34;$(cd &amp;#34;$(dirname &amp;#34;${BASH_SOURCE[0]}&amp;#34;)&amp;#34; &amp;amp;&amp;amp; pwd)&amp;#34; __file=&amp;#34;${__dir}/$(basename &amp;#34;${BASH_SOURCE[0]}&amp;#34;)&amp;#34; __base=&amp;#34;$(basename ${__file} .</description>
    </item>
    <item>
      <title>linux服务器安全最佳实践</title>
      <link>http://localhost:1313/posts/2018/20181109/</link>
      <pubDate>Fri, 09 Nov 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20181109/</guid>
      <description>在拿到一台初始化的的linux服务的第一时候，你就应该为他台服务器配置相关的安全设置。养成好的习惯，因为这可能帮你减少因为黑客攻击带来的巨额度损失。精密的配置的服务器难以攻破，会让黑可放弃攻击你的服务器。&#xA;用户管理 linux系统会默认创建第一个用户&amp;ndash;root。这个用户应该被禁止使用ssh远程登录服务器。禁止root会让黑客更难攻破你的服务器。如果黑客知道root能够登录，就相当于得到攻破服务器的一半的信息，这就为暴力破解减少一半的计算量。我们一般创建一个单独的用户来配置系统，如果需要权限，那么就使用sudo来获取root权限，而不是直接使用root账户。&#xA;密码强度设置 在你创建用户的时候，你必须确保你的密码有足够的长度和字符，这样会比较难攻破一点。&#xA;密码长度尽量在12位以上 密码尽量包含，大写字母，小写字母，数字，特殊字符 尽量使用随机密码工具来生成密码 密码不要使用连续或者重复的数字，字母 密码中不要包含个人信息 不要使用简单的单词来组合密码 添加用户(Debian 和 Ubuntu) 创建用户，设置密码 adduser {username} 如果这个用户是的主要运维用户，那么可以给他添加root权限 visudo 添加如下配置&#xA;{usernamd} ALL=(ALL:ALL) ALL 测试一些以上配置是否正确 su {username} sudo iptables -L 当你执行以上两条命令之一的时候，系统会要求你输入当前用户的密码。&#xA;创建ssh秘钥对 比密码登录更加安全的方式是使用秘钥登录，执行如下命令创建秘钥： ssh-genkey -b 4096 -t rsa 会要求你输入保存秘钥的文件，直接使用默认文件名即可，如果要更加安全，你可以给你的秘钥添加一个访问密码。创建文件了秘钥以后,```$HOME/.ssh文件夹下会生成两个文件，id_rsa和id_rsa.pub`文件。&#xA;在你生成好了秘钥以后，你需要将之前生成的公钥上传到你的远程服务器上 务必要注意，是上传公钥到服务器上，而不是上传私钥到服务器上.&#xA;ssh-copy-id -i ~/.ssh/id_rsa.pub {username}@{remotePublicIPAddress} 这行命令会提示你输入密码，在输入密码结束以后，你可以尝试ssh {username}@{remotePublicIPAddress}来登录服务器，如果一切正常，系统将不会要求你输入密码。&#xA;ssh服务端配置 现在你已经禁止了root登录，并且创建了运维专用的账号，你可以配置ssh daemon来提高服务器的安全系数了。&#xA;在你更改ssh daemon的配置的时候，你务必要确认更改配置之后你还能访问服务器，最好的是提前通知系统管理员。&#xA;ssh 配置项 这里将会介绍一些常用的ssh相关安全配置，如果你想要更加详细的说明，推荐你查阅openssh的官方文档&#xA;这一小节将包含如下信息:&#xA;Port xxx ssh默认端口配置（默认22端口） PubkeyAuthentication 允许或者禁止秘钥登录服务器 PasswordAuthentication 允许或者禁止密码登录服务器 众所周知，ssh 默认监听22端口，所以黑客都会尝试使用用户和密码爆破22端口，因为这个原因，所以你应该修改ssh服务的端口号。修改端口号不会保证服务器绝对安全，但是能够抵御所有对22端口的攻击。&#xA;登录服务器有两种方法，一种是密码的登录，另一种是秘钥登录，秘钥是成对生成，他们只能结合使用，私钥被存储在你本地的计算机上，为了保证安全，你的私钥永远都不因该改分享给他人，公钥存储你的远程服务器上。&#xA;修改sshd_config 上面说过，你应该禁止root登录，创建运维账户，为运维账户添加sudo权限，修改ssh的端口号，禁止密码登录服务器。下面我将演示如何配置：&#xA;打开openssh的配置文件 sudo vi /etc/ssh/sshd_config 更改以下几行的默认值 Port 22 &amp;gt; Port 9001 PermitRootLogin yes &amp;gt; PermitRootLogin no PasswordAuthentication yes &amp;gt; PasswordAuthentication no 把9001改成你想设置的端口号。 3.</description>
    </item>
    <item>
      <title>【翻译】Docker应用数据存储</title>
      <link>http://localhost:1313/posts/2018/20181107/</link>
      <pubDate>Wed, 07 Nov 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20181107/</guid>
      <description>容器内应用创建的数据默认在是容器内部的临时可写入层，这意味着一下问题：&#xA;当成容器不在不在运行状态时候，这部分数据不会持久化，数据会被丢失。也不方便和其他容器共享数据。 数据被写入到容器的临时可写入层，这导致数据迁移困难。 数据写入容器临时读写层，这需要操作系统内核提供数据写入驱动，这个额外的抽象，会牺牲一部分写入的性能。 数据保存在宿主机上，意味着你不需要担心容器生命周期结束以后数据会丢失，他会一直保存在宿主的磁盘上。对于在宿主机上存储文件，Docker提供能了两种方式。这两种方式分别是，挂载文件夹和挂载数据卷，当然你在Linux上运行Docker的时候，你也可以使用tmpfs挂载节点。&#xA;选择正确的挂载方式 无论你使用哪种挂载方式，被挂载的文件在容器中表现形式就好像他们正在存在容器中一样，在容器表现出来的形式为文件夹或者是文件。&#xA;用一张图来说说明上面介绍到的三种挂载方式之间的区别 容器卷: 数据存在宿主机上的一个特定目录(在Linux上: /var/lib/docker/volumes/),除了Docker自身进程，其他的进程不应该修改这个目录。挂载数据卷也是目前容器存储数据的最佳方式。 挂载目录: 能够保存在宿主机的任何目录，可能保存在一个非常重要的目录中，任何时候这个目录能够其他任何进程读写和修改。 tmpfs： 只会讲数据保存在宿主机的内存中,永远不会将数据保存宿主的磁盘上。 几种挂载方式的详细说明 容器卷：由Docker创建并且管理，你也可以手动使用docker volume create命令创建一个容器卷,或者是在服务启动的时候自动创建。 当你创建好了容器卷以后，就会在宿主机上创建某个目录，这个目录有Docker进程来管理，你可以将这个容器卷挂载到容器中，这有点类似于文件挂载的方式，只不过这个目录是由Docker管理，并且与宿主机器上的其他服务隔绝开来。&#xA;当你挂载一个容器的时候，这个容器可能是有名字的，也可能是匿名的，匿名的容器被分配了一个随机的以为的名字，匿名容器和有名字的容器在使用方式和表现形式上是一样的。 一个容器卷能够被挂载在躲着容器的内部，当应用容器都停止以后，容器卷还是存在，它不会自动删除，除非你使用docker volume prune命令来删除它。&#xA;容器卷支持给定一个容器卷驱动，他支持将数据保存在远程主机或者是云服务上。&#xA;文件挂载: 在Docker早期，文件挂载非常有用，所有宿主机上的进程都能读取这个文件。相比于挂载容器卷，文件挂载以后有一些功能上的限制。当你在使用一个被从宿主机器上挂载进来的文件以后，这个文件都是直接引用的在宿主机器上文件的绝对地址。如果文件宿主机中不存在，Docker进程会自动的创建它，文件挂载的性能不错，但是它依赖宿主上的特定文件系统以及目录存储结构。如果你正在开发一个Docker的应用，请考虑使用容器卷来替代挂载文件的方式。 文件挂载后的隐私问题，这有利有弊，它给了你更大的权利，容器中的应用能够删除，修改，读取被挂载进来的目录，这只能会影响其他的进程服务。你必须权衡利弊。&#xA;对于挂载容器卷或者挂载文件，他们的命令行都是一样的，使用--volume或者-v选项，对于tmpfs挂载稍有不同，它使用--tmpfs选项。然而在17.06 以及更新的版本里面，我们推荐使用--mount来挂载容器卷或者文件。&#xA;容器卷最佳实践 容器卷是我们推荐的容器持久化方式，在使用过程中你需要注意如下事项：&#xA;多个容器之间可以共享一个容器卷。如果在第一次挂载容器卷的时候，容器卷不存在，那么这个容器就会被自动创建，无论应用容器是否在运行或者停止，容器卷都不会被自动删除，除非你明确的手动删除他。 当时宿主机器无法提供存储空间的时候，容器卷配置会失效。 当你想存储文件在远程服务器或者云盘上时候，使用容器卷是非常好的选择。 当你需要备份，转存，迁移数据的时候，容器卷也是非常好的选择。先关闭使用这个容器卷的容器，然后在再备份容器卷的文件加，类似于（/var/lib/docker/volumes/）。 文件挂载最佳实践 如果你真的需要挂载文件，你需要注意如下事项：&#xA;容器与宿主机之间共享文件，挂载/etc/resolv.conf能够让宿主机和容器有相同的DNS配置。 挂载源代码到编译的容器中，例如，你可以挂载源码和maven的target目录到容器，这样编译后的文件其他程序也能访问到。 tmpfs最佳实践 你当你不需要持久化文件的时候你才能选择这个方案，可能是应为安全原因，你需要写入机密数据到宿主机的内存中，你可以使用这个选项。&#xA;使用容器卷和文件挂载的技巧 如果你挂载了一个空的容器卷到某个有文件的目录，那么这个目录中的文件会被拷贝中容器卷中。如果你如果你挂载某个不存在的容器卷，那么这个容器卷会被自动创建。初始化数据和容器卷的时候能够使用这样的方法。 如果你挂载了某个有数据的容器卷到某个空目录，那么容器卷的文件也会被映射到目录中。你甚至可以将/mnt挂载到容器中，容器就能读取到usb存储器上的数据。 原文地址: https://docs.docker.com/storage/</description>
    </item>
    <item>
      <title>【翻译】对docker镜像latest的误解</title>
      <link>http://localhost:1313/posts/2018/20181106/</link>
      <pubDate>Tue, 06 Nov 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20181106/</guid>
      <description>docker有一个名字叫做latest的tag，某些时候，他的工作方式可能是你想象的不一样。我也听到了很多再误解的宣传这个tag的作用。因为镜像的tag在部署的时候会经常用到，所以你必须理解tag的工作方式。&#xA;实验 为了能够说明问题，我们创建一个非常简单的Dockerfile文件&#xA;FROM busybox:ubuntu-14.04 RUN echo “#!/bin/sh\n” &amp;gt; /test.sh RUN echo “echo \”this is version 1\”” &amp;gt;&amp;gt; /test.sh ENTRYPOINT [“sh”, “/test.sh”] 为了保持简单，我们只是用一个简单的shell脚本，他输出当前的镜像版本。我们编译这个镜像&#xA;sudo docker build -t marc/test . 我们运行他&#xA;sudo docker run marc/test this is version 1 输出符合预期。接下来，我们给这个镜像打上tag&#xA;sudo docker tag marc/test marc/test:1 现在我们将这个镜像推送到DockerHub上&#xA;sudo docker push marc/test 推送成功，现在看下DockerHub上展示的图像 我们现在再编辑一下Dockerfile,这是第二个版本&#xA;FROM busybox:ubuntu-14.04 RUN echo “#!/bin/sh\n” &amp;gt; /test.sh RUN echo “echo \”this is version 2\”” &amp;gt;&amp;gt; /test.sh ENTRYPOINT [“sh”, “/test.sh”] 重复之前的过程，我们构建这个镜像，并且将它推送到DockerHub上</description>
    </item>
    <item>
      <title>CI工具介绍</title>
      <link>http://localhost:1313/posts/2018/20181105/</link>
      <pubDate>Mon, 05 Nov 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20181105/</guid>
      <description>每天都在使用Jenkins自动编译的功能，你是否了解Jenkins这个开源项目的历史，你是否还了解过其他的集成构建系统呢？这篇文章将会简单的介绍以上内容。&#xA;Jenkins的历史 2007年sun公司开启了集成构建平台Hudson项目，并且将他开源出来，因为它安装友好，配置简单，并且天然的支持java语言，所以这个项目很快的流行开来，并且打败了诸多老牌对手，成为炙手可热的的明星项目。好景不长，此时的sun公司已经不如九十年代那么辉煌，2009年，Oracle收购了sun。Oracle为Hudson申请了商标，并且开始商业化推广，社区对于Oracle的行为深恶痛绝, 因此产生了矛盾。&#xA;2011年，社区有人提议将Hudson改名为Jenkins来规避商标问题，提议很快就被采纳了，开发者在github上创建Jenkins的项目,并将代码迁移了过来，Hudson的开发者开发也慢慢往Jenkins迁移。所以现在你能够在Jenkins上看到不少Hudson的代码。Oracle宣布会继续维护项目，但是，同年失去了开发者的Hudson就被捐赠给Eclipse基金会，以此来讨好java开发者，希望能够继续吸收开源社区的养分。 事情发展到了今天，Hudson与Jenkins已经不可同日而语了，不管是社区的成熟度还是产品本身，Jenkins都遥遥领先。&#xA;其他明星工具 同样是在2011年，在德国柏林的一家公司推出一款名字叫做Travis CI的企业级集成构建服务，并且他也推出了支持github的免费社区版本。跟随github的快速发展，Travis CI也越来越受到开源社区的欢迎。到现在Travis CI与github已经是相互促进，协调发展。&#xA;为了拉拢开发者，github的敌对公司gitlab不甘示弱，迅速推出了gitlab ci。现在gitlab ci已经支持Docker,AutoDevOps等高级功能，在企业级用户中也非常受欢迎。</description>
    </item>
    <item>
      <title>前端容器化</title>
      <link>http://localhost:1313/posts/2018/20181027/</link>
      <pubDate>Sat, 27 Oct 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20181027/</guid>
      <description>这篇文章将会演示前端容器化的过程，将一个vue项目部署再docker容器中。&#xA;创建vue项目 使用vue的cli工具来创建项目&#xA;vue create vue-docker [hellojukay@localhost vue-docker]$ ls -al 总用量 480 drwxrwxr-x. 7 hellojukay hellojukay 196 10月 27 13:54 . drwxrwxr-x. 3 hellojukay hellojukay 24 10月 27 13:48 .. -rw-rw-r--. 1 hellojukay hellojukay 53 10月 27 13:48 babel.config.js drwxrwxr-x. 5 hellojukay hellojukay 75 10月 27 13:53 dist drwxrwxr-x. 8 hellojukay hellojukay 166 10月 27 13:49 .git -rw-rw-r--. 1 hellojukay hellojukay 214 10月 27 13:48 .gitignore drwxrwxr-x. 803 hellojukay hellojukay 24576 10月 27 13:50 node_modules -rw-rw-r--.</description>
    </item>
    <item>
      <title>【翻译】dockerfile最佳实践</title>
      <link>http://localhost:1313/posts/2018/20181016/</link>
      <pubDate>Tue, 16 Oct 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20181016/</guid>
      <description>此文包含官方推荐的docker镜像编译方式。dockerfile是一个包含一些列有序指令的文件，docker编译镜像的时候会自动读取dockerfile文件中的指令。docker镜像中包含一些只读的层，每一层都是对上一层的覆盖。请看如下的dockerfile&#xA;FROM ubuntu:15.04 COPY . /app RUN make /app CMD python /app/app.py 每个指令都会在原来的镜像的基础上添加一层：&#xA;FROM 在ubuntu:15.04的基础上创建一层 COPY 拷贝当前目录的文件到镜像中 RUN 使用make命令执行命令 CMD 在容器中执行的特殊程序 当启动镜像时候，会在原来的镜像上添加一个新的可以读写的层，并且生成一个容器，在容器中能对该层镜像读写，删除等。 常规指导建议 创建临时容器 dockerfile能够产生临时的容器，并且Dokerfile能够被反复编译成镜像.&#xA;理解编译的上下文 当你在执行docker build命令的时候，当我目录就是编译的上下文件，默认情况下dockerfile应该就在当前目录下，当然也可以在别的目录，通过docker build -f指定Dockefile的文件地址即可。 当执行docker build的时候，上下文(当前目录)所有文件都会被递归的发送给docker daemon进程，在dockerfile中能够使用上下文件中的文件,所以上文的大小也会影响编译时间.&#xA;创建一个空目录当前编译的上下文目录，在上下文中创建名字为hello的文件，创建dockerfile，并且在dockerfile中cat这个hello文件，然后指定编译的上下文目录为当前文件 .。&#xA;mkdir myproject &amp;amp;&amp;amp; cd myproject echo &amp;#34;hello&amp;#34; &amp;gt; hello echo -e &amp;#34;FROM busybox\nCOPY /hello /\nRUN cat /hello&amp;#34; &amp;gt; dockerfile docker build -t helloapp:v1 . 将hello文件和dockerfile分离，我们编译第二个版本的镜像，我们使用 -f来指定dockerfile文件，使用特殊的文件作为编译的上下文目录，而不是使用当前目录。&#xA;mkdir -p dockerfiles context mv dockerfile dockerfiles &amp;amp;&amp;amp; mv hello context docker build --no-cache -t helloapp:v2 -f dockerfiles/dockerfile context 不要讲不必要的文件加入到镜像，他会是增加镜像的体积，进行会增加push镜像和pull镜像的时间，同事也会增加容器运行的大小。当我们在编译dockerfile的时候，我们能够看到当前上下文件的大小:</description>
    </item>
    <item>
      <title>【行走的风景】黄岗梁</title>
      <link>http://localhost:1313/posts/2018/20181001/</link>
      <pubDate>Mon, 01 Oct 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20181001/</guid>
      <description>中秋节去了内蒙古的黄岗梁，地址是在赤峰市。一望无际的枯黄的树叶震撼到了我。 </description>
    </item>
    <item>
      <title>【摄影】关于光圈大小的思考</title>
      <link>http://localhost:1313/posts/2018/20180925/</link>
      <pubDate>Tue, 25 Sep 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20180925/</guid>
      <description>这个中秋节去了内蒙古锡林格勒的黄岗梁，风景非常好，人在途中走，仿佛画中游。我拍了很多的人像，效果并不理想，背景画面都被我的f2.8光圈给虚化掉了，太可惜了，我在拍人像的时候习惯使用长焦距和大光圈，这样能拍摄出清晰唯美的效果，大光圈也往往会虚化掉背景，我考虑过如何能够使用短焦距和小光圈拍摄人像。&#xA;小光圈如果要突出主体，就应让需要被突出的对象具体光圈近一点，这人物也能凸显出来，背景也不会虚化掉，在小光圈的时候，可能会曝光不足，所以要延长曝光时间。&#xA;大光圈在拍摄人物的时候，有非常好的虚化效果，但是有一个要注意的地方是，如果在光线比较强的情况下，使用大光圈是容易导致曝光过度，天空是一完全白色的，这个时候需要降低iso或者是缩短曝光时间，我试过了，我的D750的1/4000s完全不够用，所以也得出一个结论，我的D750如果是使用f1.2或者f1.4的光圈，在太阳底下拍摄是完全不能发挥它的作用的。</description>
    </item>
    <item>
      <title>golang添加编译版本信息</title>
      <link>http://localhost:1313/posts/2018/20180921/</link>
      <pubDate>Fri, 21 Sep 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20180921/</guid>
      <description>在很多程序中，我们都能看到编译的版本信息&#xA;[jukay@mac-pro]~/Code/Go/src/github.com/hellojukay/test$ java -version java version &amp;#34;1.8.0_151&amp;#34; Java(TM) SE Runtime Environment (build 1.8.0_151-b12) Java HotSpot(TM) 64-Bit Server VM (build 25.151-b12, mixed mode) 这里的版本信息应该不是在代码里面写死的，而是在编译过程中动态生成。这里介绍一下golang怎么在编译时候加上版本信息,我们的代码如下：&#xA;package main import ( &amp;#34;flag&amp;#34; ) var version string func init() { var printVersion bool flag.BoolVar(&amp;amp;printVersion, &amp;#34;version&amp;#34;, false, &amp;#34;print program build version&amp;#34;) if !flag.Parsed() { flag.Parse() } if printVersion { println(version) } } func main() { } 编译时期注入main包的version变量的值&#xA;mac-pro:test jukay$ go build -ldflags &amp;#34;-X main.version=v1.0&amp;#34; main.go mac-pro:test jukay$ .</description>
    </item>
    <item>
      <title>使用 go modules功能</title>
      <link>http://localhost:1313/posts/2018/20180919/</link>
      <pubDate>Tue, 18 Sep 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20180919/</guid>
      <description>使用go modules功能的前提条件,二选一&#xA;安装golang 1.11以上版本 源码安装golang master分支源码 安装完以上组件以后，你就能够激活go modules功能了，激活方法有两种： go在$GOPATH/src目录之外执行go命令，创建go.mod文件 设置环境变量GO111MODULE=on，执行go命令 概念介绍 这本主要讲一个写go modules引入的新概念，你尅话四十分钟了解一下官方文档,或者花40分钟看下这个视频,或者看下更加详细的博客 。&#xA;Modules Modules是一组功能相关的golang包，他们被统一的版本管理起来。大部分情况下，我们是一个仓库一个版本管理，但是现在我们希望一个仓库能够同时版本管理多个Module。 Modules record precise dependency requirements and create reproducible builds.&#xA;Modules 精准的记录了依赖关系，保证了项目可重复编译。Modules同时也是语义化的版本管理，例如：v0.1.0, v1.2.3, or v3.0.1。这个前置 v字符是必须要求有的，如果是使用git来管理版本，那么这应该就是git tag 。&#xA;go.mod Modules使用 go.mod 文件记录了源码的代码结构，并且他不要求你的代码必须在GOPATH中。在 go.mod 中所有的Module都有一个前缀：模块的路径。使用module字段来定义一个新的Module,例如：里面包含两个 package,example.com/my/thing/foo 和 example.com/my/thing/bar ，那么 go.mod 文件里面第一行因该是 module example.com/my/thing 。 就是golang代码一样，Modules文件里面也可以加入一些注释。下面是一个 go.mod 文件的例子：&#xA;module github.com/my/module/v3 require ( github.com/some/dependency v1.2.3 github.com/another/dependency v0.1.0 github.com/additional/dependency/v4 v4.0.0 ) Module定义文件一共有四个指令: module, require, exclude, replace 。 exclude 和 replace一般只用在主Module里面，exclude 和 replace 使用在非主Modules里面的时候会被忽略。在源码中，我们通过完整的路径来导入导入一个 Module,例如：</description>
    </item>
    <item>
      <title>【行走的风景】圣莲山</title>
      <link>http://localhost:1313/posts/2018/20180916/</link>
      <pubDate>Sun, 16 Sep 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20180916/</guid>
      <description>这次载我们的大巴司机非常有意思，去的时候经过圣莲山没有停下来，走过了，回来的时候通过限高的地段，车顶刮了。一波三折，心疼司机。&#xA;这个景区的人特别少，稀稀拉拉可以看到几辆缆车，挺漂亮的。 登上山顶以后特别美，一览众山小。 这是在爬28盘的时候，在山腰上遇到一个小卖部，我们在这里修整了会，闲聊，吃冰棒。 </description>
    </item>
    <item>
      <title>linux查看运行中的程序的环境变量</title>
      <link>http://localhost:1313/posts/2018/20180914-1/</link>
      <pubDate>Fri, 14 Sep 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20180914-1/</guid>
      <description>我们的代码如下：&#xA;package main import &amp;#34;fmt&amp;#34; import &amp;#34;os&amp;#34; import &amp;#34;time&amp;#34; func main() { for { var name = os.Getenv(&amp;#34;name&amp;#34;) time.Sleep(time.Duration(2) * time.Second) fmt.Println(name) } } 通过内核提供的/proc文件来看程序运行中一些状态数据。&#xA;这里我们很清楚的看到了name=hellojukay，非常的遗憾的是environ这个文件是无法写入的 sudo chmod +w environ也不行。</description>
    </item>
    <item>
      <title>mac下格式化U盘</title>
      <link>http://localhost:1313/posts/2018/20180914/</link>
      <pubDate>Fri, 14 Sep 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20180914/</guid>
      <description>查看U盘所在的分区&#xA;[jukay@mac-pro]~$ diskutil list /dev/disk0 (internal, physical): #: TYPE NAME SIZE IDENTIFIER 0: GUID_partition_scheme *121.3 GB disk0 1: EFI EFI 209.7 MB disk0s1 2: Apple_CoreStorage Macintosh HD 120.5 GB disk0s2 3: Apple_Boot Recovery HD 650.0 MB disk0s3 /dev/disk1 (internal, virtual): #: TYPE NAME SIZE IDENTIFIER 0: Apple_HFS Macintosh HD +120.1 GB disk1 Logical Volume on disk0s2 CDE1D658-8C57-40FD-AA38-46EFB615DE3C Unencrypted /dev/disk2 (external, physical): #: TYPE NAME SIZE IDENTIFIER 0: FDisk_partition_scheme *31.9 GB disk2 1: DOS_FAT_32 31.</description>
    </item>
    <item>
      <title>【行走的风景】百花山</title>
      <link>http://localhost:1313/posts/2018/20180909/</link>
      <pubDate>Sun, 09 Sep 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20180909/</guid>
      <description>早上6点10分出门，七点半大屯东路上车，11点07分到达百花上。山下的小苹果特别好吃，十块钱能买一大袋子，上山时候买了一袋子，下山后又买了一袋子，回来时候还买了核桃，12元一斤，买了15块钱的核桃，晒干后放两个在口袋，压力大的时候捏一下，能缓解压力。&#xA;山上的风景特别好，而我顾着给美女拍照，风景都没有怎么拍，后来玩嗨了，把我的景秀江山卡和公交卡也弄丢了，有点亏。&#xA;穿过蒙古栎和白桦交织的密林 到达&amp;quot;山顶&amp;quot;后的高山草甸 有个妈妈带着自己的儿子上山了，我特别欣赏这样的父母，给她点赞。 絮儿小姐姐 白花山非常不错，开始的爬台阶可能有点辛苦，但是爬上去了之后就是风光无限好了，是很值得的。</description>
    </item>
    <item>
      <title>自建asciinema服务器</title>
      <link>http://localhost:1313/posts/2018/20180904/</link>
      <pubDate>Tue, 04 Sep 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20180904/</guid>
      <description>把自己的终端上传到官方服务器，始终是一件不安全的事情，所以推荐大家自建asciinema服务器。直接使用官方的docker-compose文件，稍加修改就能成功clone官方的项目&#xA;version: &amp;#39;2&amp;#39; services: postgres: image: postgres container_name: asciinema_postgres restart: unless-stopped volumes: - ./volumes/postgres:/var/lib/postgresql/data ### See https://hub.docker.com/_/postgres/ for more ### configuration options for this image. redis: image: redis container_name: asciinema_redis restart: unless-stopped volumes: - ./volumes/redis:/data ### See https://hub.docker.com/_/redis/ for more ### configuration options for this image. smtp: image: namshi/smtp container_name: asciinema_smtp restart: unless-stopped env_file: .env.production ### See https://github.com/namshi/docker-smtp for more SMTP configuration ### options for this image. nginx: image: nginx:alpine container_name: asciinema_nginx restart: unless-stopped links: - phoenix - rails ports: - &amp;#34;3000:80&amp;#34; ### Uncomment for HTTPS: # - &amp;#34;443:443&amp;#34; volumes: - .</description>
    </item>
    <item>
      <title>【行走的风景】清凉谷</title>
      <link>http://localhost:1313/posts/2018/20180902/</link>
      <pubDate>Sun, 02 Sep 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20180902/</guid>
      <description>周末去了清凉谷，就在密云区，路过了密云水库，满满的回忆的。清凉谷在青龙山，景区非常小，我们两三个小时就逛完了。清凉谷票价45元，我们使用景秀江山年卡就能直接进入。&#xA;票价100元的玻璃天桥 站在玻璃桥底下查看天桥上的人 上山下山的缆车 半山腰上的池塘 陡峭的上山的栈道 曲径通幽处 </description>
    </item>
    <item>
      <title>【行走的风景】五台山</title>
      <link>http://localhost:1313/posts/2018/20180829/</link>
      <pubDate>Wed, 29 Aug 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20180829/</guid>
      <description>2018年08月24日，星期五，本次目的地是煤矿省五台山。厚着脸皮跟涛哥请假半小时后，提前下班半小时下班出发了，看着我绝尘而去的身影，同事问: 你怎么现在就走了，去哪儿？ 我答:寻找诗和远方！ 同事:唉，我还要继续苟且…&#xA;第一天 给我们开车的，还是我们的老朋友，邓师傅，车技一如既往的稳！过了11点，大巴车没能进去山西高速，7小时以后，到达了住宿地！&#xA;第二天 菜鸟第一次走五台山，不敢跑太远，就没有去东台！想着和唐队他们搭车到北台的，一路上没有车载我们，搭车未遂，走到了北台，爬上了上顶，感觉还好，并没有感觉疲劳！不管去哪里，风景都美的一个样:蓝天，白云，大草地…但是是不管去哪儿，路上的故事都是不一样的精彩。 我不认识这个姑娘，但是我欠他18块钱，她请我吃了一顿中午饭，她给我讲她和渣男男朋友的恩怨情仇，讲她去过的地方，她接下来要去的地方，最后我假装成她它乡遇故知的高中同学，成功混进她们的10人小队伍，一起爬了东台！ 第三天 这个小女孩对我的相机非常好奇，我给她拍照，她很配合，就是怎么也处理不好自己紧张的情绪，把一伙人都逗笑了！ 苦行的曾侣,出家人走路，或低头忍受生活和修行的痛苦，或目视前方自然惬意！ </description>
    </item>
    <item>
      <title>Makefile相关知识点</title>
      <link>http://localhost:1313/posts/2018/20180822/</link>
      <pubDate>Wed, 22 Aug 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20180822/</guid>
      <description>开源项目中非常流行使用Makefile来处理构建的问题，我比较喜欢使用Makefile来给命令行分组。Makefile文件前面的缩进不是空格，这个写Makefile前一定要明确的问题。&#xA;[jukay@mac-pro]~/Desktop$ cat Makefile test: echo Hello World [jukay@mac-pro]~/Desktop$ make echo Hello World Hello World [jukay@mac-pro]~/Desktop$ make命令会自动寻找当前目录下面的名字叫做Makefile的文件，可能使用make -f filename来指定其他文件，找到了文件以后构建你指定的产物，如果没有指定产物，那么会默认构建第一个产物，如果产物已经存在了，那么不会执行构建流水了。例如，当前目录下面已经存在了一个名字为 test 文件，那么执行 make test 是不会执行构建的。&#xA;[infra@dev ~]$ ls Makefile test [infra@dev ~]$ make test make: “test”是最新的。 [infra@dev ~]$ make make: “test”是最新的。 [infra@dev ~]$ 这里在shell命令前面加上@符号，是表示在指定当前命令的会后，不要打印这条命令的指定过程。如果当前的目标产物存在了，但是构建目标产物还需要其他依赖,那么还是会重新构建当前目标产物的&#xA;[infra@dev ~]$ ls Makefile test [infra@dev ~]$ cat Makefile test: dev @echo Hello World dev: @echo dev [infra@dev ~]$ make test dev Hello World [infra@dev ~]$ make也是可以一次构建两个产物的</description>
    </item>
    <item>
      <title>docker指定用户运行容器</title>
      <link>http://localhost:1313/posts/2018/20180821/</link>
      <pubDate>Tue, 21 Aug 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20180821/</guid>
      <description>在使用prometheus的时候，prometheus产生的文件的用户名总是nobody,并且给prometheus挂在的文件都没有读写权限，让我意识到，容器内部的权限也是一个不可忽视的问题。所以你不想容器打印出来日志，运维同事没有读取的权限，那么你就应该至容器运行的时候指定用户的运行用户。&#xA;docker和docker-compose都提供了指定容器运行用近乎的方法。docker指定运行用户:&#xA;docker run -u user iamge 具体说明如下&#xA;[hellojukay@localhost ~]$ docker run --help | grep user -u, --user string Username or UID (format: &amp;lt;name|uid&amp;gt;[:&amp;lt;group|gid&amp;gt;]) --userns string User namespace to use [hellojukay@localhost ~]$ 这里可以使用username也可以使用uid，但是有一点区别的是，如果是用username,那么容器里面也必须存在这个同样名字的user，如果是使用uid，那么就没有这个要求。所以大部分情况下，我们使用uid来指定用户和用户组。 docker-compose指定某个容器运行时用户方法如下：&#xA;# This is an abbreviated example docker-compose.yml version: &amp;#39;3.3&amp;#39; services: rspec: image: my-docker/my-build-environment:latest environment: - RAILS_ENV=test command: [&amp;#34;make&amp;#34;, &amp;#34;assets&amp;#34;] # THIS BIT!!!1! user: ${CURRENT_UID} volumes: - .:/app 那么我们启动的这个docker-compose的时候：&#xA;CURRENT_UID=$(id -u):$(id -g) docker-compose up 这是使用当前shell用户运行容器，也可以是别的用户&#xA;CURRENT_UID=$(id -ujukay):$(id -g jukay) docker-compose up 2018年10月15日更新 让容器用指定用户的运行的前提是：容器中有这个用户，不然容器中的程序还是会使用root运行。</description>
    </item>
    <item>
      <title>mysql数据导入导出</title>
      <link>http://localhost:1313/posts/2018/20180820/</link>
      <pubDate>Mon, 20 Aug 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20180820/</guid>
      <description>第一次做mysql的数据导入导出工作，这里记录一下导入导出方法。标题中说mysql,实际上我使用的并不是mysql，而是mysql之父创作另一个数据库:MariaDB。MariaDB完全兼容mysql的操作。这里要说明的是，我的MariaDB是跑在docker容器里面的,那么它的登录方式应该是这样的:&#xA;[infra@localhost]$ docker exec -it db mysql -uuser -ppasswd Welcome to the MariaDB monitor. Commands end with ; or \g. Your MariaDB connection id is 43 Server version: 10.3.8-MariaDB-1:10.3.8+maria~bionic-log mariadb.org binary distribution Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others. Type &amp;#39;help;&amp;#39; or &amp;#39;\h&amp;#39; for help. Type &amp;#39;\c&amp;#39; to clear the current input statement. MariaDB [(none)]&amp;gt; 导出整个数据到sql文件&#xA;[infra@localhost ~]$ docker exec -it snc_mysql mysqldump -uuser -ppasswd databasename &amp;gt; data.</description>
    </item>
    <item>
      <title>【摄影】关于快门速度的思考</title>
      <link>http://localhost:1313/posts/2018/20180819-1/</link>
      <pubDate>Sun, 19 Aug 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20180819-1/</guid>
      <description>周六的云蒙山爬山，我第一次摄影，拍了不少照片，大部分都是抓拍的，回来一看，好多照片都是模糊的。对此，我也总结了一下。当使用自动挡拍摄的时候光圈和ISO是固定的，所以相机自动调节快门速度来控制曝光。如果在比较暗的地方，快速就较低，曝光时间长，那么在暗的地方就不适合拍摄运动护对象，否则照片会模糊。在光线比较强的地方，光线强，那么需要的曝光时间就短，也就是说快速度比较快，这样就适合拍摄运动中的对象。如果是要拍摄快速运动的物体，我认为应该是用快门优先模式，提高快门的速度，快速速度高了，那么ISO需要提高，或者说光圈需要变大，如果说不希望照片中出现噪点，那么就应该使用较低的ISO，使用较大的光圈，在这种情况下，如果光圈不够大，那么只有提高ISO了。&#xA;2018年09月02日更新 光圈每相隔一档位，镜头透光量就相隔一倍，光圈只会影响景深，不会影响照片的范围大小，光圈越大，景深越浅，光圈越小景深度约深。改变照片范围的只有拍摄者相聚照片的距离，还有焦距的大小，以及画幅的大小。</description>
    </item>
    <item>
      <title>【行走的风景】云蒙山</title>
      <link>http://localhost:1313/posts/2018/20180819/</link>
      <pubDate>Sun, 19 Aug 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20180819/</guid>
      <description>五点钟就下了很大的雨，让人感觉今天的活动要取消，但是领队还是发短信告知：活动照常。可能大家都是两周没有出去了，家里闷得慌吧，怎么说今天也要出去走走。&#xA;到达云蒙山以后，天气还是很阴沉。各种石板，泥土，木材的台阶，这山路走的比较辛苦，好在有白桦林，还有远处山涧的流水声，让人忽视了登山的疲惫, 我们就这样说说笑笑到达了山顶，到达山顶以后就是一番拨开云雾见青天感觉了，山上的木地板和阳光让人瘫痪在地上，舒服得一塌糊涂。 </description>
    </item>
    <item>
      <title>【行走的风景】草原天路</title>
      <link>http://localhost:1313/posts/2018/20180809/</link>
      <pubDate>Thu, 09 Aug 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20180809/</guid>
      <description>2018年8月4日，怕赶不上大巴，早上六点钟我就起来了，在路上时候发现是8:00才集合，七点不到就都了大屯路东地铁站，结果是我等了一个小时。耗时五个小时到了目的张家口张北县，路上还经历了大雨。我没有带伞，也没有带雨衣，本来以为要完蛋，但是到了以后却是一个大好的晴天，微风拂面，凉快得很。就是这样踏上了第一天的徒步之旅。 红色背包非常健谈，一路上和我聊罗永浩,锤子科技,人工智能,区块链,比特币，云计算。。。一路上都不觉得疲惫。。。第一天19km全程徒步完成，我没有搭车，到达休息地点以及是晚上7点，和唐队一起吃的晚餐。我现在还在后悔，吃饭的时候我为什么没有要一瓶啤酒。。。 第二天我还是选择了徒步走完25km，我们徒步的先走，剩下的人搭乘汽车。1点钟的时候，我追上了大部队，开始了走走看看的漫游模式，就这样走完了第二天的25km。因为我没有任何防晒措施，必然我被晒伤了。同时们看到脸上脱皮，问我怎么回事，我开玩笑：工资太低，生活艰难，周末去工地兼职晒伤了。</description>
    </item>
    <item>
      <title>docker打包镜像的注意事项</title>
      <link>http://localhost:1313/posts/2018/20180806/</link>
      <pubDate>Mon, 06 Aug 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20180806/</guid>
      <description>在docker打包镜像的时候，我一般是使用 alpine 作为底包，而不是 ubuntu 更加不是 centos ，因为这个两个基础镜像的文件大小已经非常大了，不利于分发和快速部署。我们在为 alpine 安装工具的时候经常会遇到安装过程中卡主的情况，这是因为从 http://dl-cdn.alpinelinux.org/alpine/ 这个仓库下载包会非常缓慢。使用阿里云提供的镜像加速服务可以绕过这个坑。如下：&#xA;FROM fluent/fluentd:v0.12-onbuild # backup the orign repo and use aliyun mirror instead RUN { \ echo &amp;#34;http://mirrors.aliyun.com/alpine/v3.7/main&amp;#34;; \ echo &amp;#34;http://mirrors.aliyun.com/alpine/v3.7/community&amp;#34;; \ } &amp;gt; /etc/apk/repositories RUN apk add --update --virtual .build-deps \ sudo build-base ruby-dev \ &amp;amp;&amp;amp; sudo gem install \ fluent-plugin-elasticsearch \ &amp;amp;&amp;amp; sudo gem sources --clear-all \ &amp;amp;&amp;amp; apk del .build-deps \ &amp;amp;&amp;amp; rm -rf /var/cache/apk/* \ /home/fluent/.gem/ruby/2.3.0/cache/*.gem 以上是我编译 fluentd 的镜像时候用的 Dockerfile 文件。这行代码就是添加镜像加入的作用</description>
    </item>
    <item>
      <title>【翻译】给git仓库瘦身</title>
      <link>http://localhost:1313/posts/2018/20180731-1/</link>
      <pubDate>Tue, 31 Jul 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20180731-1/</guid>
      <description>某些特殊的原因，我们不小心把一个较大的文件加入到了 git 仓库，并且我们提交了它，git 仓库的大小会瞬间的膨胀起来，有些时候，我们甚至都不知道我们加入的是那个大文件导致，即使我们找到了这个文件，将他从 git 仓库中删除了，但是仓库并没有完全的变小，因为在 .git 这个文件中还保存着这个大文件的内容。我们处理这个问题分三个步骤：&#xA;找到这个大文件 将大文件从仓库中删除 修改 .git 服务器中的文件 clone仓库 如果你本地还没有仓库，那么你应该先将仓库下载到本地&#xA;git clone remote-url 现在你本地有这了这个仓库了，但是你还没有全部的分支，为了保证大文件能能够完全的干净的删除，你需要获取所有的分支，完成这个工作，你还需要一个脚本：&#xA;for branch in `git branch -a | grep remotes | grep -v HEAD | grep -v master`; do git branch --track ${branch##*/} $branch done 找到大文件 这里有一个脚本，帮助我们找到那个大文件&#xA;#!/bin/bash #set -x # Shows you the largest objects in your repo&amp;#39;s pack file. # Written for osx. # # @see http://stubbisms.wordpress.com/2009/07/10/git-script-to-show-largest-pack-objects-and-trim-your-waist-line/ # @author Antony Stubbs # set the internal field spereator to line break, so that we can iterate easily over the verify-pack output IFS=$&amp;#39;\n&amp;#39;; # list all objects including their size, sort by size, take top 10 objects=`git verify-pack -v .</description>
    </item>
    <item>
      <title>基于密码的自动登录方案</title>
      <link>http://localhost:1313/posts/2018/20180731/</link>
      <pubDate>Tue, 31 Jul 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20180731/</guid>
      <description>虽然密码登很不安全，运维是应该禁止掉这样的登录方式。但是。。。&#xA;编写自动登录脚本 cat auto_login.sh #!/usr/bin/expect set user xxxx set host localhost set password &amp;#39;xxxx&amp;#39; catch {set user $env(login_user)} catch {set host $env(login_host)} catch {set password $env(login_passwd)} set timeout 60 spawn ssh &amp;#34;$user@$host&amp;#34; expect &amp;#34;*assword:*&amp;#34; send &amp;#34;$password\r&amp;#34; interact 这里expect是读取的环境变量中的登录用户，登录机器，登录密码，如果环境变量没有对应的变量，会使用默认值进行登录。&#xA;编写特定机器登录脚本 #!/usr/bin/env bash env login_user=xxxx login_passwd=xxxx login_host=$(basename $0) auto_login.sh 当前脚本文件的文件名字就是你需要登录的机器，可以是域名，也可以是ip.如果我要登录的机器是blog.hellojukauy.cn。那么脚本的文件名字应该是blog.hellojukauy.cn&#xA;cat blog.hellojukauy.cn #!/usr/bin/env bash env login_user=xxxx login_passwd=xxxx login_host=$(basename $0) auto_login.sh 上面调用了auto_login.sh这个脚本，所以auto_login这个脚本最好是应该放在当前用户的PATH中。&#xA;修改PATH 在.bashrc中添加append函数&#xA;append(){ PATH=$PATH:$1 } 使用apppend将auto_login.sh加入到PATH&#xA;append /Users/jukay/login/ 更新当前环境变量,更新以后登录就能自动补全了，登录blog.hellshell.cn&#xA;source .bashrc # 登录成功 blog.</description>
    </item>
    <item>
      <title>vim小技巧</title>
      <link>http://localhost:1313/posts/2018/20180725/</link>
      <pubDate>Wed, 25 Jul 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20180725/</guid>
      <description>关于c命令的技巧，c表示clear的意思，就是清空,c命令执行完成以后都会进入insert模式。&#xA;c+^:清空至行首 c+^：清空至行尾 c+w：清空至单词尾 C: 相当于c$清空至行尾 :E: 打开目录结构 :r!date: 插入当前日期 dgg: 删除到文件首 dG: 删除到文件尾部&#xA;2018年11月22日添加 pclose: 关闭预览窗口 p: 预览当前文件&#xA;2018年12月13日添加 :w filename: 文件另存为filename&#xA;2018年12月17日添加 :!command:执行一条命令，但是不退出当前的vim&#xA;2019年10月18日添加 H 移动到当前屏幕的第一行 L 移动到墙面屏幕最后一行&#xA;2019年10月24日添加 ctrl + ] 跳转到定义 ctrl + o 跳回光标原来位置 J 删除当前行后面的换行符号，与下一行链接起来&#xA;2019年10月25日添加 ctrl + g 显示文本当前面 buffer 信息</description>
    </item>
    <item>
      <title>【翻译】nginx入门手册</title>
      <link>http://localhost:1313/posts/2018/20180710/</link>
      <pubDate>Tue, 10 Jul 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20180710/</guid>
      <description>前言 这个手册手册假设你已经安装了nginx，如果没有请前往nginx官网下载安装nginx，我们将好告诉你如何启动，关闭nginx，还有更新nginx的配置文件，像你描述如何使用nginx代理静态文件，如果配置反向代理.&#xA;nginx启动以后拥有一个master进程和多个worker进程，master进程的主要任务是读取配置文件，解析配置文件，管理worker进程的生命周期，worker进程的数量是配置在配置文件中，如果配置的不会，nginx也尝试让你的配置变得更加合理，它同事会根据cpu的数量上下调整worker进程的数量.&#xA;nginx的配置文件名字叫做nginx.conf，默认情况下,nginx会尝试从/etc/nginx/或者/usr/local/etc/nginx中寻找配置文件．&#xA;启动,关闭,更新配置 启动nginx只需要执行nginx的可执行文件&#xA;nginx 一旦启动成功，你就能通过&#xA;nginx -s signal 来空置nginx进程,信号使用说明如下&#xA;stop 关闭nginx quit 退出nginx reload 重新加载配置文件 reopen 重新打开日志文件 例如，如果你要关闭｀nginx｀服务，你需要执行下面的命令 nginx -s quit 执行这个命令的用户应该和启动nginx的用户一致，一般会是www用户或者root用户,更新nginx的配置文件，你需要执行：&#xA;nginx -s reload 当master进程收到了更新配置文件的信号以后，master进程会立马检查配置文件，并且解析配置文件，如果有语法错误，那么什么也操作，忽视用户的操作，如果配置文件没问题，那么它会解析这个文件，并且发送信号给worker进程，通知worker进程退出，master使用新的配置文件产生新的worker进程．&#xA;也可以使用kill命令发送信号给master进程,master进程的pid一般都会保存在一个nginx.pid的文件中，这文件一般会在/usr/local/nginx/logs或者/var/run,例如master的pid是1682,发送QUIT信号也能关闭nginx,命令如下：&#xA;kill -s QUIT 1628 如果要查询nginx的pid可以使用如下命令：&#xA;ps ax | grep nginx ＃　配置文件的结构 nginx包含很多的模块，各个模块都能通过配置文件中的指令来控制，可能是一个简单的指令也可能是一个指令集，一条简单的指令包含指令名字，指令参数，最后用 ; 来表示指令结束了。块指令包含多个简单的指令，他用 {来表示开始，}来表示结束。使用#开头的行表示是一行注释，不会影响nginx的行为。&#xA;nginx 代理静态文件 nginx的一个非常重要的用处是用来最为文件服务器托管文件（类似于图片，静态的HTML页面),这里将会告诉如何搭建一个简单的静态文件服务器。&#xA;创建/data/www目录，放一个index.html的静态文件再里面 创建/data/images目录，放入若干的图片 现在，我们需要再配置里面配置http模块和server模块。默认的nginx配置文件已经包含了一些记本的配置信息，下面我们创建一个新的server http { server { } } 一个nginx的配合文件里面是可以配置多个server模块的，他们绑定不同的端口。在nginx接受到请求以后，首先会检查请求的路径是否满足配置文件中的location配置。添加如下内容到server配置中:&#xA;location / { root /data/www; } location设置 / 会拦截所有来自这个端口的请求，匹配路径root指令所在的文件夹/data/www中的文件，如果满足，就会使用这个规则，如果不满足就会跳过，现在想server中再加入一条配置：&#xA;location /images { root /data; } 这条配置会匹配/images开头的请求。现在我们的配置我内存大概看起来像这样：</description>
    </item>
    <item>
      <title>使用文件记录命令行执行过程</title>
      <link>http://localhost:1313/posts/2018/20180703/</link>
      <pubDate>Tue, 03 Jul 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20180703/</guid>
      <description>今天学习了一个有意思的命令行程序，script这个命令，基本上linux上都会自带这个命令，它的使用方式也非常简单&#xA;script -a recordfile 这里-a表示以追加的形式记录，如果之前已经记录了一部分，是可以追加再次记录的，但是并不是说recordfile这个文件就一定要预先存在，它也是会临时创建文件的．执行script -a 开始记录命令行执行过程，输出exit退出记录，ctrl + D也可以退出．如果你要查看记录，直接使用cat命令查看文件即可．你也可以把文件传给别人．&#xA;hellojukay@deepin:~$ cat record Script started on 2018年07月03日 星期二 23时25分35秒 hellojukay@deepin:~$ ls 2018-07-01-14-26-10.088-VBoxSVC-4767.log Documents Pictures Steam word_list Data Downloads record Templates Desktop Music source.txt Videos hellojukay@deepin:~$ tail -f record ^C hellojukay@deepin:~$ #la hellojukay@deepin:~$ 怎么没有数据呢 bash: 怎么没有数据呢: 未找到命令 hellojukay@deepin:~$ exit exit Script done on 2018年07月03日 星期二 23时26分05秒 hellojukay@deepin:~$ </description>
    </item>
    <item>
      <title>shell多进程编程</title>
      <link>http://localhost:1313/posts/2018/20180701/</link>
      <pubDate>Sun, 01 Jul 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20180701/</guid>
      <description>#!/usr/bin/env bash mysleep() { echo &amp;#34;sleep $1 seconds&amp;#34; sleep &amp;#34;$1&amp;#34; } main() { for ((i = 1; i &amp;lt; 10; i++)); do (mysleep $i) &amp;amp; done wait } time main 直接上了,这里要说明的是,把一行命令包起来表示用子shell来执行，而不是当前进程的shell,　＆　表示让当前进程到后台执行，不阻塞当前进程，这里的&amp;amp;非常关键，如果没有&amp;amp;就还是顺序执行，大家可以试一下，下面的wait命令也非常关键，表示等待当前进程的所有子进程返回，没有这里wait命令，main进程会提前退出，那么就有可能有命令没有执行完全．&#xA;hellojukay@deepin:~/Data/Code/Web/blog$ bash source/_posts/20180701/mysleep.sh sleep 1 seconds sleep 2 seconds sleep 3 seconds sleep 4 seconds sleep 5 seconds sleep 6 seconds sleep 7 seconds sleep 8 seconds sleep 9 seconds real 0m9.004s user 0m0.011s sys 0m0.006s 可以看到这里只使用了９秒钟，因为他是并行的．如果去掉 &amp;amp; ,那么有可能是45秒钟左右，如果去掉wait，可能就是不到一秒钟就结束了．</description>
    </item>
    <item>
      <title>【翻译】在jenkins流水线使用docker</title>
      <link>http://localhost:1313/posts/2018/20180816/</link>
      <pubDate>Sat, 16 Jun 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20180816/</guid>
      <description>许多团队和组织使用docker来跨平台的测试，构建，发布他们的项目, docker提供了非常好高效的部署效率。Jenkins 在2.5版本以后加入了pipeline功能,pipeline支持在Jenkinsfile里面执行docker相关的操作。本文将会介绍在Jenkinsfile中执行docker的相关操作。&#xA;自定义执行环境 pipeline能够使用一个docker image指定执行环境，既可以为整个pipeline指定指定环境，也可以为单个stage指定执行环境。&#xA;pipeline { agent { docker {image: &amp;#39;node:7-alpine&amp;#39;} } stages { stage(&amp;#39;test&amp;#39;){ steps{ sh &amp;#39;node --version&amp;#39; } } } } 当这个pipeline执行的时候，Jenkins会自动的启动一个容器来执行指定的steps&#xA;[Pipeline] stage [Pipeline] { (Test) [Pipeline] sh [guided-tour] Running shell script + node --version v7.4.0 [Pipeline] } [Pipeline] // stage [Pipeline] } 为容器缓存数据 许多的构建工具会下载一些外部的依赖并且缓存到本地，将来再次构建的时候会用到这些数据。pipeline支持传递自定义参数给docker命令，允许在docker执行的挂载本地的文件，这个能够缓存容器执行过程产生的数据.例如：maven构建过程中会缓存数据到~/.m2这个文件夹中。&#xA;pipeline { agent { docker { image: &amp;#39;maven:2-alpine&amp;#39; args: &amp;#39;-v $HOME/.m2:/root/.m2&amp;#39; } } stages { stage { steps { sh &amp;#39;mvn -B&amp;#39; } } } } 使用多种容器 一个项目可能使用java写后端，使用javascript写前端，我们要运行他，就需要在不同的stage中使用相应的容器。</description>
    </item>
    <item>
      <title>【翻译】bash备忘录</title>
      <link>http://localhost:1313/posts/2018/20180609/</link>
      <pubDate>Sat, 09 Jun 2018 23:29:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20180609/</guid>
      <description>原文地址: http://www.linux-sxs.org/programming/bashcheat.html 本文不会教你如何使用bash，但是他会让你快速的知道bash是什么，让你知道什么是bash脚本。&#xA;基础 bash脚本都需要告诉操作系统，当前使用哪一种解释器来执行这个脚本。写在脚本的第一行,如下：&#xA;#!/bin/bash //或者 #!/usr/bin/env bash #!/bin/node 你必须让脚本拥有可执行权限&#xA;#所有人都拥有执行权 chmod +x filname # 当前用户拥有执行权限 chmod u+x filename 变量 bash的变量没有类型，定义方法如下：&#xA;varname=value n=10 在变量名字前面使用 $ 来使用这个变量，例如：&#xA;n=10 echo $n 命令行参数中的变量通常使用$N来访问，$#表示命令行参数的个数(不包括命令本身)&#xA;command var1 var2 var3 &amp;hellip;. varX&#xA;$# 表示参数个数 $@ 表示所有参数(不包括命令本身) $0 表示 command 命令本身 $1 表示var1 $2 表示var2 依次类推。。。 引用符号 双引号：&amp;ldquo;var&amp;quot;被shell理解为是一个普通的字符串参数，你需要特别注意其中的转义字符。 单引号： &amp;lsquo;var&amp;rsquo;被shell理解为一个单纯的字符，shell会忽略其中的转义字符，不会转义他们。 反引号： var被shell理解为一条需要执行的bash命令，通过会用在子名字中，例如：&#xA;echo `pwd` 逻辑判断 数字比较 test expression 或者 [ expression ]&#xA;int1 -eq int2&#x9;如果int1等于int2,返回true int1 -ge int2&#x9;如果int1大于或者等于int2，返回true int1 -gt int2&#x9;如果int1大于int2，返回true int1 -le int2&#x9;如果int1小于或者等于int2，返回true int1 -lt int2&#x9;如果int1小于int2, 返回true int1 -ne int2&#x9;如果int1不等于int2, 返回true</description>
    </item>
    <item>
      <title>几个golang的面试编程题目</title>
      <link>http://localhost:1313/posts/2018/20180603/</link>
      <pubDate>Sun, 03 Jun 2018 12:30:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20180603/</guid>
      <description>前几天出去面试了，有几个编程现场编程题目，我这里记录一下:&#xA;字符串翻转 方法1 // 非常低的效率 func reverse(s string)string{ var buffer = []rune(s) var arr []rune for index := range buffer{ arr = append([]rune{buffer[index]},arr ...) } return string(arr) } 方法2 func reverse(s string)string{ var n string for _,v := range s{ n = string(v)+n } return n } 10个goroutine分别打印 1, 2, 3 &amp;hellip; 10 方法1 package main import &amp;#34;sync&amp;#34; var wg sync.WaitGroup func fx(n int){ defer wg.Done() println(n) } func main(){ for i := 1 ;i &amp;lt;=10;i++{ wg.</description>
    </item>
    <item>
      <title>常用的Linux命令</title>
      <link>http://localhost:1313/posts/2018/20180602/</link>
      <pubDate>Sat, 02 Jun 2018 13:38:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20180602/</guid>
      <description>昨天面试，面试官问我都用了哪些linux命令，我一想，那可太多了。回来有我总结一下，这里列举一下自己经常使用的linux命令&#xA;ls,ll 查看当前目录，或者给定目录下的文件 cd 工作目录切换 pushd, popd 切换目录 pwd 查看当前用户所在工作空间 clear 清屏 echo 输出到终端 yes,true 返回成功 no 返回失败 tail 从尾部开始查看文件，可以实时查看 cat 查看整个文件 more 分页查看文件 head 从文件头部 vi， vim linux上最流行的编辑器 sed 实时编辑文本 awk 字符流处理 touch 创建文件 mkfs 分区格式化 tar ,zip, unzip 文件打包，压缩或者解压 dd 磁盘快拷贝 rm 删除文件 mv 移动文件或文件改名字 rename 文件改名字 cp 文件复制 df 查看磁盘使用情况 du 查看文件信息 top 查看当前进程列表 free 查看内存使用情况 ps 查看进程信息 grep 搜索文本 reboot 重启 shutdown 关闭计算机或者重启 date 查看当前日期 watch 重复执行命令 chmod 修改文件权限 chown 修改文件属主 chsl 修改用户默认shell lsof 查看Linux打开的文件信息 netstat 查看系统网络相关信息 ssh 登录服务相关 nc , netcat 连接远程服务器，有点hack telnet 连接远程服务器 ping 使用icpm协议看出网络情况 ifconfig 查看网络配置 ip 查看ip地址 nslookup dns查询 whois 域名信息查询 dig 域名信息查询 curl 发送http请求 wget http下载 rsync 文件同步 scp 文件传输 rz,sz 文件传输 gcc, g++ 编译c++或者c make 执行构建 xargs 将管道数据转换成命令行参数 kill 给进程发送信号 ptree 查看进程书状结构 strace 查看进程的系统调用情况 find 文件查找 sysctl 内核配置相关 systemd ， service 操作linux服务 nohup 进程托管 killall 关闭特定名字的进程 pidof 获取后面进程的进程号 exit 退出shell的session yum ,pacman, apt 包管理工具 bash,sh,source 执行shell脚本 env 设置当前命令的环境变量 set 查看环境变量 export 设置环境变量 sudo 以root全新执行命令 su 切换用户 file 查看文件内心 type 查看命令内心 man 查看命令手册 ln link相关操作 bc 计算器 sort 排序 md5 计算文件md5值 jobs 查看后台作业 useradd 添加用户 userdel 删除用户 users 查看已经登录的用户 w 查看负载信息 mount 挂载磁盘 uname ，lsb_release 查看系统信息 pip 安装node包 lsblk 查看磁盘分区信息 chpassword, password 修改密码 svn svn相关的操作 git git相关操作 </description>
    </item>
    <item>
      <title>google搜索的正确使用方式</title>
      <link>http://localhost:1313/posts/2018/20180528/</link>
      <pubDate>Mon, 28 May 2018 20:27:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20180528/</guid>
      <description>虽然标题写的是google搜索，但是大部分的技巧在baidu下也是适用的，本文中的搜索技巧配置chrome的tab补全搜索体验更佳。备注：以下搜索技巧可以混合使用。&#xA;搜索相关的内容 关联多个内容的时候搜索方式 过滤搜索网站结果 你可能注意到了，搜索的第一条结果就是java.com这样网站，如果我想搜索结果里面去掉某个特定网站的内容，比如我在搜索的时候就经常会去掉csnd和cnblog这两个网站。 这样oracle.com和java.com就不会出现在我的搜索结果中了。&#xA;特定网址网址搜索 有些时候，某些网站的站内搜索功能并不好用，我们可以使用google的站内搜索功能，比如我要在zhihu上搜索java相关的内容。 这样的搜索结果就都是知乎的内容了。&#xA;关键字搜索 使用英文的双引号把关键字包含起来,这样搜索结果中是必须包含所有关键字的，关键字可以是多个比如: &amp;ldquo;a&amp;rdquo; &amp;ldquo;b&amp;rdquo; 既包含字符串a又包含字符串b &amp;ldquo;a&amp;rdquo; -&amp;ldquo;b&amp;rdquo; 之包含a字符串，绝对不包含b字符串 &amp;ldquo;a&amp;rdquo; or &amp;ldquo;b&amp;rdquo; 包含字符串a或者包含字符串b 按照文件类型搜索 使用filtype指令加上文件类型，这个搜索功能有你想要的效果，至于怎么使用，哈哈哈哈哈 搜索类似网站 这里搜索出类hacknews相关的网址。 以上就是最常用的google搜索技巧，如果你想知道更多关于google搜索技巧的只是，你可以使用google搜索。&#xA;参考文章 十大高明的Google搜索技巧 </description>
    </item>
    <item>
      <title>这可能是局域网内分享文件的最佳方案</title>
      <link>http://localhost:1313/posts/2018/20180525/</link>
      <pubDate>Fri, 25 May 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20180525/</guid>
      <description>标题中说是局域网，但是并没有限制你在公网上使用这种方式来单向传出文件，只要是HTTP协议能够正常工作的网络就行。通常发送文件给同事，都是用钉钉，QQ，微信或者的别的社交软件，或者是U盘(很少用到)。使用社交软件传文件的坏处就是这个文件要先发送到服务器，然后对人从服务器上下载，可能文件挺大的，速度慢，也不支持断点传输，也可能是机密文件，你不想被第三方获取。使用U盘缺点是，你要先把文件拷贝到U盘，然后从U盘拷贝到对方的电脑，速度慢，问题是我根本就没有U盘，或者文件在一台U盘无法工作阿里云服务器。所以我这里给出的解决方案是Python内置的HTTP服务器，优点是*nix都自带了python，所需不需要安装任何依赖。即便是widnows，安装python也非常的简单。同事让我发个什么文件给他，我都懒得发，都是把这个进程打开，让他自己下载。&#xA;python 2.x&#xA;// 默认是8000端口 python -m SimpleHTTPServer // 设置为80端口 python -m SimpleHTTPServer 80 [deploy@baochai ~]$ python -m SimpleHTTPServer Serving HTTP on 0.0.0.0 port 8000 ... 192.168.1.46 - - [25/May/2018 09:11:50] code 501, message Unsupported method (&amp;#39;OPTIONS&amp;#39;) 192.168.1.46 - - [25/May/2018 09:11:50] &amp;#34;OPTIONS / HTTP/1.1&amp;#34; 501 - 192.168.1.46 - - [25/May/2018 09:12:53] &amp;#34;GET / HTTP/1.1&amp;#34; 200 - 192.168.1.46 - - [25/May/2018 09:12:54] code 404, message File not found 192.168.1.46 - - [25/May/2018 09:12:54] &amp;#34;GET /favicon.</description>
    </item>
    <item>
      <title>终端文件传输神器rz与sz</title>
      <link>http://localhost:1313/posts/2018/20180524-1/</link>
      <pubDate>Thu, 24 May 2018 15:10:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20180524-1/</guid>
      <description>简介 rz和sz是目前为止我看到过的最简单的终端文件命令，他不止操作简单，功能也非常简单：当前桌面系统与当前终端所在服务器传输文件。也就是说如果你通过ssh跳转了多个服务器，rz和sh也是能够正常工作的，这一点就绕过了堡垒机导致不方便传输文件的问题,手动运维的时候，这个功能简直不要太好用了。&#xA;安装 这里介绍一下源码安装的方法。目前最新版本的源码是lrzsz-0.12.20.tar.gz,使用wget下载源码然后编译安装：&#xA;# 下载源码 wget http://www.ohse.de/uwe/releases/lrzsz-0.12.20.tar.gz # 解压源码 tar -xf lrzsz-0.12.20.tar.gz # 安装到/root/soft/fuck目录 cd lrzsz-0.12.20 ./configure --prefix=/root/soft/fuck make install 这样就安装好了，买一送一，还送了装了别的工具，可以探索一下。&#xA;[root@iz2zefvnzjphkalt990sg0z bin]# pwd /root/soft/fuck/bin [root@iz2zefvnzjphkalt990sg0z bin]# ll 总用量 1416 -rwxr-xr-x 3 root root 233624 5月 24 15:38 lrb -rwxr-xr-x 3 root root 233624 5月 24 15:38 lrx -rwxr-xr-x 3 root root 233624 5月 24 15:38 lrz -rwxr-xr-x 3 root root 244536 5月 24 15:38 lsb -rwxr-xr-x 3 root root 244536 5月 24 15:38 lsx -rwxr-xr-x 3 root root 244536 5月 24 15:38 lsz [root@iz2zefvnzjphkalt990sg0z bin]# 这里的命令都前置了 &amp;ldquo;l&amp;quot;这个字符，不知道是啥含义。总之：</description>
    </item>
    <item>
      <title>从一次救火想到问题</title>
      <link>http://localhost:1313/posts/2018/20180524/</link>
      <pubDate>Thu, 24 May 2018 08:55:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20180524/</guid>
      <description>写在前面的话:&#xA;火烧大了，总会嫌水不够用。今天机房网络出现了问题，导致许多go服务从zk上断开了，因为网络断开，这些程序在尝试重新连接一定次数后主动退出了。开发人员需要到部署系统重启这些服务。这个时候部署系统也无法工作了，导致服务全部无法重启，大家只能干瞪眼。部署系统的前端能页面，后端api调用不通，原因机房的网络的问题。领导指示把后端服务迁移到网络正常的机器，因为当初api是直接ip连接的，没有使用域名，这个时候迁移后端服务，需要手动重新编译前端，手动部署前端(部署系统前端也是部署系统部署，部署系统无法工作，只能手动部署)，手动部署后端服务，手动修改新机器的ngix。。。。。。 大吉大利，赶在早高峰前网络恢复了，能够正常部署了，虽然我什么也没有干。。。，但是这次事故让我看到了一些问题。&#xA;内部服务是否应该使用ip访问 内部服务不应该用ip访问，目前公司内部服务知之间都是通过ip或者机器名字(本地host)项目调用，这回存在一些问题，新加了机器host忘记同步，机器改了名字，host忘记同步，或者有的同步了Host，有的没有，服务迁移会导致很多其他的服务不可用，需要一个一个手动更新调用地址,这过程麻烦，并且容易改错或者遗漏。&#xA;程序是否应该有手动hack的后门 一定需要。当服务运行起来了，我想查看服务的内部信息，修改服务的状态，绕过某些条件限制执行操作，这个时候怎么办。最常见的就是线上环境发现很难调试的bug，无法复现，这个时候就需要开启日志的debug，让开发人员能看到更多的调戏信息。Linux下给进程发送信号，控制进程完成相应的操作。linux切换到root权限，修改特权文件,之前特权操作。&#xA;自动化工具不能使用时候怎么办 明确自动化的过程，将自动过程(日志)记录下来，使开发人员能够按照这个流程来执行。比如自动化执行一条非常复杂的命令，那么就应该将这条命令及命令执行过程，执行结果都保存下来，无关人员应该能够通知日志知道程序作了什么，在哪里出错，以便在救火的时候能够手动hack。即使无法自动化，也要将手动档的难度降到最低。</description>
    </item>
    <item>
      <title>你可能不知道的shell快捷键</title>
      <link>http://localhost:1313/posts/2018/20180523/</link>
      <pubDate>Wed, 23 May 2018 09:13:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20180523/</guid>
      <description>这里记录一下我在工作中用到的一些shell快捷键，这些快捷键能够大大的提高你在终端下的工作效率。&#xA;ctrl + A 跳转到当前命令行的首部，比如我的命令行的第一个字符输入错误了，或者命令忘记加上sudo了，ctrl + A就能修改你的输入错误。 ctrl + E 跳转到当前命令行的尾部 ctrl + R 搜索历史命令，这个比fish的自动补全要强大很多 ctrl + P 回到上一条命， p -&amp;gt; pre ，对于没有上下键的键盘来说，这个快捷键简直就是神器 ctrl + L 清空当前的终端，这比手动输入clear要来的快(貌似在windows的cmd中也管用) ctrl + C 丢弃当前命令行输入,这个也非常好用，有时候我输入命令了，但是我并不想执行这条命令(可能会与复制命令冲突，需要修改终端快捷键) ctrl + B 向左移动光标 ctrl + F 向右移动光标 ctrl + K 从光标当前位置剪切到行尾 ctrl + W 从光标当前位置剪切，知道遇到第一个空格 ctrl + U 从光标当前位置剪切到行首 ctrl + Y 粘贴以上几个剪切命令的内容（不包括系统剪切板的内容） ctrl + H 向左删除一个字符 ctrl + D 向右删除一个字符 ctrl + T 交换光标左右两个字符的位置,如果光标在行尾，会交换前两个字符的位置 ctrl + M 或者 ctrl + J 功能和回车键一致（用处不大） </description>
    </item>
    <item>
      <title>linux中的/bin与/usr/bin</title>
      <link>http://localhost:1313/posts/2018/20180521/</link>
      <pubDate>Mon, 21 May 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20180521/</guid>
      <description>有一些开源项目在make构建的时候会调用一些shell脚本，我发现这些shell脚本的shebang有一些微妙之处：&#xA;/usr/bin/env bash /usr/bin/bash /bin/bash 第一种我就不讨论了，主要是后面两种，我老是傻傻的分不清，今天找了个时间，到服务器上一看,傻眼了。 阿里云机器的centos 7&#xA;[root@iz2zefvnzjphkalt990sg0z /]# uname -a Linux iz2zefvnzjphkalt990sg0z 3.10.0-693.2.2.el7.x86_64 #1 SMP Tue Sep 12 22:26:13 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux [root@iz2zefvnzjphkalt990sg0z /]# ll / 总用量 72 lrwxrwxrwx. 1 root root 7 10月 15 2017 bin -&amp;gt; usr/bin dr-xr-xr-x. 5 root root 4096 10月 15 2017 boot drwxr-xr-x 20 root root 3040 5月 14 18:09 dev drwxr-xr-x. 88 root root 12288 5月 21 12:46 etc drwxr-xr-x.</description>
    </item>
    <item>
      <title>林沛满的一句编程忠告</title>
      <link>http://localhost:1313/posts/2018/20180515/</link>
      <pubDate>Tue, 15 May 2018 15:41:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20180515/</guid>
      <description>写在前面的废话&#xA;今晚7:30 ，锤子科技发布会。作为一个锤粉，我已经迫不及待了。&#xA;最近在看林沛满的wireshark抓包系列书籍，写的非常好，我读到了里面一句话，觉得非常赞同。意思大概如下：&#xA;仰慕优秀的人， 追随优秀的人， 成为优秀的人。&#xA;这是一个程序员的三个境界，我现在的状态大概是：第一个阶段往第二个阶段走吧。</description>
    </item>
    <item>
      <title>ssh相关的若干技巧</title>
      <link>http://localhost:1313/posts/2018/20180514/</link>
      <pubDate>Mon, 14 May 2018 17:05:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20180514/</guid>
      <description>写在前面的废话。&#xA;明天就是5月15日了，锤子科技的新手机即将发布，现在这个手机已经用了一年半了，老化严重，我已经迫不及待要想换手机了。&#xA;ssh的基本操作 ssh分为ssh客户端和服务端，服务端的程序通常名字叫做sshd,服务端的配置文件一般都是/etc/ssh/sshd_config，可以配置大概有一下内容:&#xA;是否允许明码登录 是否允许远程主机登录 绑定端口号 进程id所在文件(通常不改) 是否保持长连接 是否允许端口转发 公钥所在文件 修改之后一般执行systemctl restart sshd 或者service restart sshd(这两个命令有什么区别，请自行google)重启就能更新配置，重启过程中当前的会话不会断开(自行思考为什么不会断开)。一下是几种常规的用法:&#xA;deploy登录39.106.10.228，默认端口22&#xA;// root 登录同理 ssh deploy@39.106.10.228 deploy登录39.106.10.228,远程端口8099&#xA;ssh -p 8099 deploy@39.106.10.228 当前用户登录39.106.10.228&#xA;ssh 39.106.10.228 ssh免密码登录 ssh免密码登录需要生产一对私钥和公钥&#xA;ssh-keygen -t rsa 将公钥复制远程服务端的 .ssh/authorized_keys 文件中(默认是这个文件，上面讲了，这个也是可以配置的),记得配置这个文件的权限，chmod u+600,登录使用ssh -i 指定私钥文件路径，如下:&#xA;ssh -p 33339 -i licong_simulate.rsa licong@211.100.49.107 复制公钥的时候可以使使用ssh-copy-id这个命令来copy，避免了手动在远处服务器上修改或者创建文件的麻烦&#xA;ssh-copy-id -i hack.pub root@hacking #输入密码就完事了 ssh设置默认秘钥文件和端口 本地的~/.ssh目录下面创建config文件，文件内容格式如下&#xA;Host aliyun Hostname Port 22 Username hellojukay IdentityFile ~/.ssh/myaliyun 这里指定登录远程ssh的端口是22，也可以修改成别的端口。这里同时指定登录aliyun这台机器的默认秘钥文件为~/.ssh/myaliyun。&#xA;使用ssh来进行内网穿透 ssh功能非常非常强大，和frp一样，它也能用来做内网穿透。什么是内网穿透呢，打个比方，就是我本地局域网内的一台机器能访问互联网，能够主动socket连接阿里云上的一台机器，但是因为nat的原因，阿里云上的那台机器不能主动连接我本机的机器。让局域网内的机器暴露在公网上，这个的操作就是内网穿透。比如你需要远程操作你家里的空调，小米电视机，这些都需要内网穿透。ssh内网穿透的命令如下:&#xA;ssh -fNR 7000:localhost:4000 root@aliyun 这样就把本地的4000端口暴露在aliyun的7000端口上了，访问aliyun:7000的流量会被导入到内网机器的4000端口。</description>
    </item>
    <item>
      <title>asciinema记录你的终端操作</title>
      <link>http://localhost:1313/posts/2018/20180511/</link>
      <pubDate>Fri, 11 May 2018 15:19:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20180511/</guid>
      <description>在github上浏览项目的时候，看到 How to use it 是个录屏播放的动画，我觉得很炫酷，调研了下，其实他就是用asciinema这个工具生成的。它的项目地址是asciinema&#xA;mac直接可以通过brew 来安装。&#xA;brew install asciinema centos使用yum安装&#xA;yum install -y asciinema 这样就安装好了客户端了。一下是这个软件的使用方法:&#xA;jukay@mac-pro ~/C/W/blog&amp;gt; asciinema -h 367ms  五 5/11 15:23:45 2018 usage: asciinema [-h] [--version] {rec,play,cat,upload,auth} ... Record and share your terminal sessions, the right way. positional arguments: {rec,play,cat,upload,auth} rec Record terminal session play Replay terminal session cat Print full output of terminal session upload Upload locally saved terminal session to asciinema.org auth Manage recordings on asciinema.</description>
    </item>
    <item>
      <title>源码安装Python</title>
      <link>http://localhost:1313/posts/2018/20180510-1/</link>
      <pubDate>Thu, 10 May 2018 21:57:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20180510-1/</guid>
      <description>&amp;amp;bnsp; 今天同事向我抱怨，服务上的python版本太低了，他想把python版本升级到2.7.10，但是他没有root权限，使用yum更新python是需要root权限。求人不如求自己,所以自己动手，我告诉它用源码安装，它说源码安装以后会覆盖当前的默认python,我告诉它，可以单独源码安装python，不需要覆盖默认的Python，可以两个版本并存。这里记录一下安装的过程，这里我们以安装Python 3.4为例子。&#xA;下载Python-3.4.0a4.tar.xz 解压 tar -xvf Python-3.4.0a4.tar.xz 生成makefile文件,这里我们设置python安装到 /home/hellojukay/Data/Bin/python这个目录中 # 这不操作可能需要半分钟左右 ./configure --prefix=/home/hellojukay/Data/Bin/python/ 生成了Makefile文件，我们来编译python # 这里时间也会比较长，C、C++语言编译大型项目都比较慢,这个是个梗了 hellojukay@deepin:~/Data/Bin/Python-3.4.0a4$ make 安装编译好的python到之前设置的目录。 hellojukay@deepin:~/Data/Bin/Python-3.4.0a4$ make install 这里我们已经安装好了，可以到对应目录看一下。&#xA;hellojukay@deepin:~/Data/Bin/python$ ll 总用量 24 drwxr-sr-x 6 hellojukay hellojukay 4096 5月 10 22:17 . drwxr-sr-x 8 hellojukay hellojukay 4096 5月 10 22:11 .. drwxr-sr-x 2 hellojukay hellojukay 4096 5月 10 22:17 bin drwxr-sr-x 3 hellojukay hellojukay 4096 5月 10 22:17 include drwxr-sr-x 4 hellojukay hellojukay 4096 5月 10 22:17 lib drwxr-sr-x 3 hellojukay hellojukay 4096 5月 10 22:17 share hellojukay@deepin:~/Data/Bin/python$ 把bin目录加入到path中，我们就能正常使用了。</description>
    </item>
    <item>
      <title>一段有意思的话</title>
      <link>http://localhost:1313/posts/2018/20180510/</link>
      <pubDate>Thu, 10 May 2018 10:07:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20180510/</guid>
      <description> 今天看书看到一句很有意思的话，我个人觉得不无道理。这里粘贴出来，勉力自己。在我看来，良好的计算机科学素养，求知欲望，动手能力，解决问题的能力，这些都算是上乘的武功。这些武功都是难以修炼，需要耗费时日，一旦掌握，所向霹雳。 </description>
    </item>
    <item>
      <title>vscode插件系列（shellcheck）</title>
      <link>http://localhost:1313/posts/2018/20180508/</link>
      <pubDate>Tue, 08 May 2018 20:42:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20180508/</guid>
      <description>shellcheck简介 不知道什么时候开始，我已经从一个开发变成了一个半开发半运维的程序员了，在我的工作中，运维和开发同等的重要。编写shell脚本和编写golang,java代码也是同样的多。通常我使用vscode来编写shell脚本，除了java，我一切的代码编写工作都是使用vscode编辑器完成的。所以这里介绍一款shell语法检查的lint工具，shellcheck类似于jslint或者tslint这类的工具。如果你不希望你的shell脚本中不小心混入了sudo rm -rf / ,你就应该使用shellcheck, shellcheck的官网地址是:&#xA;https://www.shellcheck.net 打开官网以后,你可以在文本编辑窗口输入你的shell脚本，如果你代码有不恰当的地方，你会收到提示。&#xA;插件安装 在vscode的插件搜索框输入shell，你就能搜索到shellcheck了，它的图标大概是下面这个样子: shellcheck这个插件需要安装shellcheck这个命令行工具,我们可以在github上找到这个项目的仓库:&#xA;https://github.com/koalaman/shellchecks 下面是这个软件在各种操作系统下的安装方法:&#xA;max osx&#xA;brew install shellcheck FreeBSD&#xA;pkg install hs-ShellCheck openSUSE&#xA;zypper in ShellCheck Arch Linux&#xA;pacman -S shellcheck Debian&#xA;apt-get install shellcheck CentOS&#xA;yum -y install epel-release yum install ShellChecks 这里安装完了shellcheck以后，我们再为vscode安装shellcheck插件就能生效了，如果是安装shellcheck检查，插件是不生效的。这里提一句，shellcheck命令是可以单独使用的，具体使用方式如下:&#xA;正在处理用于 man-db (2.7.6.1-2) 的触发器 ... hellojukay@deepin:~/Data/Code/Web/blog$ shellcheck No files specified. Usage: shellcheck [OPTIONS...] FILES... -e CODE1,CODE2.. --exclude=CODE1,CODE2.. exclude types of warnings -f FORMAT --format=FORMAT output format -C[WHEN] --color[=WHEN] Use color (auto, always, never) -s SHELLNAME --shell=SHELLNAME Specify dialect (sh,bash,dash,ksh) -x --external-sources Allow &amp;#39;source&amp;#39; outside of FILES.</description>
    </item>
    <item>
      <title>git hooks</title>
      <link>http://localhost:1313/posts/2018/20180507/</link>
      <pubDate>Mon, 07 May 2018 21:47:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20180507/</guid>
      <description>今天在看jaeger的前端代码的时候，发现本地git commit之后会自动执行前端的测试用例。然后知道git本地有hooks这个文件夹，里面可以添加好几种hook，只要按照制定的文件写，并且加上可以执行文件，加上对于的SheBang，就能执行hook。在本地git仓库的.git/hooks/文件中，我编写了一个hook文件，pre-push，这个是在push代码之前触发的。&#xA;#!/bin/sh echo &amp;#34;我要push代码了&amp;#34; 编写了这个文件以后，记得chmod u+x pre-push，让当前用户具有执行这个脚本的权限，注意：这里写的是bash脚本，但是它并没有约束只能使用bash，你也可以使用Python或者perl，awk,node&amp;hellip;等等语言来编写，只要加上对于的SheBang就可以。&#xA;hellojukay@deepin:~/Data/Code/Linux$ git push origin master 我要push代码了 对象计数中: 3, 完成. Delta compression using up to 8 threads. 压缩对象中: 100% (2/2), 完成. 写入对象中: 100% (3/3), 258 bytes | 0 bytes/s, 完成. Total 3 (delta 1), reused 0 (delta 0) remote: Resolving deltas: 100% (1/1), completed with 1 local object. To github.com:hellojukay/linux-c.git 7be5e01..d0a1a40 master -&amp;gt; master push 一下代码，我的hook触发了。其他类型的hook也是同意的道理，这里也就不在赘述了。&#xA;2020年10月27日补充 git 还有 2 种配置全局 hook 目录的方式:</description>
    </item>
    <item>
      <title>bash中函数的使用方法</title>
      <link>http://localhost:1313/posts/2018/20180506/</link>
      <pubDate>Sun, 06 May 2018 15:03:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20180506/</guid>
      <description>函数定义 bash是shell的一种，这篇博客主要是讲关于bash中函数的定义和使用，bash的函数可以定义在.bashrc中，也可以定义在/etc/profile中，定义完了以后source一下就能直接在当前登录的shell中调用,比如我在.bashrc中定义了cool函数：&#xA;function cool(){ echo &amp;#34;$1，你就是最帅的那个人!&amp;#34; } 然后 source .bashrc，就可以在命令中使用这个函数了&#xA;hellojukay@deepin:~$ cool hellojukay hellojukay，你就是最帅的那个人! hellojukay@deepin:~$ bash还可以在命令行中直接定义:&#xA;:() { :|:&amp;amp; };: 上面这行代码就是非常著名的bash炸，它定义了一个名字叫 ： 的函数，这个函数的函数提就是地柜的调用自己，这样代码除了定了这个函数，它同事也调用这个自己的定义的这个函数，所以当你执行这行命令的时候，你可能很快就会因为内存耗尽而死机。&#xA;一个有用的例子 再给一个有用的例子，我们进场需要将一个自定义的目录添加到当前用户的path环境中，比如安装jdk的时候，就需要把java和javac的可执行文件加入到path中，那么我们就可以写一个append函数，将给定的路径加入到path中,比如：&#xA;function append(){ export PATH=$PATH:$1 } export GOROOT=/home/hellojukay/Data/Bin/go export GOPATH=/home/hellojukay/Data/Code/Go export NODEHOME=/home/hellojukay/Data/Bin/node append $GOPATH/bin append $GOROOT/bin append $NODEHOME/bin 我就是这样安装go和node的，这里还有一个技巧需要提及一下。&#xA;/home/hellojukay/Data/Bin/go 这是我安装go的目录，但是它并不是一个真正的目录，而是一个link，指向的是go1.10的安装目录，这样做的好处是，下次我需要安装别的版本的go，我不需要卸载当前版本的golang，我只需要修改一下当前这个link执行的文件夹，这样就可以同事安装多个版本，并且随便切换版本了。&#xA;其他技巧 在命令行中调用bash函数和调用其他命令没有任何区别。那么我如何知道当前我使用的这个命令是一个bash function还是一个可执行文件呢,使用type命令就能做到.&#xA;hellojukay@deepin:~$ type cool cool 是函数 cool () { echo &amp;#34;$1，你就是最帅的那个人!&amp;#34; } 这里显示出来了cool是一个函数，并且还展示出了cool这个函数的源码.&#xA;hellojukay@deepin:~$ type cd cd 是 shell 内建 hellojukay@deepin:~$ hellojukay@deepin:~$ type ls ls 是 `ls --color=auto&amp;#39; 的别名 hellojukay@deepin:~$ </description>
    </item>
    <item>
      <title>github pages支持自定义域名https访问了</title>
      <link>http://localhost:1313/posts/2018/20180505/</link>
      <pubDate>Sat, 05 May 2018 19:17:23 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20180505/</guid>
      <description>这两天github的官方blog宣布：github pages支持定义域名通过https访问了，不需要通过第三方服务就能使自己的博客用上https了。我想起来我的博客好像一直都是http，不支持https，自己的博客也没有别人看，都是自己记录自己的代码和生活，也就没有去折腾这个。这回github官方都自带支持了，我就按着教程配置了，现在自己的博客已经标记上安全的小绿锁了。具体操作非常简单：&#xA;settings-&amp;gt;github pages-&amp;gt; Enforce HTTPS ping 一下的你github博客的地址，得到ip 到你的域名解析商配置你的自定域名的解析，配置为A类地址解析为上面的到的那个ip setting-&amp;gt;github pages-&amp;gt;custom domain 这里给出具体教程的地址:&#xA;https://help.github.com/articles/securing-your-github-pages-site-with-https/ </description>
    </item>
    <item>
      <title>/proc/pid文件夹解析</title>
      <link>http://localhost:1313/posts/2018/20180503/</link>
      <pubDate>Thu, 03 May 2018 14:42:07 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20180503/</guid>
      <description>linux内核提供了用户访问内核数据的接口，就是/proc这个文件夹。这个文件夹中每一个数字组成的文件夹就是一个进程的信息，文件夹的数组是一个进程的pid，这篇文章是记录/pro/[pid]这个文件夹里面各个文件的调研结果，就是如何或程序在运行过程中的各项数据指标。/pro/[pid]这个文件夹里面一般有43个文件，每个文件或者文件夹都记录了不同的信息。&#xA;[root@baochai /proc/1449]# ll total 0 dr-xr-xr-x 2 root root 0 May 3 14:58 attr -rw-r--r-- 1 root root 0 May 3 14:58 autogroup -r-------- 1 root root 0 May 3 14:58 auxv -r--r--r-- 1 root root 0 May 3 14:58 cgroup --w------- 1 root root 0 May 3 14:58 clear_refs -r--r--r-- 1 root root 0 May 3 11:40 cmdline -rw-r--r-- 1 root root 0 May 3 14:58 comm #命令行程序的名字 -rw-r--r-- 1 root root 0 May 3 14:58 coredump_filter -r--r--r-- 1 root root 0 May 3 14:58 cpuset lrwxrwxrwx 1 root root 0 May 3 14:58 cwd -&amp;gt; /opt/gitlab/sv/gitaly # 当前进程的工作空间，可以理解为启动目录 -r-------- 1 root root 0 May 3 04:50 environ 这里文件里面存的是当前进程的环境变量 lrwxrwxrwx 1 root root 0 May 3 01:01 exe -&amp;gt; /opt/gitlab/embedded/bin/runsv # 当前进程可执行文件的绝对路径 dr-x------ 2 root root 0 May 3 04:51 fd dr-x------ 2 root root 0 May 3 14:58 fdinfo -r-------- 1 root root 0 May 3 14:58 io -rw------- 1 root root 0 May 3 14:58 limits -rw-r--r-- 1 root root 0 May 3 14:58 loginuid -r--r--r-- 1 root root 0 May 3 14:58 maps -rw------- 1 root root 0 May 3 14:58 mem -r--r--r-- 1 root root 0 May 3 14:58 mountinfo -r--r--r-- 1 root root 0 May 3 14:58 mounts # 当前进程能观察到的挂载信息 -r-------- 1 root root 0 May 3 14:58 mountstats dr-xr-xr-x 4 root root 0 May 3 14:58 net dr-x--x--x 2 root root 0 May 3 14:58 ns -r--r--r-- 1 root root 0 May 3 14:58 numa_maps -rw-r--r-- 1 root root 0 May 3 14:58 oom_adj -r--r--r-- 1 root root 0 May 3 14:58 oom_score -rw-r--r-- 1 root root 0 May 3 14:58 oom_score_adj -r--r--r-- 1 root root 0 May 3 14:58 pagemap -r--r--r-- 1 root root 0 May 3 14:58 personality lrwxrwxrwx 1 root root 0 May 3 14:58 root -&amp;gt; / -rw-r--r-- 1 root root 0 May 3 14:58 sched -r--r--r-- 1 root root 0 May 3 14:58 schedstat -r--r--r-- 1 root root 0 May 3 14:58 sessionid -r--r--r-- 1 root root 0 May 3 14:58 smaps -r--r--r-- 1 root root 0 May 3 14:58 stack -r--r--r-- 1 root root 0 May 3 11:20 stat -r--r--r-- 1 root root 0 May 3 10:44 statm -r--r--r-- 1 root root 0 May 3 11:20 status -r--r--r-- 1 root root 0 May 3 14:58 syscall dr-xr-xr-x 3 root root 0 May 3 14:58 task -r--r--r-- 1 root root 0 May 3 14:58 wchan [root@baochai /proc/1449]# /proc/[pid]/cmdline 一般情况下，这是一个只读的文件，只有当前该进程是僵尸进程的时候，你能够修改这个文件。读取这个文件返回的是当前进程的完成的命令行，如果当前进程是僵尸进程，那么读取这个文件会直接返回空字符串。</description>
    </item>
    <item>
      <title>deepin链接openvpn</title>
      <link>http://localhost:1313/posts/2018/20180502/</link>
      <pubDate>Wed, 02 May 2018 21:51:07 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20180502/</guid>
      <description>之前一直在mac上使用openvpn，这回把自己家里的deepin也配置好openvpn，这样在家里就能直接访问公司的网络了，这里记录一下配置的步骤，以便以后不记得了可以回来再看看。deepin的设置里面是默认就有openvpn的选项的，所以不需要我们另外安装了。 这里选择导入,就是导入那个ovpn结尾的文件。 然后进入配置界面，我选填上账户和密码就可以了。 这里有一点需要注意的是，需要勾选上“仅用于相对应的网络上的资源&amp;quot;,不然你是无法访问公网的。</description>
    </item>
    <item>
      <title>deepin更新公钥问题解决方案</title>
      <link>http://localhost:1313/posts/2018/20180501-1/</link>
      <pubDate>Tue, 01 May 2018 20:27:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20180501-1/</guid>
      <description>操作系统从之前的arch换成deepin了，原因是arch不够稳定，滚着滚着就出现各种问题了。换成deepin之后我首选需要更新一下当前的系统，保准包安全的包比较新，sudo apt updte&#xA;hellojukay@deepin:/etc/apt/sources.list.d$ sudo apt update gpg: key EFDC8610341D9410: public key &amp;#34;Spotify Public Repository Signing Key &amp;lt;tux@spotify.com&amp;gt;&amp;#34; imported │获取:1 http://packages.deepin.com/deepin panda InRelease [11.4 kB] gpg: Total number processed: 1 │获取:2 http://repository.spotify.com stable InRelease [3,302 B] gpg: imported: 1 │错误:2 http://repository.spotify.com stable InRelease hellojukay@deepin:/dev/fd$ sudo apt update │ 由于没有公钥，无法验证下列签名： NO_PUBKEY EFDC8610341D9410 获取:1 http://packages.deepin.com/deepin panda InRelease [11.4 kB] │正在读取软件包列表... 完成 获取:2 http://repository.spotify.com stable InRelease [3,302 B] │W: GPG 错误：http://repository.spotify.com stable InRelease: 由于没有公钥，无法验证下列签名： NO_PUBKEY EF 获取:3 http://repository.</description>
    </item>
    <item>
      <title>C语言的sizeof操作符</title>
      <link>http://localhost:1313/posts/2018/20180501/</link>
      <pubDate>Tue, 01 May 2018 10:08:10 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20180501/</guid>
      <description>复习一下linux c编程，写了个hello world,发现linux c的api已经被我忘记的差不多了，平时都在用golang写代码，只是知道后面有系统调用这回事情，但是自己操作起linux C的编程api起来好像不是那么回事了，这里写一片博客记录一下。&#xA;#include &amp;lt;unistd.h&amp;gt; #include &amp;lt;stdio.h&amp;gt; int main(){ int fd = dup(1); char* buffer = &amp;#34;Hello World\n&amp;#34;; write(fd,buffer,sizeof(buffer)); return 0; } hellojukay@deepin:~/Data/Code/Linux/dup$ gcc dup.c hellojukay@deepin:~/Data/Code/Linux/dup$ ./a.out Hello Wohellojukay@deepin:~/Data/Code/Linux/dup$ 这里并没有完整的输出Hello World这个字符串。我们来看在write这个系统调用返回的是什么。&#xA;#include &amp;lt;unistd.h&amp;gt; #include &amp;lt;stdio.h&amp;gt; int main(){ int fd = dup(1); char* buffer = &amp;#34;Hello World\n&amp;#34;; int len = sizeof(buffer); int count = write(fd,buffer,sizeof(buffer)); printf(&amp;#34;%d chars wirte %d to stdout&amp;#34;,len,count); return 0; } hellojukay@deepin:~/Data/Code/Linux/dup$ gcc dup.c hellojukay@deepin:~/Data/Code/Linux/dup$ ./a.out Hello Wo8 chars wirte 8 to stdouthellojukay@deepin:~/Data/Code/Linux/dup$ 这里打印出来了，8个字符全部都被写入了,等等，&amp;ldquo;Hello World&amp;quot;这个字符串怎么会只有8个字符，好像不对,是我蠢了，这个sizeof是编译器编译器期间决定的，他返回的&amp;quot;Hello World&amp;quot;这个字符串指针变量占用的内存的大小，而不是指代字符串本身所用的内存，所以这里应该使用strlen函数来获取字符串的长度，蠢了蠢了。</description>
    </item>
    <item>
      <title>docker访问外部局域网</title>
      <link>http://localhost:1313/posts/2018/20180428/</link>
      <pubDate>Sat, 28 Apr 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20180428/</guid>
      <description>从gitlab的runner界面来看，跑在docker里面的runner从来没有连接过gitlab服务，所以我怀疑他们之间的网络是不通的 在k8s上找到对应的runner容器&#xA;[root@shawujing ~]# docker ps | grep runner fd3e106f36d5 docker.io/gitlab/gitlab-runner@sha256:9b1e53a91fc8914c934b9eacf93365c7af97d97514c71b1825f677c8ee2a2369 &amp;#34;/bin/bash /script...&amp;#34; About an hour ago Up About an hour k8s_runner-gitlab-runner_runner-gitlab-runner-fddfc9d7c-fxtbl_gitlab-managed-apps_73a2f2a4-4a88-11e8-9128-782bcb57680f_0 a1c5b8f86d7c k8s.gcr.io/pause-amd64:3.1 &amp;#34;/pause&amp;#34; About an hour ago Up About an hour k8s_POD_runner-gitlab-runner-fddfc9d7c-fxtbl_gitlab-managed-apps_73a2f2a4-4a88-11e8-9128-782bcb57680f_0 [root@shawujing ~]# 进入容器里面看一下，是否能够ping我们的gitlab服务器&#xA;docker exec -it fd3e106f36d5 /bin/bash bash-4.4# ping baochai ping: bad address &amp;#39;baochai&amp;#39; bash-4.4# 这里他不认识baochai这个域名，我们手动改一下这个容器的/etc/hosts文件，加入baochai的域名解析&#xA;bash-4.4# cat /etc/hosts # Kubernetes-managed hosts file. 127.0.0.1&#x9;localhost ::1&#x9;localhost ip6-localhost ip6-loopback fe00::0&#x9;ip6-localnet fe00::0&#x9;ip6-mcastprefix fe00::1&#x9;ip6-allnodes fe00::2&#x9;ip6-allrouters 192.</description>
    </item>
    <item>
      <title>记一次抓包经历</title>
      <link>http://localhost:1313/posts/2018/20180425/</link>
      <pubDate>Wed, 25 Apr 2018 21:58:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20180425/</guid>
      <description>这是昨天发生的事情，我本机在使用仿真环境部署的时候，浏览器会概率性的卡死。同事部署仿真环境百分百的卡死。top命令查看进程的情况，Chrome疯狂吃内存。同样的代码，测试环境和仿真环境都没有问题，就偏偏仿真环境有问题。因为在部署的时候，服务端会通过浏览器实时传输文件日志到浏览器，偏偏卡死的时候在Chrome终端是看不到传输数据的，之打印了一条日志，然后卡死。于是我怀疑是不是仿真环境机器的网络有问题，因为之前就是机器问题才迁移项目到当前这台机器的。所以我想通过抓包来看到到底发生额生么。 看到很多个tcp的zerowindow信号，zerowindow异味着通知tcp连接通知对方暂时不要发送数据了，本机因为某些原因无法接手更多的数据。本机内存耗尽，tcp无法接受更多的数据，发送了我zerowindow信号。继续抓包 这里发送了很多同样的数据，如果我不终止当前的chrome,chrome会继续接受这些数据，然后连接字符串渲染在div中，连接字符过程中会产生许多的临时对象，占用大量的内存，并且占用内存中连续的内存地址，当cpu无法分配连续分配大块连续内存的时候，他清理内存碎片，攒出大块的内存，分配给程序。这个过程往往会很久，这里就会导致Chrome无响应，卡死。&#xA;为什么只有仿真环境会卡死呢，原因是迁移部署的仿真环境地址，从wuyong迁移到lvfang，而lvfang这台的机器运维并没有给他安装Ansible，这就导致Ansible执行报错. 追根到底，找到了这几行代码，这里没处理ReadLine失败的情况，所以Ansible执行失败了，读取日志ReadLine失败，但是错误并不是EOF,而是其他的错误，就会导致死循环向前端写数据，导致前端卡死。&#xA;这里为什么我是概率性的卡死，我的同事100%的卡死呢，原因是前端js文件有缓存，我在清空Chrome浏览器缓存的时候没有清空干净 这里也要勾选上，不然可能会存在js文件缓存的情况。说道这里，我真的想把服务器的nginx设置为禁止前端缓存，已经不是第一次了，只是之前的问题没有这么绕。</description>
    </item>
    <item>
      <title>golang项目的构建</title>
      <link>http://localhost:1313/posts/2018/20180403/</link>
      <pubDate>Mon, 02 Apr 2018 15:43:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20180403/</guid>
      <description>现在用golang开发项目,项目结构一般都是这样&#xA;. ├── README.md ├── ansible ├── app.yaml ├── conf ├── deploy ├── glide.lock ├── glide.yaml ├── main.go ├── models ├── operate ├── plat_deploy ├── restart ├── rollback ├── router ├── utils └── vendor 10 directories, 6 files 最外面一个main文件，这程序的入口，要执行构建操作都是直接到当前的目录下面直接运行go install，但是这样做有个缺陷，就是你的golang项目必须放在GOPATH下面的正确的位置，直接导致构建不成功的例子，目前较好的方法还是是用make结合go install的方法来执行你的构建，在Makefile里面设置好的你的构建需要好的条件，然后直接Make install就能构建成功，或者Make test完成测试。这样也更加有利于自动化。</description>
    </item>
    <item>
      <title>不为人知的echo黑魔法</title>
      <link>http://localhost:1313/posts/2018/20180402/</link>
      <pubDate>Mon, 02 Apr 2018 15:43:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20180402/</guid>
      <description>今天干了件大事：把测试环境的机器搞死机了。事情的发展顺序是这样的：有人向我反馈jenkins编译速度特别慢，我打开jenkins一看，好多任务都没有执行完，打开jenkins的过程是非常缓慢，想到早上仿真环境网络的问题，我下意识的认为是今天的网络太慢了。我登录baochai试一下，发现登录服务竟然需要10秒钟之久，ls回显也很慢。这个时候在钉钉上联系运维的同学，我说baochai的网络特别慢，运维的同学去机房找原因，半小时未果，突然钉钉里有测试的同学发了一条消息，说baochai的cpu占用非常高，这个时候运维的同学在群里发了一张截图，说是有条bash命令占用了83G的内存，服务器濒临司机。于是赶紧kill了这个进程。一切恢复平静。大家都在讨论那条命令是在干什么，他们当时没有看就Kill了。后来我想起来了，我上午在服务器上执行了一条echo命令，当时卡死了，ctrl+c也无法退出，于是我关闭了当前的iterm2会话窗口，没有当一回事，我没有想到我退出登录以后echo经常竟然没有自动退出，并且造成了这么大的影响。&#xA;echo [{&amp;#34;id&amp;#34;:188,&amp;#34;cat&amp;#34;:&amp;#34;java&amp;#34;,&amp;#34;user&amp;#34;:0,&amp;#34;name&amp;#34;:&amp;#34;websocket-thrift-service&amp;#34;,&amp;#34;code&amp;#34;:&amp;#34;websocket-thrift-service&amp;#34;,&amp;#34;jdk&amp;#34;:&amp;#34;1.8&amp;#34;,&amp;#34;create_time&amp;#34;:&amp;#34;2018-02-02 09:52:23&amp;#34;,&amp;#34;update_time&amp;#34;:&amp;#34;2018-03-30 18:03:39&amp;#34;},{&amp;#34;id&amp;#34;:117,&amp;#34;cat&amp;#34;:&amp;#34;go&amp;#34;,&amp;#34;user&amp;#34;:0,&amp;#34;name&amp;#34;:&amp;#34;日志系统agent&amp;#34;,&amp;#34;code&amp;#34;:&amp;#34;plat-log-agent&amp;#34;,&amp;#34;jdk&amp;#34;:&amp;#34;&amp;#34;,&amp;#34;create_time&amp;#34;:&amp;#34;2017-09-28 19:22:32&amp;#34;,&amp;#34;update_time&amp;#34;:&amp;#34;2018-03-21 18:02:37&amp;#34;},{&amp;#34;id&amp;#34;:204,&amp;#34;cat&amp;#34;:&amp;#34;go&amp;#34;,&amp;#34;user&amp;#34;:0,&amp;#34;name&amp;#34;:&amp;#34;jaeger-agent&amp;#34;,&amp;#34;code&amp;#34;:&amp;#34;jaeger-agent&amp;#34;,&amp;#34;jdk&amp;#34;:&amp;#34;&amp;#34;,&amp;#34;create_time&amp;#34;:&amp;#34;2018-03-27 14:01:21&amp;#34;,&amp;#34;update_time&amp;#34;:&amp;#34;2018-03-27 14:01:21&amp;#34;},{&amp;#34;id&amp;#34;:120,&amp;#34;cat&amp;#34;:&amp;#34;tomcat&amp;#34;,&amp;#34;user&amp;#34;:0,&amp;#34;name&amp;#34;:&amp;#34;deploy_tmcat_test&amp;#34;,&amp;#34;code&amp;#34;:&amp;#34;deploy_tomcat_test&amp;#34;,&amp;#34;jdk&amp;#34;:&amp;#34;1.7&amp;#34;,&amp;#34;create_time&amp;#34;:&amp;#34;2017-09-29 16:16:16&amp;#34;,&amp;#34;update_time&amp;#34;:&amp;#34;2017-09-29 20:19:18&amp;#34;},{&amp;#34;id&amp;#34;:102,&amp;#34;cat&amp;#34;:&amp;#34;java&amp;#34;,&amp;#34;user&amp;#34;:0,&amp;#34;name&amp;#34;:&amp;#34;transferhook-service&amp;#34;,&amp;#34;code&amp;#34;:&amp;#34;transferhook-service&amp;#34;,&amp;#34;jdk&amp;#34;:&amp;#34;1.7&amp;#34;,&amp;#34;create_time&amp;#34;:&amp;#34;2017-09-28 19:22:31&amp;#34;,&amp;#34;update_time&amp;#34;:&amp;#34;2018-02-08 09:58:36&amp;#34;},{&amp;#34;id&amp;#34;:183,&amp;#34;cat&amp;#34;:&amp;#34;go&amp;#34;,&amp;#34;user&amp;#34;:0,&amp;#34;name&amp;#34;:&amp;#34;plat-log-agent-new&amp;#34;,&amp;#34;code&amp;#34;:&amp;#34;plat-log-agent-new&amp;#34;,&amp;#34;jdk&amp;#34;:&amp;#34;&amp;#34;,&amp;#34;create_time&amp;#34;:&amp;#34;2018-01-30 19:08:50&amp;#34;,&amp;#34;update_time&amp;#34;:&amp;#34;2018-01-30 19:56:20&amp;#34;},{&amp;#34;id&amp;#34;:66,&amp;#34;cat&amp;#34;:&amp;#34;java&amp;#34;,&amp;#34;user&amp;#34;:0,&amp;#34;name&amp;#34;:&amp;#34;carbooking_queue&amp;#34;,&amp;#34;code&amp;#34;:&amp;#34;carbooking_queue&amp;#34;,&amp;#34;jdk&amp;#34;:&amp;#34;1.7&amp;#34;,&amp;#34;create_time&amp;#34;:&amp;#34;2017-09-28 19:22:30&amp;#34;,&amp;#34;update_time&amp;#34;:&amp;#34;2017-09-29 09:35:52&amp;#34;}] 在我看来这是条在普通不过的echo命令了，我的本意是重定向这条json到underscore，格式化这条json。没想到会造成服务器司机。这里的原因是没有给字符串加上引号，造成了自动的排列组合。他的原理如下：&#xA;&amp;#39;-&amp;gt;$ echo [{1,2,3},{a,b,c}] [1,a] [2,a] [3,a] [1,b] [2,b] [3,b] [1,c] [2,c] [3,c] </description>
    </item>
    <item>
      <title>archlinux开机自动挂载磁盘</title>
      <link>http://localhost:1313/posts/2018/20180401/</link>
      <pubDate>Wed, 28 Mar 2018 11:43:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20180401/</guid>
      <description>我的这台archlinux的主板上接了一个2TB的硬盘，每次开机启动他斗没有自动挂载上来，我总是在自己需要使用这硬盘的时候来手动挂载他，这样太不方便了，我想能不能在开机的时候自动来挂载这个块硬盘。解决这个问题的方法是有的，往/etc/fstab这个文件的后面加入的分区信息和挂载点&#xA;[hellojukay@archlinux ~]$ cat /etc/fstab # Static information about the filesystems. # See fstab(5) for details. # &amp;lt;file system&amp;gt; &amp;lt;dir&amp;gt; &amp;lt;type&amp;gt; &amp;lt;options&amp;gt; &amp;lt;dump&amp;gt; &amp;lt;pass&amp;gt; # /dev/sda3 UUID=e3a426e2-4713-4b33-ad6c-773bf144081c&#x9;/ ext4 rw,relatime,data=ordered&#x9;0 1 # /dev/sda1 UUID=1b43aa57-22fc-4af2-8a84-cd8f6e27e8f2&#x9;/boot ext4 rw,relatime,data=ordered&#x9;0 2 # /dev/sda5 UUID=2d6bde7f-b18c-44e1-8036-8ecdd93c13c1&#x9;/home ext4 rw,relatime,data=ordered&#x9;0 2 # /dev/sda2 UUID=6bbfba42-07ec-479a-b9fa-d3e89e94af9f&#x9;none swap defaults,pri=-2&#x9;0 0 这个需要知道的分区的UUID,使用blkid命令能看到分区的id，一下是我的挂载的情况&#xA;[hellojukay@archlinux ~]$ sudo lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 111.</description>
    </item>
    <item>
      <title>gitlab ci从入门到放弃</title>
      <link>http://localhost:1313/posts/2018/20180329/</link>
      <pubDate>Wed, 28 Mar 2018 11:43:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20180329/</guid>
      <description>我们组要做持续集成，需要调研gitlab的ci。这里来写一下记录下这个学习的过程。gitlab需要像github上那些开源项目一样，展示自己的编译情况和测试情况，就是build status badge icon,需要在README.md文件中加入markdown连接&#xA;![build](http://baochai:7201/plat/hello/badges/master/build.svg) ![coverage](http://baochai:7201/plat/hello/badges/master/coverage.svg) 然后在项目的主页就能看到下面的图标了 这个还是没有生成测试覆盖的服务，看到测试覆盖率.再看一下一个基本的.gitlab-ci.yml文件样子&#xA;variables: project_name: hello bin_name: sayhello before_script: - export GOPATH=/deployment/GoProjects - export GOROOT=/deployment/ci/go; - export PATH=$PATH:$GOROOT/bin; - echo $GOPATH stages: - test - pre - build - deploy # 调整目录结构 setenv: stage: pre script: - ls -al - rm -rf ${GOPATH}/src/github.com/hellojukay/${project_name} - mkdir -p ${GOPATH}/src/github.com/hellojukay/${project_name} - cp -rf ./* ${GOPATH}/src/github.com/hellojukay/${project_name} # 执行测试用例 test: stage: test script: - cd ${GOPATH}/src/github.com/hellojukay/${project_name} - go test -v -cover -race .</description>
    </item>
    <item>
      <title>gitlab从卸载到放弃</title>
      <link>http://localhost:1313/posts/2018/20180328/</link>
      <pubDate>Wed, 28 Mar 2018 11:43:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20180328/</guid>
      <description>最近要调用gitlab-ci，正好测试环境的huanggai这机器上，安装了gitlab，但是使用起来总有一些问题，应该安装时候的问题吧。决定重装gitlab,首先，我关闭gitlab服务&#xA;gitlab-ctl stop 但是执行关了这个命令以后，还是有一些gitlab的进程存在&#xA;[deploy@huanggai /opt/gitlab/sv/unicorn]$ ps aux | grep gitlab root 3499 0.0 0.0 11420 1296 ? Ss 12:34 0:00 /bin/sh /opt/gitlab/embedded/bin/gitlab-logrotate-wrapper root 11996 0.0 0.0 35516 3136 ? Ss 13:10 0:00 /opt/gitlab/embedded/sbin/nginx -p /var/opt/gitlab/nginx git 12016 0.0 0.0 11428 1376 ? Ss 13:10 0:00 /bin/bash /opt/gitlab/embedded/bin/gitlab-unicorn-wrapper deploy 12054 0.0 0.0 103416 888 pts/1 S+ 13:10 0:00 grep gitlab root 84470 0.0 0.0 4176 460 ? Ss 11:34 0:02 runsvdir -P /opt/gitlab/service log: to lock directory: /var/log/gitlab/redis-exporter: temporary failure?</description>
    </item>
    <item>
      <title>记一次服务部署失败</title>
      <link>http://localhost:1313/posts/2018/20180316/</link>
      <pubDate>Fri, 16 Mar 2018 21:28:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20180316/</guid>
      <description>最有golang服务部署一直失败，服务被启动起来以后，打印了两行启动日志，然后立马就自动退出了，没有panic日志，而且在老版本的部署系统上部署是没有这个问题的。而且吧部署系统的使用的命令行复制出来，直接在服务器上执行，进程也能正常启动，并且退出登录以后，程序也不会挂掉，所以我确认我的启动方式是没有问题的，之前那么多的golang服务启动也没有问题，后来下载代码下来看发现代码。这个golang服务监听了SIGHUP信号，收到这个号信号以后程序会调用os.Exit(1)自动退出，然后我用老版本的部署系统启动进程,手动给这个进程发送SIGHUP信号，果然程序自动退出了。于是我想起来了，通知相关的开发人员收到这个信号以后忽略掉。再次部署，一气呵成。事情还没有完，因为我想到了之前部署node服务的时候也发生了这样的问题，一直没有找到原因，不得已放弃nohup的形式，改用pm2来管理进程，所以我怀疑node是不是默认监听了SIGHUP型号，并且收到型号以后自动退出。于是我验证了下，手写了最简单的服务，手动启动，发送SIGHUP型号，果然程序退出了。那么手动忽略这个型号是不是就ok了呢&#xA;var http = require(&amp;#39;http&amp;#39;); var hostname = &amp;#39;127.0.0.1&amp;#39;; var port = 3000; var server = http.createServer(function(req, res) { res.statusCode = 200; res.setHeader(&amp;#39;Content-Type&amp;#39;, &amp;#39;text/html&amp;#39;); res.write(&amp;#39;&amp;lt;head&amp;gt;&amp;lt;meta charset=&amp;#34;utf-8&amp;#34;/&amp;gt;&amp;lt;/head&amp;gt;&amp;#39;); var htmlDiv = &amp;#39;&amp;lt;div style=&amp;#34;width: 200px;height: 200px;background-color: #f0f;&amp;#34;&amp;gt;div&amp;lt;/div&amp;gt;&amp;#39;; res.write(&amp;#39;&amp;lt;b&amp;gt;亲爱的，你慢慢飞，小心前面带刺的玫瑰...&amp;lt;/b&amp;gt;&amp;#39;); res.write(htmlDiv); res.end(&amp;#39;&amp;lt;h1&amp;gt;Hello world!&amp;lt;/h1&amp;gt;&amp;#39;); }); process.on(&amp;#39;SIGHUP&amp;#39;, (err) =&amp;gt; { console.info(err) }); server.listen(port, hostname, function() { console.log(&amp;#39;Server running at http://%s:%s&amp;#39;, hostname, port); }); jukay@localhost ~/C/W/blog(20.5)&amp;gt; lsof -i:3000 五 3/16 17:21:20 2018 COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME node 85016 jukay 13u IPv4 0xd088754a58137eaf 0t0 TCP localhost:hbci (LISTEN) jukay@localhost ~/C/W/blog(20.</description>
    </item>
    <item>
      <title>记一次&#34;hack&#34;公司ssh</title>
      <link>http://localhost:1313/posts/2018/20180310/</link>
      <pubDate>Sat, 10 Mar 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20180310/</guid>
      <description>今天总算解决了在家无法登录公司测试服务器的问题。因为不知道的什么原因，公司是不允许在外部网络登录测试服务，虽然有vpn，但是运维禁止了vpn登录ssh,要登录测试服务，必须要申请权限，而且每次登录最长只能保持15分钟，过期了有要再次登录。所以我想能不能自己想办法绕过这个坑，我试了下，到跳板机的连接是ping的同的，说明网络是没有问题。我要的做的只是监听一个端口，把这个端口的输入和输出都同步到跳板机的ssh端口就可以了，代码如下&#xA;https://github.com/hellojukay/ssh_proxy 登录到jenkins，部署，然后登录到部署系统，部署，本地连接完美登录成功。&#xA;jukay@MP ~/.ssh(18.9)&amp;gt; ssh -p 7013 -i licong_testing.rsa licong@huanggai 六 3/10 10:26:42 2018 key_load_public: invalid format Last login: Sat Mar 10 09:44:48 2018 from 192.168.1.197 [licong@xiangyun ~]$ 这行命令太长了，写在一个文件里面吧&#xA;jukay@MP ~/.ssh(18.9)&amp;gt; cat huanggai 六 3/10 10:28:07 2018 #!/bin/bash cd /Users/jukay/.ssh ssh -p 7013 -i licong_testing.rsa licong@huanggai jukay@MP ~/.ssh(18.9)&amp;gt; 每次登录都要~/.ssh目录下执行huanggai，太麻烦了，取一个全局额别名吧,我用的shell是fish，直接在fish的配置里面加上&#xA;alias huanggai=&amp;#34;sh /Users/jukay/.ssh/huanggai&amp;#34; 以后就可以在本地的任何目录执行huanggai，就能登录测试环境，以后要加班就不要去公司了。</description>
    </item>
    <item>
      <title>golang defer的&#34;坑&#34;</title>
      <link>http://localhost:1313/posts/2018/20180227/</link>
      <pubDate>Tue, 27 Feb 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20180227/</guid>
      <description>今天同事在计算程序耗时的时候遇到了一个问题：命名一个耗时非常长的函数，计算出来的耗时总是0ms，于是顺藤摸瓜，我们发现了golang中defer关键字的一个需要特别注意的地方，如果你不明白这个特性，下次也可能犯同样的错误，这里记录下这个问题。他的代码是这样的:&#xA;package main import ( &amp;#34;log&amp;#34; &amp;#34;time&amp;#34; ) func f() { var start = time.Now() defer log.Printf(&amp;#34;use %f seconds&amp;#34;, time.Now().Sub(start).Seconds()) time.Sleep(time.Second * 3) } func main() { f() } // 2018/02/27 22:37:53 use 0.000001 seconds 这里代码中已经sleep了3秒了，但是计算出来的耗时却几乎为0。原因是defer关键字后面接一个方法的调用，程序在执行到defer的时候会创建一个defer栈，方法以及参数都会入栈，这里就需要计算出方法的参数的具体值，将这个值保存在栈中，所以这里的日志虽然没有直接打印出来，但是log.Printf的方法的每个参数都已经计算出来了，也就是说time.Now().Sub(start).Seconds()这行代码其实是已经执行了的。这也就不难解释为什么计算出来的耗时总是接近于0.我写个代码验证一下这个问题。&#xA;import ( &amp;#34;log&amp;#34; ) func p() string { log.Println(&amp;#34;hello&amp;#34;) return &amp;#34;hello&amp;#34; } func f(str string) { } func main() { defer f(p()) log.Print(&amp;#34;world&amp;#34;) } //2018/02/27 22:48:55 hello //2018/02/27 22:48:55 world 输出与我们预期的一致。</description>
    </item>
    <item>
      <title>nc命令</title>
      <link>http://localhost:1313/posts/2018/20180214/</link>
      <pubDate>Wed, 14 Feb 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20180214/</guid>
      <description>nc命令的全称是netcat，netcat是一款带有hack性质的网络工具，他的功能非常强力。在网络工具中有“瑞士军刀”美誉.&#xA;mac 安装netcat&#xA;brew install netcat ubunt安装netcat&#xA;apt install netcat cenots安装netcat&#xA;yum install netcat 基本参数&#xA;root@tiantian-MS-7A36:~# nc -h GNU netcat 0.7.1, a rewrite of the famous networking tool. Basic usages: connect to somewhere: nc [options] hostname port [port] ... listen for inbound: nc -l -p port [options] [hostname] [port] ... tunnel to somewhere: nc -L hostname:port -p port [options] Mandatory arguments to long options are mandatory for short options too. Options: -c, --close close connection on EOF from stdin -e, --exec=PROGRAM program to exec after connect -g, --gateway=LIST source-routing hop point[s], up to 8 -G, --pointer=NUM source-routing pointer: 4, 8, 12, .</description>
    </item>
    <item>
      <title>watch命令</title>
      <link>http://localhost:1313/posts/2018/20180208/</link>
      <pubDate>Thu, 08 Feb 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20180208/</guid>
      <description>今年在查看端口情况使用到了watch命令,如果我要实时的查看当前系统的端口使用情况,这样写:&#xA;watch -n 1 &amp;#34;netstat -ant&amp;#34; 显示结果如下:&#xA;Every 1.0s: netstat -ant Thu Feb 8 22:25:55 2018 Active Internet connections (servers and established) Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0&#x9;0 0.0.0.0:80 0.0.0.0:* LISTEN tcp 0&#x9;0 0.0.0.0:22 0.0.0.0:* LISTEN tcp 0&#x9;0 0.0.0.0:443 0.0.0.0:* LISTEN tcp 0&#x9;0 172.17.220.102:22 221.217.218.194:49390 ESTABLISHED tcp&#x9;391&#x9;0 172.17.220.102:51760 106.11.68.13:80 CLOSE_WAIT tcp&#x9;401&#x9;0 172.17.220.102:50192 140.205.140.205:80 CLOSE_WAIT tcp 0&#x9;0 172.17.220.102:56940 106.</description>
    </item>
    <item>
      <title>linux磁盘挂载</title>
      <link>http://localhost:1313/posts/2018/20180130/</link>
      <pubDate>Tue, 30 Jan 2018 21:28:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20180130/</guid>
      <description>查看磁盘信息&#xA;fdisk -l oot@tiantian-MS-7A36:/# fdisk -l Disk /dev/sda: 111.8 GiB, 120034123776 bytes, 234441648 sectors Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disklabel type: dos Disk identifier: 0x8381099c Device Boot Start End Sectors Size Id Type /dev/sda1 * 2048 217761791 217759744 103.9G 83 Linux /dev/sda2 217763838 234440703 16676866 8G 5 Extended /dev/sda5 217763840 234440703 16676864 8G 82 Linux swap / Solaris Disk /dev/sdb: 931.</description>
    </item>
    <item>
      <title>2018年的学习计划</title>
      <link>http://localhost:1313/posts/2018/20180101/</link>
      <pubDate>Mon, 01 Jan 2018 21:28:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/20180101/</guid>
      <description>2017年过去了，过去一年，我对自己很满意，做了想做的事情，学习一直想学学习的技术。2018年我对自己也有新的学习计划。&#xA;docker容器的大规模自动化部署 参与一个正经的开源项目 前端技术的学习 深入了解golang的标准库 </description>
    </item>
    <item>
      <title>pm2管理node进程</title>
      <link>http://localhost:1313/posts/2017/20171210/</link>
      <pubDate>Sun, 10 Dec 2017 15:31:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2017/20171210/</guid>
      <description>这两天在做node部署相关的工作，使用ansible和nohup部署node服务。在这个过程中遇到了一个大坑，ansible退出以后，node进程会被killed，按道理&#xA;nphup node app.js &amp;gt;&amp;gt; /dev/null &amp;amp; 这样是不会有问题，确实，我吧这样的命令直接粘贴到服务器上运行，退出shell登录，一点问题也没有，可偏偏结合了ansible就不好使了，我到现在也没有找到问题所在。不得已，不得不弃坑，转用现在比较流行的pm2来管理node进程。调查发现pm2完全满足我的需求，而且看起来也足够炫酷。这里来记录一下pm2的使用方法吗。&#xA;安装pm2 npm install -g pm2 启动服务 // -name appname 表示给程序命名为appname,稍后我们就能appname来管理这个进程了 pm2 start app.js -name appname 启动两个实例(fork方式) // -i 表示实例数量， -x 表示fork方式启动，这样就能同事监听某个端口了 pm2 start app.js -i 2 -x 管理实例 // 这样就管理所有名字叫做appname的实例了 pm2 stop appname 删除实例 // 这样所有名字叫做appname的实例都会被删除并且关闭进程，之后就不能使用appname来启动它了 pm2 delete appname </description>
    </item>
    <item>
      <title>git相关操作</title>
      <link>http://localhost:1313/posts/2017/20171205/</link>
      <pubDate>Tue, 05 Dec 2017 15:07:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2017/20171205/</guid>
      <description>git分支相关操作 良好的git使用习惯是，如果我的代码已经合并到Master分之，并且测试通过，上线了，确认无误，我就可以删除之前的开发和测试分支了，git上如果有太多的无用分支，有时候会让你摸不着头脑，哪个是有用的，哪个是无用的。&#xA;clone仓库 git clone ${repo} clone指定分支或者tag的仓库 git clone ${repo} --branch=${tag}|${branch} 提交暂存区的变更 git commit -m {mesage} 删除本地分支 git branch -d {branch} 强制删除本地分支，可能是未合并的分支 git branch -D {branch} 删除远程分支 git push origin --delete {branch} 合并目标分支到当前分支 git merge ${target} 取消merge代码 git merge --abort tag操作 查看当前tag列表 git tag -l 或者 git tag --list 创建tag git tag -a {tag} -m {comment} 推送tag到remote git push {remote} {tag} 删除本地tag git tag -d {tag} 删除远程tag git push {reomte} --delete {tag} 文件操作 跟踪文件或者将文件加入到暂存区 // 文件名字支持通配符 git add {file} 从暂存区移除某文件 git reset head file 取消工作区域文件的修改,也可以用来恢复误删除的文件 git checkout {filename} 从git仓删除某个文件 git rm {file} ssh配置 每次输入账户名和密码实在太麻烦了，给github账户配置一个全局的ssh秘钥就不用那么麻烦了，操作也很简单:</description>
    </item>
    <item>
      <title>Linux用户相关操作</title>
      <link>http://localhost:1313/posts/2017/20171205-1/</link>
      <pubDate>Tue, 05 Dec 2017 15:07:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2017/20171205-1/</guid>
      <description>添加新用户 useradd {username} 这样会创建{username}用户，并且会同步产生/home/{username}主目录文件夹&#xA;删除用户 userdel {username} 修改用户的密码 passwd {username} 这里会提示输出两次密码，输入密码以后，{username}用户的密码就被改变了</description>
    </item>
    <item>
      <title>自我性格省视</title>
      <link>http://localhost:1313/posts/2017/20171126/</link>
      <pubDate>Sun, 26 Nov 2017 22:41:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2017/20171126/</guid>
      <description>我是一个自尊心特别强的人，不愿意在别人面前暴露自己的缺点，很怕被人轻视，所以在追女孩子上，非常不主动，害怕被拒绝。一旦拒绝，就很难再主动去追求别人了。我不会轻易去寻求别人的帮助，从小都是自己独立生活，独立思考，独立这方面也算是一个优点吧。我行为孤独，但是我不孤僻，我不会主动和别人混在一起，因为我认为，和别人在一起，不是听别人的，就是别人听我的，而我往往不想花很多时间去说服别人，我也不想被别人说服，所以，我拒绝了和别人一起活动。当然，这是不好事情，我深刻的明白这一点，我也在慢慢的改变。&#xA;在别人面前，我是一个问题特别多的人，因为我会抛出特别多的问题，这个在学习的时候，是一件好事，但是在工作中，就不是一件好了，领导不想你听那些问题，他们会认为你是一个怨妇，在抱怨。事实上，我并没有抱怨，我只是在阐述可能出道的问题。我在做一件事情前，总是会尽可能的把这件事想清楚，然后在动手去做。</description>
    </item>
    <item>
      <title>有道云笔记使用笔记</title>
      <link>http://localhost:1313/posts/2017/20171115/</link>
      <pubDate>Wed, 15 Nov 2017 11:08:09 +0000</pubDate>
      <guid>http://localhost:1313/posts/2017/20171115/</guid>
      <description>创建代办To-do list 未完成 完成 看书 学习 画流程图 graph LR A--&amp;gt;B sequenceDiagram A-&amp;gt;&amp;gt;B: How are you? B-&amp;gt;&amp;gt;A: Great! graph TD A[开始] --&amp;gt;B(第一个步骤) B --&amp;gt; C{let me thik} 甘特图 gantt dateFormat YYYY-MM-DD section S1 T1: 2014-01-01, 9d section S2 T2: 2014-01-11, 9d section S3 T3: 2014-01-02, 9d 链接 普通链接&#xA;++带下划线的链接++</description>
    </item>
    <item>
      <title>什么是优秀的程序员</title>
      <link>http://localhost:1313/posts/2017/20170922/</link>
      <pubDate>Fri, 22 Sep 2017 23:36:23 +0000</pubDate>
      <guid>http://localhost:1313/posts/2017/20170922/</guid>
      <description>最近总是在想，什么是好的程序员，是能搞懂操作系统，计算机网络，编译原理，能写出非常炫酷的代码的吗，还是能虽然对这些原理都不太懂，但是总是能用别人的框架完成自己的工作的。第二种程序员其实要比第一种要强一点，因为他能为企业创建直接的经济价值。更好的程序员应该精通各种原理，同时又能快速的学习和使用各种框架，并别制作有经济价值的产品的程序员吧嗯，是的。&#xA;2018-05-12日更新 优秀的程序应该是能写出优秀的程序(产品),这样的程序可维护性好，运维简单，容易一直，使用简单，对于我来说，就该是符合unix哲学。优秀的程序员不会浪费自己的时间做重复的事情，不会毫无理由的在代码里面炫技，增加代码复杂性。对于已经有的技术，做到自己心中了解，动手能做，但是不会重复再早一遍轮子。很多时候，我们达成一个目的，写代码是下策，找不现有的合适的工具的时候，才考虑去自己动手写代码。即使找到能完全使用的，我也希望能像shell一样去组装一些已经存在的工具。</description>
    </item>
    <item>
      <title>golang中map的&#34;坑&#34;</title>
      <link>http://localhost:1313/posts/2017/20171122/</link>
      <pubDate>Sun, 17 Sep 2017 21:28:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2017/20171122/</guid>
      <description>package main import ( &amp;#34;fmt&amp;#34; ) type User struct{ Name string } func main(){ var m = make(map[int]User) var u = User{ Name: &amp;#34;Hello World&amp;#34;, } m[1] = u fmt.Println(m[1].Name) var u2 =m[1] u2.Name=&amp;#34;Hello Golang&amp;#34; fmt.Println(m[1].Name) } // Hello World // Hello World 这段golang代码会输出两行Hello World，并不会输出Hello Golang，原因是golang中的map返回的是一个copy，而不是一个refrence。&#xA;如果要想返回一个refrence，那么应该怎么改呢&#xA;package main import ( &amp;#34;fmt&amp;#34; ) type User struct{ Name string } func main(){ var m = make(map[int]*User) var u = User{ Name: &amp;#34;Hello World&amp;#34;, } m[1] = &amp;amp;u fmt.</description>
    </item>
    <item>
      <title>论做家务的重要性</title>
      <link>http://localhost:1313/posts/2017/20170917/</link>
      <pubDate>Sun, 17 Sep 2017 21:28:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2017/20170917/</guid>
      <description> 工作和生活的压力很大，闲下来的时候，做家务能使你的精神得到放松，做家务能够培养自己不厌其烦的耐心，和对简单生活的热爱！做家务还是能得到一个干净整洁的生活环境，当你经过一整天的忙碌，十分的疲惫，沮丧，回到家里，推开家门，看到自己的衣服，鞋子摆放的错落有致，地板干净清洁，你可能会有一个愉悦的心情，能睡一个好觉。这也是做家务的好处。不要抗拒做家务，因为这就是你生活的一部分。坚持做家务，就是热爱生活的表现。从今天起，我要坚持整理自己的房间,过好自己的生活，安排好自己的时间！生活没有那么难:就是不厌其烦，积极面对！&#xA;时间 安排 周一 回家做饭 周二 回家做饭，清洗衣物 周三 回家做饭，折叠衣服 周三 回家做饭，拖地 周四 回家做饭，整理书桌 周五 回家做饭，加餐，早点睡觉 周六 早点起来，去图书馆看看书，晚上回来做饭，加个菜 周日 睡个懒觉，上午清理房间，清洗衣物，傍晚出去散散步 </description>
    </item>
  </channel>
</rss>
